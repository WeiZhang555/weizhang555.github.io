<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>WeiZhang555</title>
    <link>https://weizhang555.github.io/</link>
    <description>Recent content on WeiZhang555</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright> © Zhang Wei(weizhang555)</copyright>
    <lastBuildDate>Fri, 21 Jul 2023 00:10:46 +0800</lastBuildDate><atom:link href="https://weizhang555.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BPF的设计原则Q&amp;A</title>
      <link>https://weizhang555.github.io/translate/bpf-design-qa/</link>
      <pubDate>Fri, 21 Jul 2023 00:10:46 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/translate/bpf-design-qa/</guid>
      <description>
        
          
            原文链接：BPF Design Q&amp;amp;A
声明：
本文根据截止2023-07-22日的文档最新内容进行翻译，无法保证永远是最新的。 由于作者水平有限，难免出现错误和遗漏，如果发现有错误的内容欢迎在下方评论区留言指正。 这篇文章是以文档的形式介绍了ebpf的设计上的考虑，对于提升ebpf的理解很有好处，这是为什么单独挑选这篇文章进行翻译的原因。
以下是正文。
问：BPF是一种类似x86和arm64的通用指令集吗？ 答: NO.
问：BPF是通用的虚拟机吗？ 答：NO。
BPF是遵循C语言调用约定(C calling convention)的一种通用指令集。
问：为什么选择了C语言调用约定？ 答：因为BPF程序是为在Linux kernel内运行而设计的，kernel是用C语言写的，因而BPF定义了与x86和arm64两个最常用的架构兼容的指令集(同时也考虑到了其他架构的一些重要“怪癖”)，也定义了与那些架构上的linux kernel的C调用约定兼容的调用约定。
问：未来会支持多个返回值吗？ 答：NO。BPF仅支持使用R0寄存器作为函数返回值。
问：未来会支持超过5个函数参数吗？ 答：NO。BPF 调用约定仅允许寄存器 R1-R5 用作参数。 BPF 不是一个独立的指令集。 （与允许 msft、cdecl 和其他约定的 x64 ISA 不同）
问：BPF程序可以访问指令指针(instruction pointer)或返回地址吗？ 答：NO
问：BPF程序可以访问栈指针(stack pointer)吗？ 答：NO。
只有帧指针(frame pointer)(寄存器R10)可以被访问。从编译器角度看，拥有栈指针是有必要的。例如，LLVM定义了寄存器R11作为BPF后端的栈指针，但是它确保了生成的代码永远不会使用它。
问：C 调用约定是否会减少可能的用例？ 答：YES。
BPF的设计强制以内核helper函数和内核对象（像BPF maps）的形式添加主要功能，并且他们之间可以无缝互操作。它允许kernel调用BPF程序，并且BPF程序可以零开销调用kernel helpers，因为他们都是原生C代码。对于与本机内核 C 代码无法区分的 JIT 化 BPF 程序尤其如此。
问：这是否意味着对BPF代码进行‘创新’扩展是不允许的？ 答：算对吧（Soft yes）。
至少到目前为止成立，直到BPF代码支持了bpf-to-bpf calls, indirect calls, loops, global variables, jump tables, read-only sections, 和其他所有C代码可以产生的结构。
          
          
        
      </description>
    </item>
    
    <item>
      <title>转载：著名的 P=NP 问题到底是什么</title>
      <link>https://weizhang555.github.io/republish/pnp-problem/</link>
      <pubDate>Fri, 21 Oct 2022 18:01:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/republish/pnp-problem/</guid>
      <description>
        
          
            这篇文章对于N和NP问题讲解的非常通俗易通，值得一读。
原文链接: 其一 其二
以下为正文
你会经常看到网上出现“这怎么做，这不是NP问题吗”、“这个只有搜了，这已经被证明是NP问题了”之类的话。这或许是众多OIer最大的误区之一。你要知道，大多数人此时所说的NP问题其实都是指的NPC问题。他们没有搞清楚NP问题和NPC问题的概念。NP问题并不是那种“只有搜才行”的问题，NPC问题才是。
好，行了，基本上这个误解已经被澄清了。下面的内容都是在讲什么是P问题，什么是NP问题，什么是NPC问题，你如果不是很感兴趣就可以不看了。接下来你可以看到，把NP问题当成是 NPC问题是一个多大的错误。
还是先用几句话简单说明一下时间复杂度。时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当问题规模扩大后，程序需要的时间长度增长得有多快。
也就是说，对于高速处理数据的计算机来说，处理某一个特定数据的效率不能衡量一个程序的好坏，而应该看当这个数据的规模变大到数百倍后，程序运行时间是否还是一样，或者也跟着慢了数百倍，或者变慢了数万倍。
不管数据有多大，程序处理花的时间始终是那么多的，我们就说这个程序很好，具有O(1)的时间复杂度，也称常数级复杂度；数据规模变得有多大，花的时间也跟着变得有多长，这个程序的时间复杂度就是O(n)，比如找n个数中的最大值；而像冒泡排序、插入排序等，数据扩大2倍，时间变慢4倍的，属于O(n^2)的复杂度。
还有一些穷举类的算法，所需时间长度成几何阶数上涨，这就是O(a^n)的指数级复杂度，甚至O(n!)的阶乘级复杂度。不会存在O(2*n^2)的复杂度，因为前面的那个“2”是系数，根本不会影响到整个程序的时间增长。同样地，O (n^3+n^2)的复杂度也就是O(n^3)的复杂度。
因此，我们会说，一个O(0.01n^3)的程序的效率比O(100n^2)的效率低，尽管在n很小的时候，前者优于后者，但后者时间随数据规模增长得慢，最终O(n^3)的复杂度将远远超过O(n^2)。我们也说，O(n^100)的复杂度小于O(1.01^n)的复杂度。
容易看出，前面的几类复杂度被分为两种级别，其中后者的复杂度无论如何都远远大于前者：一种是O(1)，O(log(n))，O(n^a)等，我们把它叫做多项式级的复杂度，因为它的规模n出现在底数的位置；另一种是O(a^n)和O(n!)型复杂度，它是非多项式级的，其复杂度计算机往往不能承受。
当我们在解决一个问题时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度需要的时间太多，往往会超时，除非是数据规模非常小。
自然地，人们会想到一个问题：会不会所有的问题都可以找到复杂度为多项式级的算法呢？很遗憾，答案是否定的。有些问题甚至根本不可能找到一个正确的算法来，这称之为“不可解问题”(Undecidable Decision Problem)。
The Halting Problem就是一个著名的不可解问题，在我的Blog上有过专门的介绍和证明。再比如，输出从1到n这n个数的全排列。不管你用什么方法，你的复杂度都是阶乘级，因为你总得用阶乘级的时间打印出结果来。
有人说，这样的“问题”不是一个“正规”的问题，正规的问题是让程序解决一个问题，输出一个“YES”或“NO”（这被称为判定性问题），或者一个什么什么的最优值（这被称为最优化问题）。那么，根据这个定义，我也能举出一个不大可能会有多项式级算法的问题来：Hamilton回路。
问题是这样的：给你一个图，问你能否找到一条经过每个顶点一次且恰好一次（不遗漏也不重复）最后又走回来的路（满足这个条件的路径叫做Hamilton回路）。这个问题现在还没有找到多项式级的算法。事实上，这个问题就是我们后面要说的NPC问题。
下面引入P类问题的概念：如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于P问题。
****P是英文单词多项式的第一个字母。哪些问题是P类问题呢？通常NOI和NOIP不会出不属于P类问题的题目。我们常见到的一些信息奥赛的题目都是P问题。道理很简单，一个用穷举换来的非多项式级时间的超时程序不会涵盖任何有价值的算法。
接下来引入NP问题的概念。这个就有点难理解了，或者说容易理解错误。在这里强调（回到我竭力想澄清的误区上），NP问题不是非P类问题。NP问题是指可以在多项式的时间里验证一个解的问题。NP问题的另一个定义是，可以在多项式的时间里猜出一个解的问题。
比方说，我RP很好，在程序中需要枚举时，我可以一猜一个准。现在某人拿到了一个求最短路径的问题，问从起点到终点是否有一条小于100个单位长度的路线。它根据数据画好了图，但怎么也算不出来，于是来问我：你看怎么选条路走得最少？
我说，我RP很好，肯定能随便给你指条很短的路出来。然后我就胡乱画了几条线，说就这条吧。那人按我指的这条把权值加起来一看，嘿，神了，路径长度98，比100小。于是答案出来了，存在比100小的路径。别人会问他这题怎么做出来的，他就可以说，因为我找到了一个比100 小的解。
在这个题中，找一个解很困难，但验证一个解很容易。验证一个解只需要O(n)的时间复杂度，也就是说我可以花O(n)的时间把我猜的路径的长度加出来。那么，只要我RP好，猜得准，我一定能在多项式的时间里解决这个问题。我猜到的方案总是最优的，不满足题意的方案也不会来骗我去选它。这就是NP问题。
当然有不是NP问题的问题，即你猜到了解但是没用，因为你不能在多项式的时间里去验证它。下面我要举的例子是一个经典的例子，它指出了一个目前还没有办法在多项式的时间里验证一个解的问题。
很显然，前面所说的Hamilton回路是NP问题，因为验证一条路是否恰好经过了每一个顶点非常容易。但我要把问题换成这样：试问一个图中是否不存在Hamilton回路。这样问题就没法在多项式的时间里进行验证了，因为除非你试过所有的路，否则你不敢断定它“没有Hamilton回路”。
之所以要定义NP问题，是因为通常只有NP问题才可能找到多项式的算法。我们不会指望一个连多项式地验证一个解都不行的问题存在一个解决它的多项式级的算法。相信读者很快明白，信息学中的号称最困难的问题——“NP问题”，实际上是在探讨NP问题与P类问题的关系。
很显然，所有的P类问题都是NP问题。也就是说，能多项式地解决一个问题，必然能多项式地验证一个问题的解——既然正解都出来了，验证任意给定的解也只需要比较一下就可以了。关键是，人们想知道，是否所有的NP问题都是P类问题。
我们可以再用集合的观点来说明。如果把所有P类问题归为一个集合P中，把所有 NP问题划进另一个集合NP中，那么，显然有P属于NP。现在，所有对NP问题的研究都集中在一个问题上，即究竟是否有P=NP？通常所谓的“NP问题”，其实就一句话：证明或推翻P=NP。
NP问题一直都是信息学的巅峰。巅峰，意即很引人注目但难以解决。在信息学研究中，这是一个耗费了很多时间和精力也没有解决的终极问题，好比物理学中的大统一和数学中的歌德巴赫猜想等。
目前为止这个问题还“啃不动”。但是，一个总的趋势、一个大方向是有的。人们普遍认为，P=NP不成立，也就是说，多数人相信，存在至少一个不可能有多项式级复杂度的算法的NP问题。
人们如此坚信P≠NP是有原因的，就是在研究NP问题的过程中找出了一类非常特殊的NP问题叫做NP-完全问题，也即所谓的 NPC问题。C是英文单词“完全”的第一个字母。正是NPC问题的存在，使人们相信P≠NP。下文将花大量篇幅介绍NPC问题，你从中可以体会到NPC问题使P=NP变得多么不可思议。
为了说明NPC问题，我们先引入一个概念——约化(Reducibility，有的资料上叫“归约”)。
简单地说，一个问题A可以约化为问题B的含义即是，可以用问题B的解法解决问题A，或者说，问题A可以“变成”问题B。
《算法导论》上举了这么一个例子。比如说，现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。那么我们说，前者可以约化为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程。
我们可以写出两个程序分别对应两个问题，那么我们能找到一个“规则”，按照这个规则把解一元一次方程程序的输入数据变一下，用在解一元二次方程的程序上，两个程序总能得到一样的结果。这个规则即是：两个方程的对应项系数不变，一元二次方程的二次项系数为0。按照这个规则把前一个问题转换成后一个问题，两个问题就等价了。
同样地，我们可以说，Hamilton回路可以约化为TSP问题(Travelling Salesman Problem，旅行商问题)：在Hamilton回路问题中，两点相连即这两点距离为0，两点不直接相连则令其距离为1，于是问题转化为在TSP问题中，是否存在一条长为0的路径。Hamilton回路存在当且仅当TSP问题中存在长为0的回路。
“问题A可约化为问题B”有一个重要的直观意义：B的时间复杂度高于或者等于A的时间复杂度。也就是说，问题A不比问题B难。这很容易理解。既然问题A能用问题B来解决，倘若B的时间复杂度比A的时间复杂度还低了，那A的算法就可以改进为B的算法，两者的时间复杂度还是相同。正如解一元二次方程比解一元一次方程难，因为解决前者的方法可以用来解决后者。
很显然，约化具有一项重要的性质：约化具有传递性。如果问题A可约化为问题B，问题B可约化为问题C，则问题A一定可约化为问题C。这个道理非常简单，就不必阐述了。
现在再来说一下约化的标准概念就不难理解了：如果能找到这样一个变化法则，对任意一个程序A的输入，都能按这个法则变换成程序B的输入，使两程序的输出相同，那么我们说，问题A可约化为问题B。
当然，我们所说的“可约化”是指的可“多项式地”约化(Polynomial-time Reducible)，即变换输入的方法是能在多项式的时间里完成的。约化的过程只有用多项式的时间完成才有意义。
好了，从约化的定义中我们看到，一个问题约化为另一个问题，时间复杂度增加了，问题的应用范围也增大了。通过对某些问题的不断约化，我们能够不断寻找复杂度更高，但应用范围更广的算法来代替复杂度虽然低，但只能用于很小的一类问题的算法。
再回想前面讲的P和NP问题，联想起约化的传递性，自然地，我们会想问，如果不断地约化上去，不断找到能“通吃”若干小NP问题的一个稍复杂的大NP问题，那么最后是否有可能找到一个时间复杂度最高，并且能“通吃”所有的 NP问题的这样一个超级NP问题？
答案居然是肯定的。也就是说，存在这样一个NP问题，所有的NP问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的NP问题都解决了。
这种问题的存在难以置信，并且更加不可思议的是，这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的NPC 问题，也就是NP-完全问题。NPC问题的出现使整个NP问题的研究得到了飞跃式的发展。我们有理由相信，NPC问题是最复杂的问题。
再次回到全文开头，我们可以看到，人们想表达一个问题不存在多项式的高效算法时应该说它“属于NPC问题”。此时，我的目的终于达到了，我已经把NP问题和NPC问题区别开了。
到此为止，本文已经写了近5000字了，我佩服你还能看到这里来，同时也佩服一下自己能写到这里来。
NPC问题的定义非常简单。同时满足下面两个条件的问题就是NPC问题。首先，它得是一个NP问题；然后，所有的NP问题都可以约化到它。证明一个问题是 NPC问题也很简单。先证明它至少是一个NP问题，再证明其中一个已知的NPC问题能约化到它（由约化的传递性，则NPC问题定义的第二条也得以满足；至于第一个NPC问题是怎么来的，下文将介绍），这样就可以说它是NPC问题了。
既然所有的NP问题都能约化成NPC问题，那么只要任意一个NPC问题找到了一个多项式的算法，那么所有的NP问题都能用这个算法解决了，NP也就等于P 了。因此，给NPC找一个多项式算法太不可思议了。因此，前文才说，“正是NPC问题的存在，使人们相信P≠NP”。我们可以就此直观地理解，NPC问题目前没有多项式的有效算法，只能用指数级甚至阶乘级复杂度的搜索。
顺便讲一下NP-Hard问题。NP-Hard问题是这样一种问题，它满足NPC问题定义的第二条但不一定要满足第一条（就是说，NP-Hard问题要比 NPC问题的范围广）。NP-Hard问题同样难以找到多项式的算法，但它不列入我们的研究范围，因为它不一定是NP问题。
即使NPC问题发现了多项式级的算法，NP-Hard问题有可能仍然无法得到多项式级的算法。事实上，由于NP-Hard放宽了限定条件，它将有可能比所有的NPC问题的时间复杂度更高从而更难以解决。
不要以为NPC问题是一纸空谈。NPC问题是存在的。确实有这么一个非常具体的问题属于NPC问题。下文即将介绍它。
下文即将介绍逻辑电路问题。这是第一个NPC问题。其它的NPC问题都是由这个问题约化而来的。因此，逻辑电路问题是NPC类问题的“鼻祖”。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Solidity入门系列(1)：基于Truffle搭建本地开发环境</title>
      <link>https://weizhang555.github.io/original/learn-solidity/</link>
      <pubDate>Fri, 03 Jun 2022 22:08:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/learn-solidity/</guid>
      <description>
        
          
            怎样开始Solidity的学习 最近在学习区块链、智能合约相关知识，发现Solidity权威的学习资料很匮乏，很奇怪Solidity这么火竟然没有官方的详细学习资料，比如《Solidity Cookbook》这类书籍。
这篇文章是Solidity入门的入门文档，介绍如何搭建本地环境搭建。我个人也是新手，多年的语言学习体验还是习惯先有个本地的开发环境，Ethereum官方推荐的学习工具列举在下面：https://ethereum.org/zh/developers/learning-tools/ ，其中Remix我看到很多人在推荐，如果喜欢在线编码的话可以直接使用。
另外，Solidity的入门学习材料推荐以下两个：
CryptoZombie 讲的很泛但是方方面面都介绍到了，很适合建立初步的体感。 Solidity By Example 我正在看，例子很多，但是貌似也没有介绍的很深入。 需要更加Advanced的学习资料。 Solidity本地环境我个人选择Truffle，我也是新手，如果大家有更好的推荐可以在评论区推荐给我，谢谢~
Truffle环境搭建 主要参考Truffle官方Quick Start：https://trufflesuite.com/docs/truffle/quickstart/
安装很简单：
1$ npm install -g truffle 强烈推荐安装Ganache，Ganache可以在本地启动一个带UI的eth链，带10个测试账号，每个账号有100个eth供测试用。
虽然Truffle也会启动本地的eth测试链，但是有个UI界面的Ganache还是很直观的，方便学习。
Ganache建议安装支持Filecoin的最新版本，虽然我们还没用到Filecoin，但是提前准备总是没错的。
参考：https://trufflesuite.com/docs/ganache/quickstart/#1-install-ganache
所有可用的版本列表：https://github.com/trufflesuite/ganache-ui/releases
手动安装最新版本，我用的版本是2.6.0-beta.3.1390，下载地址
Truffle一些操作技巧及常用命令 参考：https://trufflesuite.com/docs/truffle/quickstart/
Truffle Quick Start里面的例子使用的MetaCoin，我们这里从truffle init开始建一个新的truffle工程。
1. 创建工程 1$ mkdir test 2$ cd test 3$ truffle init 查看目录树：
1$ tree . 2. 3├── contracts 4│ └── Migrations.sol 5├── migrations 6│ └── 1_initial_migration.js 7├── test 8└── truffle-config.js 9\ 10 113 directories, 3 files 2.
          
          
        
      </description>
    </item>
    
    <item>
      <title>最准确的Go语言运算符优先级介绍</title>
      <link>https://weizhang555.github.io/original/go-operators-priority/</link>
      <pubDate>Fri, 18 Mar 2022 11:24:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/go-operators-priority/</guid>
      <description>
        
          
            前言 写Go代码时一下子想不起准确的运算符优先级了，Google搜索了下，发现前面几个SEO做的比较好的网址给的要不就是错的，要不就是写的乱七八糟，误人子弟。喷的就是下面这几个出错的：
https://haicoder.net/golang/golang-operator-precedence.html http://c.biancheng.net/view/5559.html http://gitbook.net/go/go_operators_precedence.html 这几个基本上是互相抄的，没有验证，很容易反驳。比如，上面说&amp;quot;+&amp;quot;, &amp;quot;-&amp;quot;的优先级大于“|”，那么以下代码
1a := 2 | 4 - 1 的结果应该等同于
1a := 2 | (4 - 1) 但实际上前者结果为5，后者的答案是3。原因是“-”运算符优先级与“|”实际上是相等的。
验证链接： https://go.dev/play/p/fPFNO8r6bJ3
简单分享下正确的运算符优先级，避免后人踩坑。
正确的运算符优先级 Google找到了官方的说明：
https://go.dev/ref/spec 可以参考其中Operator Precedence一节，介绍的非常清楚。
单目运算符优先级最高。 单目运算符包括：
1&amp;#34;+&amp;#34; | &amp;#34;-&amp;#34; | &amp;#34;!&amp;#34; | &amp;#34;^&amp;#34; | &amp;#34;*&amp;#34; | &amp;#34;&amp;amp;&amp;#34; | &amp;#34;&amp;lt;-&amp;#34; 双目运算符分5个优先级，从高到低为 1Precedence Operator 2 5 * / % &amp;lt;&amp;lt; &amp;gt;&amp;gt; &amp;amp; &amp;amp;^ 3 4 + - | ^ 4 3 == != &amp;lt; &amp;lt;= &amp;gt; &amp;gt;= 5 2 &amp;amp;&amp;amp; 6 1 || 分别是： “乘法类”，“加法类”，“比较类”，“逻辑与”，“逻辑或”，优先级最低的是“逻辑或”。
          
          
        
      </description>
    </item>
    
    <item>
      <title>你的软件是“椰子”还是“苹果”？</title>
      <link>https://weizhang555.github.io/original/different-software-types/</link>
      <pubDate>Wed, 21 Apr 2021 14:14:13 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/different-software-types/</guid>
      <description>
        
          
            我至今在两家公司工作过，第一家是华为，第二家是蚂蚁金服。在两家待的时间都足够长了，谈谈对两家公司软件质量控制的一点感悟。
用一句话来对比两家的软件质量的话，我称为“椰子型”和“苹果型”。两家公司基本可以代表传统软件公司与互联网公司的不同的质量管理标准。
椰子型 苹果型 选哪个？ 椰子型 华为擅长做“椰子型”软件，外壳坚硬无比，内部一包水。
华为的研发流程是很早就花大价钱从IBM引入的IPD研发流程，大致分为几个流程(参考)：
Charter(立项) --&amp;gt; TR1/2/3 --&amp;gt; PDCP(中期) --&amp;gt; TR4/5 --&amp;gt; EDCP(结项)
一个项目周期基本上是一年，PDCP之前是项目的设计和PoC阶段，可以改方案和设计，PDCP之后就不允许修改设计了，TR5要达到验收标准， 验收不过等同于项目延期，会对项目的Manager和团队的考评有重大影响，所以TR5的验收是极其重要且严肃的。
整个开发模型沿用了很多年，基本上是个大的软件开发瀑布模型，周期长，与现在倡导的敏捷开发模式完全背道而驰。 这套开发模式引入之后一直在使用，使得华为一直对软件质量有着极其优秀的掌控，帮助华为站稳了ICT和企业市场，但过于笨重也遭到了很多内部人员的吐槽。 所以在云BU成立以后，也做了局部的敏捷开发的尝试。
华为的整个研发体系和流程都是很笨重的，也很严肃。研发人员和测试人员的比例可以达到2:1左右（各个部门有不同），由于大量的测试人员的存在，对外出口的软件质量是极好的，不会出现太明显的Bug和崩溃等现象。
所以在我看来，对外表现的是“椰子型”的外壳。
但是我比较受不了的一点是，内部的人员质量参差不齐，差的真的是太差了。在我参加“三营”培训时，10个人一组做敏捷开发的培训，全组竟然只有我一个人能写程序，其他9个人给我做测试，也是很搞笑。更可笑的是我们组最后做出来的软件评分是第一名，可能是由于开发：测试达到了1:9吧。
大量的低水平开发造就了垃圾一般的代码质量，所以华为的软件只能黑盒来用，要是你看到了实现的代码，怕是要战战兢兢吐一口老血了。
“水”代码其实也不能完全怪垃圾程序员，我自己也写过很多自己不屑的垃圾代码，让我来告诉你原因。
在最后的突击测试阶段，管理者是要看测试的漏洞数据的，要求随时间的推进测试人员发现的代码bug数应该递减，最后趋近于0，这很合理对吧？ 还有两项要求，要看bug的解决时长，这个关乎manager的考核指标，所以要求每日的bug要日清；并且TR5时系统内的bug必须清0，我不管是多么难解或者重大的bug，一定要修复。
这两项要求给我造成了巨大的麻烦，设想一下下午6点的时候，测试给你提了5个bug，你挨个看了一下，有1个几乎不可能在短时间解决，于是你跟领导反馈，领导说必须严格按照质量标准，今天一定要解决。 这个情况就多次发生在了我的身上，于是在通宵都仍然无法解决的情况下，只能用大量的workaround去想办法从cmdline和api调用层面屏蔽掉这个bug，于是我亲手给这座代码屎山贡献了更多。最终这包屎山变成了“椰子”来到了用户手里。
内部的整套研发流程，在我看来是有好有坏的，确实严格的管理流程给了华为对产品的严密把控。华为就是有30%的一流人才带着70%的庸才做出来世界一流软件的质量，但是对我这种有点轻微代码洁癖的人来说，是无法忍受的。 我也迫切的希望能与更多优秀的人合作，而不是浪费时间教笨人做事，所以离开华为，加入了互联网公司，希望能找到更多志同道合的人。
苹果型 互联网公司就是完全的另一个极端了，我来介绍下蚂蚁的研发流程：
[流程加载失败...]
你没看错，没有研发流程，质量把控流程完全没有，测试工程师也很少。 据我所知，这种模式在互联网公司比较流行，即使是Google，Facebook这种大厂也是如此，Facebook是全栈工程师，每个人开发的组件直接上线运行和实测，所以听闻Google的工程师经常嘲讽Facebook是“踩着香蕉皮滑行”，滑到哪儿算哪儿。
这种模式之所以并没有引起大的问题，在我看来主要是两点原因：
1.人员平均水平较高
每个人的主观能动性比较高，代码平均质量较高，会主动写单元测试和集成测试，习惯于敏捷开发，CI/CD。靠着优秀程序员的自我修养，代码质量仍然获得了一定的保证。
2.面向消费者业务较多，bug不敏感
ToC的业务对产品的质量要求并没有企业级或CT级要求高，Web形态的产品完全可以先推一个公测版的产品出去试试效果，对于Bug的存在是有一定容忍度的。本身互联网产品迭代快，对速度的要求胜过对质量的要求。
所以好的互联网公司的产品质量通常是“苹果型”的，外表摸起来有一点点硬，打开来看，内部代码质量也不错。 由于测试人员缺失以及快速迭代的需求，很难将外表做的像椰子一样。
互联网的开发流程较敏捷，留给工程师的自由发挥空间比较大，所以从我个人来说，是更喜欢互联网这种模式的。二八效应决定着一套80分的软件做到100分需要额外耗费巨大的人力，在不成正比的投入产出面前，有必要衡量下是否要继续优化下去？
没有流程其实造成了更大的问题，项目立项随意，周期随意，没有验收标准，为了KPI每个人都在努力的造轮子却不管重复不重复。所以我看到的是，对外我们是有无数的黑科技呈现出来，从外部看我们的软件研发能力是无比强大的，但是很多黑科技只能偏居一隅没有机会获得大规模推广，大规模推广的项目也有很多致命的缺陷导致寿命不长。
由此，阿里巴巴已经开始沦落为“geek的自留地”，自己内部玩的嗨，更多的却是“内卷”而不是创造实际价值。
选哪个？ 二八效应对应着中国的一句成语“行百里者半九十”，所以在继续提升产品质量的时候，我们都要掂量一下是否值得如此大的投入？
不同的企业会有不同的选择，ToB or ToC的选择会有大的不同。在我还在华为的时候，我痛恨70%的庸才拉低了华为的档次，拉低了我对外的credit，但是华为的80分到90分恰恰需要70%的庸才作为一颗颗螺丝钉消耗自身的精力来完成，而Google，Facebook的优秀人才们只愿意做软件开发的前一部分创造性的工作做到85分，而非整天无休止的消耗自己。由此造就了“椰子型”与“苹果型”软件的不同。
选哪个？从政治正确的角度考虑，我们要做“石头型”的软件，从公司层面，“椰子型”是不错的选择，从工程师个人角度，还是“苹果型”更加友好。
我现在要承认，自己还是很怀念IPD研发流程的，它可恨却又很有用，帮助产品找到正确的方向以及一直运行在正确的轨道上。蚂蚁相比华为，还是有小作坊vs大厂的既视感的，但是我无意贬低任意一家，对前东家和现东家我内心都是喜欢的。
Respect to everything!
          
          
        
      </description>
    </item>
    
    <item>
      <title>docker-runc主机逃逸漏洞复现：CVE-2019-5736</title>
      <link>https://weizhang555.github.io/original/runc-host-escape-cve/</link>
      <pubDate>Wed, 11 Dec 2019 11:30:46 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/runc-host-escape-cve/</guid>
      <description>
        
          
            CVE-2019-5736是一个比较知名的runc漏洞，利用方式简单，危害很大，经常被拿来做云原生安全的攻击/防御演示。
我最近也研究了下这个漏洞的使用，研究的第一步首先是复现。
尝试了github上的示例： https://github.com/Frichetten/CVE-2019-5736-PoC ， 这里对源码做了一些修改，在下面分享一下。
注意：ubuntu上安装的docker 18.06似乎已经打上了补丁，我手动编译了runc的1.0.0-rc5版本才成功复现。
复现方式：
在一个terminal里面：
1zhangwei@zhangwei-ubuntu-vm:~/program/gocode/src/github.com/Frichetten/CVE-2019-5736-PoC$ docker run -ti -v $PWD/exploit:/exploit ubuntu:18.04 bash 另一个terminal内执行：
1$ docker exec -ti 5b28d7ab5083 /bin/sh 此时第一个terminal的打印：
1zhangwei@zhangwei-ubuntu-vm:~/program/gocode/src/github.com/Frichetten/CVE-2019-5736-PoC$ docker run -ti -v $PWD/exploit:/exploit ubuntu:18.04 bash 2root@5b28d7ab5083:/# /exploit 3[+] Overwritten /bin/sh successfully 4[+] Found the PID: 17 5[+] Successfully got the file handle 6[-]Failed to open /proc/self/fd/3: open /proc/self/fd/3: text file busy 7[+] Successfully got write handle &amp;amp;{0xc0000501e0} 8root@5b28d7ab5083:/# /tmp/下多了一个passwd文件。
Ubuntu下面没有原demo里使用的/etc/shadow文件，所以我修改成了/etc/passwd，会被copy到/tmp/目录下。
修改过的源码：
          
          
        
      </description>
    </item>
    
    <item>
      <title>kubernetes安装指南</title>
      <link>https://weizhang555.github.io/original/kubernetes-setup/</link>
      <pubDate>Wed, 11 Dec 2019 11:11:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/kubernetes-setup/</guid>
      <description>
        
          
            本文介绍如何使用kubeadm安装一个简单的包含三个节点的集群。
测试环境 三台VM，分别为test-vm, test-vm-1, test-vm-2，系统是ubuntu 19.04
下载 kubernetes的安装包，官方文档用apt get的方式，由于国内被墙了没法get到，可以直接从github上下载release包。把kubeadm，kubelet, kubectl装好就够了。docker当然也要装好。
具体的安装步骤暂时略过。
配置kubelet 三台节点可以手动配置一下kubelet服务，配置方法都是一样的：
1# cat &amp;gt; /lib/systemd/system/kubelet.service &amp;lt;&amp;lt; EOF 2[Unit] 3Description=kubelet: The Kubernetes Node Agent 4Documentation=http://kubernetes.io/docs/ 5 6[Service] 7ExecStart=/usr/bin/kubelet 8Restart=always 9StartLimitInterval=0 10RestartSec=10 11 12[Install] 13WantedBy=multi-user.target 14EOF 上面就是简单的调用了下kubelet命令，实际上还有很多参数，这个不着急。因为我们是用kubeadm配置的，所以实际上生效的是kubeadm为kubelet设置的参数，kubelet的启动将依赖kubeadm设置的bootstrap配置：
1# mkdir -p /etc/systemd/system/kubelet.service.d/ 2# cat &amp;gt; /etc/systemd/system/kubelet.service.d/10-kubeadm.conf &amp;lt;&amp;lt; EOF 3[Service] 4Environment=&amp;#34;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&amp;#34; 5Environment=&amp;#34;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&amp;#34; 6# This is a file that &amp;#34;kubeadm init&amp;#34; and &amp;#34;kubeadm join&amp;#34; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically 7EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Docker官方镜像签名方案：Notary</title>
      <link>https://weizhang555.github.io/original/notary-intro/</link>
      <pubDate>Tue, 11 Dec 2018 11:20:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/notary-intro/</guid>
      <description>
        
          
            1. TUF 1.1 背景 1.2 TUF的角色 1.2 TUF的工作流 step 0: 加载可信的root元数据文件 step 1: 更新root元数据文件 step 2: 下载timestamp元数据文件 step 3：下载snapshot元数据文件 step 4：下载最顶层的targets元数据 step 5：对照target元数据验证target 2. Notary 2.1 介绍 2.2 目标 2.3 Notary的密钥管理 3. Docker Content Trust本地测试 3.1 环境准备 3.2 push的镜像无签名的情况 3.3 push有签名的版本 3.4 恶意用户上传恶意镜像，覆盖ubuntu:18.04 3.5 docker content trust的问题 1. TUF 1.1 背景 TUF是Tor项目设计出的一套安全分发软件更新的框架，Notary是TUF框架的go语言实现，而Docker Content Trust是TUF框架的应用。理清三者关系有助于后续理解。
1.2 TUF的角色 TUF框架包含五类角色，对应五把密钥，分别是Root, Target, Snapshot, Timestamp, Delegated target(可选)，每个角色对应一个元数据文件及一把密钥。
TUF角色和密钥的理解与Notary介绍有重合，可以参考 &amp;quot;2.3 Notary的密钥管理&amp;quot;
1.2 TUF的工作流 TUF框架的定义在这里：https://github.com/theupdateframework/specification/blob/master/tuf-spec.md 。
          
          
        
      </description>
    </item>
    
    <item>
      <title>创建kata的K8s集群</title>
      <link>https://weizhang555.github.io/original/create-k8s-cluster-with-kata/</link>
      <pubDate>Sat, 18 Aug 2018 19:10:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/create-k8s-cluster-with-kata/</guid>
      <description>
        
          
            本文介绍下如何创建kata的k8s集群， kata项目链接：https://github.com/kata-containers kata是什么不介绍了，能看到这篇文章的相信对kata都已经有一定了解了。
本文参考了官方的安装说明： https://github.com/kata-containers/documentation/blob/master/how-to/how-to-use-k8s-with-cri-containerd-and-kata.md 实际上仅仅安装没有什么好讲的，文档里讲的很清楚了。但是在我们恶劣的大网络环境下，就变得有点技巧了。
以下为正文
安装环境 Virtual Machine:
OS: Ubuntu 18.04
CPU: 4
Memory: 8G
在虚拟化环境中，务必保证嵌套虚拟化打开。
虚拟化软件必须要支持 可以在guest OS里面通过以下命令检查：
1$ sudo grep -E &amp;#34;(vmx|svm)&amp;#34; --color=always /proc/cpuinfo 如果没有显示则不支持硬件虚拟化。需要打开相应的虚拟化选项，如果是物理机则需要bios里面启用虚拟化支持。
启动kvm_intel的嵌套虚拟化支持 1# modprobe -r kvm_intel 2# modprobe kvm_intel nested=1 安装kata-containers 参考：
https://github.com/kata-containers/documentation/blob/master/install/ubuntu-installation-guide.md
运行以下命令：
1$ sudo sh -c &amp;#34;echo &amp;#39;deb http://download.opensuse.org/repositories/home:/katacontainers:/release/xUbuntu_$(lsb_release -rs)/ /&amp;#39; &amp;gt; /etc/apt/sources.list.d/kata-containers.list&amp;#34; 2$ curl -sL http://download.opensuse.org/repositories/home:/katacontainers:/release/xUbuntu_$(lsb_release -rs)/Release.key | sudo apt-key add - 3$ sudo -E apt-get update 4$ sudo -E apt-get -y install kata-runtime kata-proxy kata-shim 安装docker 参考：
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kernel调试基础--制作initramfs</title>
      <link>https://weizhang555.github.io/original/make-initramfs-for-qemu-start/</link>
      <pubDate>Thu, 12 Apr 2018 19:10:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/make-initramfs-for-qemu-start/</guid>
      <description>
        
          
            通过自己制作initramfs可以使用qemu启动自定义的内核， 可以用于调试或测试。这里记录一下制作简单的initramfs的脚本， 方便后续使用。
本文参考了链接：Building a minimal Linux / Busybox OS for Qemu
完整脚本如下：
1#!/bin/bash 2set -e 3 4CWD=`pwd` 5BUSYBOX_FILE=busybox-1.28.1 6BUSYBOX_SRC=/tmp/busybox 7BUSYBOX_BUILD=/tmp/busybox-build 8INITRAMFS_DIR=/tmp/initramfs 9 10mkdir -p $BUSYBOX_SRC $BUSYBOX_BUILD $INITRAMFS_DIR 11if [ ! -e $BUSYBOX_FILE ]; then 12 wget http://busybox.net/downloads/${BUSYBOX_FILE}.tar.bz2 13fi 14tar -C $BUSYBOX_SRC -xvf ${BUSYBOX_FILE}.tar.bz2 15 16cd ${BUSYBOX_SRC}/${BUSYBOX_FILE} &amp;amp;&amp;amp; make O=${BUSYBOX_BUILD} defconfig 17# enable busybox static build 18cd ${BUSYBOX_BUILD} &amp;amp;&amp;amp; sed -i &amp;#34;s/# CONFIG_STATIC is not set/CONFIG_STATIC=y/&amp;#34; .config \ 19 &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install 20 21cd $INITRAMFS_DIR &amp;amp;&amp;amp; rm -rfv * &amp;amp;&amp;amp; mkdir -p bin sbin etc proc sys usr/bin usr/sbin \ 22 &amp;amp;&amp;amp; cp -a $BUSYBOX_BUILD/_install/* .
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kata Containers介绍，附上演讲ppt</title>
      <link>https://weizhang555.github.io/original/kata-containers-introduction/</link>
      <pubDate>Sun, 08 Apr 2018 22:00:00 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/kata-containers-introduction/</guid>
      <description>
        
          
            最近在51cto举办的meetup上做了关于Kata Containers的演讲， KataContainers是github上的新项目，前身是Intel的clear container和Hyper的runv， 融合了普通容器的轻快和虚拟机的高隔离高安全性的优点。
详细可以直接参观Kata Containers的github主页： https://github.com/kata-containers/runtime
演讲的链接传送门：http://developer.huawei.com/ict/forum/thread-48823.html
完整的演讲ppt可以在此处下载： Kata介绍与Huawei_iSula安全容器-张伟.ppt
          
          
        
      </description>
    </item>
    
    <item>
      <title>containerd源码阅读(1)--框架篇</title>
      <link>https://weizhang555.github.io/original/containerd-code-analysis/</link>
      <pubDate>Tue, 12 Sep 2017 22:40:46 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/containerd-code-analysis/</guid>
      <description>
        
          
            1. 简介 containerd是与docker直接沟通的下属组件，详细是什么不说了。 每个docker daemon启动的时候都会启动一个containerd daemon，启动容器的时候， 每个容器的init进程／exec进程都会对应一个containerd-shim进程， containerd-shim同样是containerd库里面单独的一个二进制程序， containerd-shim会调用runc最终启动容器。 这些基本的知识一笔带过不详细展开。
随着docker改名为moby，docker的大部分功能，比如image管理，容器运行都会下沉到containerd， docker会越来越侧重于编排调度部分--swarm。
简单分析下containerd的代码架构，作为官方containerd文档的一个补充。 本篇以git commit d700a9c35b09239c8c056cd5df73bc19a79db9a9 为标准讲解。
2. grpc containerd的架构极其依赖grpc协议。
1# ls api/services/ 2containers content diff events images namespaces snapshot tasks version api/services目录下存放着containerd提供的不同服务对应的grpc接口。 以比较基础的content服务为例，
1# ls api/services/content/v1/ 2content.pb.go content.proto 下面一共有两个文件，一个content.proto一个是.pb.go, 其中用户只需要定义content.proto文件， 而程序最终使用的content.pb.go则可以由grpc命令自动生成。 containerd在Makefile中提供了生成.pb.go的指令
1// 安装依赖的库 2# cd containerd &amp;amp;&amp;amp; make setup 3# make protos 打开content.proto 来看，里面主要定义了一个service：
113 service Content { 2 14 // Info returns information about a committed object. 3 15 // 4 16 // This call can be used for getting the size of content and checking for 5 17 // existence.
          
          
        
      </description>
    </item>
    
    <item>
      <title>runc源码阅读</title>
      <link>https://weizhang555.github.io/original/runc-code-analysis/</link>
      <pubDate>Tue, 12 Sep 2017 22:40:46 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/runc-code-analysis/</guid>
      <description>
        
          
            runc是docker的核心底层依赖，是容器运行的runtime，目前所属的仓库是opencontainers/runc, 是docker将原先的libcontainer模块独立出来，并贡献给oci社区的产物。
一直想写一下runc的源码分析，但是一直没有时间。暂时先把自己阅读runc过程中画得xmind思维脑图放出来吧， 里面的内容是runc的代码流程分析。有时间再回来补齐源码分析。
runc源码分析xmind文件
          
          
        
      </description>
    </item>
    
    <item>
      <title>起个头</title>
      <link>https://weizhang555.github.io/original/start/</link>
      <pubDate>Tue, 12 Sep 2017 22:40:46 +0800</pubDate>
      
      <guid>https://weizhang555.github.io/original/start/</guid>
      <description>
        
          
            之前也在其他地方开过博客，每次都坚持不了多久，零零散散写一些，回头看一下没多少有价值的东西。 这次搬家到github pages上面，算是个新的开始，旧的东西就随风而去吧，不带过来了。
从今天开始，尽量腾点时间，多写点技术文章，不在乎长度，不必刻意追求深度，尽量多留下点东西。
目前在研究容器领域的东西，就多写点docker容器相关的文章吧。
共勉。
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
